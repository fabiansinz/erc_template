@ARTICLE{Ho2016-jw,
  title         = "Generative Adversarial Imitation Learning",
  author        = "Ho, Jonathan and Ermon, Stefano",
  abstract      = "Consider learning a policy from example expert behavior,
                   without interaction with the expert or access to
                   reinforcement signal. One approach is to recover the
                   expert's cost function with inverse reinforcement learning,
                   then extract a policy from that cost function with
                   reinforcement learning. This approach is indirect and can be
                   slow. We propose a new general framework for directly
                   extracting a policy from data, as if it were obtained by
                   reinforcement learning following inverse reinforcement
                   learning. We show that a certain instantiation of our
                   framework draws an analogy between imitation learning and
                   generative adversarial networks, from which we derive a
                   model-free imitation learning algorithm that obtains
                   significant performance gains over existing model-free
                   methods in imitating complex behaviors in large,
                   high-dimensional environments.",
  month         =  jun,
  year          =  2016,
  keywords      = "4 behavior;read;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1606.03476"
}

@ARTICLE{McIntosh2016-tr,
  title    = "Deep Learning Models of the Retinal Response to Natural Scenes",
  author   = "McIntosh, Lane T and Maheswaranathan, Niru and Nayebi, Aran and
              Ganguli, Surya and Baccus, Stephen A",
  abstract = "A central challenge in sensory neuroscience is to understand
              neural computations and circuit mechanisms that underlie the
              encoding of ethologically relevant, natural stimuli. In
              multilayered neural circuits, nonlinear processes such as
              synaptic transmission and spiking dynamics present a significant
              obstacle to the creation of accurate computational models of
              responses to natural stimuli. Here we demonstrate that deep
              convolutional neural networks (CNNs) capture retinal responses to
              natural scenes nearly to within the variability of a cell's
              response, and are markedly more accurate than linear-nonlinear
              (LN) models and Generalized Linear Models (GLMs). Moreover, we
              find two additional surprising properties of CNNs: they are less
              susceptible to overfitting than their LN counterparts when
              trained on small amounts of data, and generalize better when
              tested on stimuli drawn from a different distribution (e.g.
              between natural scenes and white noise). An examination of the
              learned CNNs reveals several properties. First, a richer set of
              feature maps is necessary for predicting the responses to natural
              scenes compared to white noise. Second, temporally precise
              responses to slowly varying inputs originate from feedforward
              inhibition, similar to known retinal mechanisms. Third, the
              injection of latent noise sources in intermediate layers enables
              our model to capture the sub-Poisson spiking variability observed
              in retinal ganglion cells. Fourth, augmenting our CNNs with
              recurrent lateral connections enables them to capture contrast
              adaptation as an emergent property of accurately describing
              retinal responses to natural scenes. These methods can be readily
              generalized to other sensory modalities and stimulus ensembles.
              Overall, this work demonstrates that CNNs not only accurately
              capture sensory circuit responses to natural scenes, but also can
              yield information about the circuit's internal structure and
              function.",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  29,
  number   = "Nips",
  pages    = "1369--1377",
  year     =  2016,
  keywords = "system identification;system identification;ERC Consolidator 2023"
}

@ARTICLE{Arora2018-tq,
  title         = "A Survey of Inverse Reinforcement Learning: Challenges,
                   Methods and Progress",
  author        = "Arora, Saurabh and Doshi, Prashant",
  abstract      = "Inverse reinforcement learning (IRL) is the problem of
                   inferring the reward function of an agent, given its policy
                   or observed behavior. Analogous to RL, IRL is perceived both
                   as a problem and as a class of methods. By categorically
                   surveying the current literature in IRL, this article serves
                   as a reference for researchers and practitioners of machine
                   learning and beyond to understand the challenges of IRL and
                   select the approaches best suited for the problem on hand.
                   The survey formally introduces the IRL problem along with
                   its central challenges such as the difficulty in performing
                   accurate inference and its generalizability, its sensitivity
                   to prior knowledge, and the disproportionate growth in
                   solution complexity with problem size. The article
                   elaborates how the current methods mitigate these
                   challenges. We further discuss the extensions to traditional
                   IRL methods for handling: inaccurate and incomplete
                   perception, an incomplete model, multiple reward functions,
                   and nonlinear reward functions. This survey concludes the
                   discussion with some broad advances in the research area and
                   currently open research questions.",
  month         =  jun,
  year          =  2018,
  keywords      = "read;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1806.06877"
}

@ARTICLE{Watters2019-qy,
  title         = "Spatial Broadcast Decoder: A Simple Architecture for
                   Learning Disentangled Representations in {VAEs}",
  author        = "Watters, Nicholas and Matthey, Loic and Burgess, Christopher
                   P and Lerchner, Alexander",
  abstract      = "We present a simple neural rendering architecture that helps
                   variational autoencoders (VAEs) learn disentangled
                   representations. Instead of the deconvolutional network
                   typically used in the decoder of VAEs, we tile (broadcast)
                   the latent vector across space, concatenate fixed X- and
                   Y-``coordinate'' channels, and apply a fully convolutional
                   network with 1x1 stride. This provides an architectural
                   prior for dissociating positional from non-positional
                   features in the latent distribution of VAEs, yet without
                   providing any explicit supervision to this effect. We show
                   that this architecture, which we term the Spatial Broadcast
                   decoder, improves disentangling, reconstruction accuracy,
                   and generalization to held-out regions in data space. It
                   provides a particularly dramatic benefit when applied to
                   datasets with small objects. We also emphasize a method for
                   visualizing learned latent spaces that helped us diagnose
                   our models and may prove useful for others aiming to assess
                   data representations. Finally, we show the Spatial Broadcast
                   Decoder is complementary to state-of-the-art (SOTA)
                   disentangling techniques and when incorporated improves
                   their performance.",
  month         =  jan,
  year          =  2019,
  keywords      = "read next;unread;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1901.07017"
}

@ARTICLE{Deverett2019-gs,
  title    = "Interval timing in deep reinforcement learning agents",
  author   = "Deverett, B and Faulkner, Ryan and Fortunato, Meire and Wayne,
              Greg and Leibo, Joel Z",
  abstract = "This work characterize the strategies developed by recurrent and
              feedforward agents, which both succeed at temporal reproduction
              using distinct mechanisms, some of which bear specific and
              intriguing similarities to biological systems. The measurement of
              time is central to intelligent behavior. We know that both
              animals and artificial agents can successfully use temporal
              dependencies to select actions. In artificial agents, little work
              has directly addressed (1) which architectural components are
              necessary for successful development of this ability, (2) how
              this timing ability comes to be represented in the units and
              actions of the agent, and (3) whether the resulting behavior of
              the system converges on solutions similar to those of biology.
              Here we studied interval timing abilities in deep reinforcement
              learning agents trained end-to-end on an interval reproduction
              paradigm inspired by experimental literature on mechanisms of
              timing. We characterize the strategies developed by recurrent and
              feedforward agents, which both succeed at temporal reproduction
              using distinct mechanisms, some of which bear specific and
              intriguing similarities to biological systems. These findings
              advance our understanding of how agents come to represent time,
              and they highlight the value of experimentally inspired
              approaches to characterizing agent abilities.",
  journal  = "Adv. Neural Inf. Process. Syst.",
  year     =  2019,
  keywords = "4 behavior;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Cowley2020-cy,
  title    = "High-contrast ``gaudy'' images improve the training of deep
              neural network models of visual cortex",
  author   = "Cowley, Benjamin R and Pillow, Jonathan W",
  abstract = "A key challenge in understanding the sensory transformations of
              the visual system is to obtain a highly predictive model of
              responses from visual cortical neurons. Deep neural networks
              (DNNs) provide a promising candidate for such a model. However,
              DNNs require orders of magnitude more training data than
              neuroscientists can collect from real neurons because
              experimental recording time is severely limited. This motivates
              us to find images that train highly-predictive DNNs with as
              little training data as possible. We propose gaudy
              images---high-contrast binarized versions of natural images---to
              efficiently train DNNs. In extensive simulation experiments, we
              find that training DNNs with gaudy images substantially reduces
              the number of training images needed to accurately predict the
              simulated responses of visual cortical neurons. We also find that
              gaudy images, chosen before training, outperform images chosen
              during training by active learning algorithms. Thus, gaudy images
              overemphasize features of natural images, especially edges, that
              are the most important for efficiently training DNNs. We believe
              gaudy images will aid in the modeling of visual cortical neurons,
              potentially opening new scientific questions about visual
              processing, as well as aid general practitioners that seek ways
              to improve the training of DNNs.",
  year     =  2020,
  keywords = "read;system identification;ERC Consolidator 2023"
}

@ARTICLE{Locatello2020-io,
  title         = "Object-centric learning with Slot Attention",
  author        = "Locatello, Francesco and Weissenborn, Dirk and Unterthiner,
                   Thomas and Mahendran, Aravindh and Heigold, Georg and
                   Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas",
  abstract      = "Learning object-centric representations of complex scenes is
                   a promising step towards enabling efficient abstract
                   reasoning from low-level perceptual features. Yet, most deep
                   learning approaches learn distributed representations that
                   do not capture the compositional properties of natural
                   scenes. In this paper, we present the Slot Attention module,
                   an architectural component that interfaces with perceptual
                   representations such as the output of a convolutional neural
                   network and produces a set of task-dependent abstract
                   representations which we call slots. These slots are
                   exchangeable and can bind to any object in the input by
                   specializing through a competitive procedure over multiple
                   rounds of attention. We empirically demonstrate that Slot
                   Attention can extract object-centric representations that
                   enable generalization to unseen compositions when trained on
                   unsupervised object discovery and supervised property
                   prediction tasks.",
  month         =  jun,
  year          =  2020,
  keywords      = "read;ERC Consolidator 2023",
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2006.15055"
}

@ARTICLE{Cobbe2020-ap,
  title         = "Phasic Policy Gradient",
  author        = "Cobbe, Karl and Hilton, Jacob and Klimov, Oleg and Schulman,
                   John",
  abstract      = "We introduce Phasic Policy Gradient (PPG), a reinforcement
                   learning framework which modifies traditional on-policy
                   actor-critic methods by separating policy and value function
                   training into distinct phases. In prior methods, one must
                   choose between using a shared network or separate networks
                   to represent the policy and value function. Using separate
                   networks avoids interference between objectives, while using
                   a shared network allows useful features to be shared. PPG is
                   able to achieve the best of both worlds by splitting
                   optimization into two phases, one that advances training and
                   one that distills features. PPG also enables the value
                   function to be more aggressively optimized with a higher
                   level of sample reuse. Compared to PPO, we find that PPG
                   significantly improves sample efficiency on the challenging
                   Procgen Benchmark.",
  month         =  sep,
  year          =  2020,
  keywords      = "4 behavior;read next;unread;ERC Consolidator 2023",
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2009.04416"
}

@ARTICLE{Chen2021-ap,
  title         = "Decision Transformer: Reinforcement Learning via Sequence
                   Modeling",
  author        = "Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee,
                   Kimin and Grover, Aditya and Laskin, Michael and Abbeel,
                   Pieter and Srinivas, Aravind and Mordatch, Igor",
  abstract      = "We introduce a framework that abstracts Reinforcement
                   Learning (RL) as a sequence modeling problem. This allows us
                   to draw upon the simplicity and scalability of the
                   Transformer architecture, and associated advances in
                   language modeling such as GPT-x and BERT. In particular, we
                   present Decision Transformer, an architecture that casts the
                   problem of RL as conditional sequence modeling. Unlike prior
                   approaches to RL that fit value functions or compute policy
                   gradients, Decision Transformer simply outputs the optimal
                   actions by leveraging a causally masked Transformer. By
                   conditioning an autoregressive model on the desired return
                   (reward), past states, and actions, our Decision Transformer
                   model can generate future actions that achieve the desired
                   return. Despite its simplicity, Decision Transformer matches
                   or exceeds the performance of state-of-the-art model-free
                   offline RL baselines on Atari, OpenAI Gym, and Key-to-Door
                   tasks.",
  month         =  jun,
  year          =  2021,
  keywords      = "read;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2106.01345"
}

@ARTICLE{Kipf2021-zk,
  title         = "Conditional {Object-Centric} Learning from Video",
  author        = "Kipf, Thomas and Elsayed, Gamaleldin F and Mahendran,
                   Aravindh and Stone, Austin and Sabour, Sara and Heigold,
                   Georg and Jonschkowski, Rico and Dosovitskiy, Alexey and
                   Greff, Klaus",
  abstract      = "Object-centric representations are a promising path toward
                   more systematic generalization by providing flexible
                   abstractions upon which compositional world models can be
                   built. Recent work on simple 2D and 3D datasets has shown
                   that models with object-centric inductive biases can learn
                   to segment and represent meaningful objects from the
                   statistical structure of the data alone without the need for
                   any supervision. However, such fully-unsupervised methods
                   still fail to scale to diverse realistic data, despite the
                   use of increasingly complex inductive biases such as priors
                   for the size of objects or the 3D geometry of the scene. In
                   this paper, we instead take a weakly-supervised approach and
                   focus on how 1) using the temporal dynamics of video data in
                   the form of optical flow and 2) conditioning the model on
                   simple object location cues can be used to enable segmenting
                   and tracking objects in significantly more realistic
                   synthetic data. We introduce a sequential extension to Slot
                   Attention which we train to predict optical flow for
                   realistic looking synthetic scenes and show that
                   conditioning the initial state of this model on a small set
                   of hints, such as center of mass of objects in the first
                   frame, is sufficient to significantly improve instance
                   segmentation. These benefits generalize beyond the training
                   distribution to novel objects, novel backgrounds, and to
                   longer video sequences. We also find that such
                   initial-state-conditioning can be used during inference as a
                   flexible interface to query the model for specific objects
                   or parts of objects, which could pave the way for a range of
                   weakly-supervised approaches and allow more effective
                   interaction with trained models.",
  month         =  nov,
  year          =  2021,
  keywords      = "read;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "2111.12594"
}

@ARTICLE{Whittington2021-rb,
  title         = "Relating transformers to models and neural representations
                   of the hippocampal formation",
  author        = "Whittington, James C R and Warren, Joseph and Behrens,
                   Timothy E J",
  abstract      = "Many deep neural network architectures loosely based on
                   brain networks have recently been shown to replicate neural
                   firing patterns observed in the brain. One of the most
                   exciting and promising novel architectures, the Transformer
                   neural network, was developed without the brain in mind. In
                   this work, we show that transformers, when equipped with
                   recurrent position encodings, replicate the precisely tuned
                   spatial representations of the hippocampal formation; most
                   notably place and grid cells. Furthermore, we show that this
                   result is no surprise since it is closely related to current
                   hippocampal models from neuroscience. We additionally show
                   the transformer version offers dramatic performance gains
                   over the neuroscience version. This work continues to bind
                   computations of artificial and brain networks, offers a
                   novel understanding of the hippocampal-cortical interaction,
                   and suggests how wider cortical areas may perform complex
                   tasks beyond current neuroscience models such as language
                   comprehension.",
  month         =  dec,
  year          =  2021,
  keywords      = "read next;unread;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.NE",
  eprint        = "2112.04035"
}

@ARTICLE{Schneider2022-qf,
  title         = "Learnable latent embeddings for joint behavioral and neural
                   analysis",
  author        = "Schneider, Steffen and Lee, Jin Hwa and Mathis, Mackenzie
                   Weygandt",
  abstract      = "Mapping behavioral actions to neural activity is a
                   fundamental goal of neuroscience. As our ability to record
                   large neural and behavioral data increases, there is growing
                   interest in modeling neural dynamics during adaptive
                   behaviors to probe neural representations. In particular,
                   neural latent embeddings can reveal underlying correlates of
                   behavior, yet, we lack non-linear techniques that can
                   explicitly and flexibly leverage joint behavior and neural
                   data. Here, we fill this gap with a novel method, CEBRA,
                   that jointly uses behavioral and neural data in a
                   hypothesis- or discovery-driven manner to produce
                   consistent, high-performance latent spaces. We validate its
                   accuracy and demonstrate our tool's utility for both calcium
                   and electrophysiology datasets, across sensory and motor
                   tasks, and in simple or complex behaviors across species. It
                   allows for single and multi-session datasets to be leveraged
                   for hypothesis testing or can be used label-free. Lastly, we
                   show that CEBRA can be used for the mapping of space,
                   uncovering complex kinematic features, and rapid,
                   high-accuracy decoding of natural movies from visual cortex.",
  month         =  apr,
  year          =  2022,
  keywords      = "read;U19;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2204.00673"
}

@ARTICLE{Kalweit2022-ev,
  title         = "{NeuRL}: Closed-form Inverse Reinforcement Learning for
                   Neural Decoding",
  author        = "Kalweit, Gabriel and Kalweit, Maria and Alyahyay, Mansour
                   and Jaeckel, Zoe and Steenbergen, Florian and Hardung,
                   Stefanie and Brox, Thomas and Diester, Ilka and Boedecker,
                   Joschka",
  abstract      = "Current neural decoding methods typically aim at explaining
                   behavior based on neural activity via supervised learning.
                   However, since generally there is a strong connection
                   between learning of subjects and their expectations on
                   long-term rewards, we propose NeuRL, an inverse
                   reinforcement learning approach that (1) extracts an
                   intrinsic reward function from collected trajectories of a
                   subject in closed form, (2) maps neural signals to this
                   intrinsic reward to account for long-term dependencies in
                   the behavior and (3) predicts the simulated behavior for
                   unseen neural signals by extracting Q-values and the
                   corresponding Boltzmann policy based on the intrinsic reward
                   values for these unseen neural signals. We show that NeuRL
                   leads to better generalization and improved decoding
                   performance compared to supervised approaches. We study the
                   behavior of rats in a response-preparation task and evaluate
                   the performance of NeuRL within simulated inhibition and
                   per-trial behavior prediction. By assigning clear functional
                   roles to defined neuronal populations our approach offers a
                   new interpretation tool for complex neuronal data with
                   testable predictions. In per-trial behavior prediction, our
                   approach furthermore improves accuracy by up to 15\%
                   compared to traditional methods.",
  month         =  apr,
  year          =  2022,
  keywords      = "4 mouse;read;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.NC",
  eprint        = "2204.04733"
}

@ARTICLE{Sajjadi2022-qb,
  title         = "Object Scene Representation Transformer",
  author        = "Sajjadi, Mehdi S M and Duckworth, Daniel and Mahendran,
                   Aravindh and van Steenkiste, Sjoerd and Paveti{\'c}, Filip
                   and Lu{\v c}i{\'c}, Mario and Guibas, Leonidas J and Greff,
                   Klaus and Kipf, Thomas",
  abstract      = "A compositional understanding of the world in terms of
                   objects and their geometry in 3D space is considered a
                   cornerstone of human cognition. Facilitating the learning of
                   such a representation in neural networks holds promise for
                   substantially improving labeled data efficiency. As a key
                   step in this direction, we make progress on the problem of
                   learning 3D-consistent decompositions of complex scenes into
                   individual objects in an unsupervised fashion. We introduce
                   Object Scene Representation Transformer (OSRT), a 3D-centric
                   model in which individual object representations naturally
                   emerge through novel view synthesis. OSRT scales to
                   significantly more complex scenes with larger diversity of
                   objects and backgrounds than existing methods. At the same
                   time, it is multiple orders of magnitude faster at
                   compositional rendering thanks to its light field
                   parametrization and the novel Slot Mixer decoder. We believe
                   this work will not only accelerate future architecture
                   exploration and scaling efforts, but it will also serve as a
                   useful tool for both object-centric as well as neural scene
                   representation learning communities.",
  month         =  jun,
  year          =  2022,
  keywords      = "ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "2206.06922"
}

@ARTICLE{Willeke2022-qu,
  title         = "The Sensorium competition on predicting large-scale mouse
                   primary visual cortex activity",
  author        = "Willeke, Konstantin F and Fahey, Paul G and Bashiri,
                   Mohammad and Pede, Laura and Burg, Max F and Blessing,
                   Christoph and Cadena, Santiago A and Ding, Zhiwei and Lurz,
                   Konstantin-Klemens and Ponder, Kayla and Muhammad, Taliah
                   and Patel, Saumil S and Ecker, Alexander S and Tolias,
                   Andreas S and Sinz, Fabian H",
  abstract      = "The neural underpinning of the biological visual system is
                   challenging to study experimentally, in particular as the
                   neuronal activity becomes increasingly nonlinear with
                   respect to visual input. Artificial neural networks (ANNs)
                   can serve a variety of goals for improving our understanding
                   of this complex system, not only serving as predictive
                   digital twins of sensory cortex for novel hypothesis
                   generation in silico, but also incorporating bio-inspired
                   architectural motifs to progressively bridge the gap between
                   biological and machine vision. The mouse has recently
                   emerged as a popular model system to study visual
                   information processing, but no standardized large-scale
                   benchmark to identify state-of-the-art models of the mouse
                   visual system has been established. To fill this gap, we
                   propose the Sensorium benchmark competition. We collected a
                   large-scale dataset from mouse primary visual cortex
                   containing the responses of more than 28,000 neurons across
                   seven mice stimulated with thousands of natural images,
                   together with simultaneous behavioral measurements that
                   include running speed, pupil dilation, and eye movements.
                   The benchmark challenge will rank models based on predictive
                   performance for neuronal responses on a held-out test set,
                   and includes two tracks for model input limited to either
                   stimulus only (Sensorium) or stimulus plus behavior
                   (Sensorium+). We provide a starting kit to lower the barrier
                   for entry, including tutorials, pre-trained baseline models,
                   and APIs with one line commands for data loading and
                   submission. We would like to see this as a starting point
                   for regular challenges and data releases, and as a standard
                   tool for measuring progress in large-scale neural system
                   identification models of the mouse visual system and beyond.",
  month         =  jun,
  year          =  2022,
  keywords      = "read;own;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.NC",
  eprint        = "2206.08666"
}

@ARTICLE{Doerig2022-ex,
  title         = "The neuroconnectionist research programme",
  author        = "Doerig, Adrien and Sommers, Rowan and Seeliger, Katja and
                   Richards, Blake and Ismael, Jenann and Lindsay, Grace and
                   Kording, Konrad and Konkle, Talia and Van Gerven, Marcel A J
                   and Kriegeskorte, Nikolaus and Kietzmann, Tim C",
  abstract      = "Artificial Neural Networks (ANNs) inspired by biology are
                   beginning to be widely used to model behavioral and neural
                   data, an approach we call neuroconnectionism. ANNs have been
                   lauded as the current best models of information processing
                   in the brain, but also criticized for failing to account for
                   basic cognitive functions. We propose that arguing about the
                   successes and failures of a restricted set of current ANNs
                   is the wrong approach to assess the promise of
                   neuroconnectionism. Instead, we take inspiration from the
                   philosophy of science, and in particular from Lakatos, who
                   showed that the core of scientific research programmes is
                   often not directly falsifiable, but should be assessed by
                   its capacity to generate novel insights. Following this
                   view, we present neuroconnectionism as a cohesive
                   large-scale research programme centered around ANNs as a
                   computational language for expressing falsifiable theories
                   about brain computation. We describe the core of the
                   programme, the underlying computational framework and its
                   tools for testing specific neuroscientific hypotheses.
                   Taking a longitudinal view, we review past and present
                   neuroconnectionist projects and their responses to
                   challenges, and argue that the research programme is highly
                   progressive, generating new and otherwise unreachable
                   insights into the workings of the brain.",
  month         =  sep,
  year          =  2022,
  keywords      = "read;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.NC",
  eprint        = "2209.03718"
}

@ARTICLE{Chiappa2022-tj,
  title         = "{DMAP}: a Distributed Morphological Attention Policy for
                   Learning to Locomote with a Changing Body",
  author        = "Chiappa, Alberto Silvio and Vargas, Alessandro Marin and
                   Mathis, Alexander",
  abstract      = "Biological and artificial agents need to deal with constant
                   changes in the real world. We study this problem in four
                   classical continuous control environments, augmented with
                   morphological perturbations. Learning to locomote when the
                   length and the thickness of different body parts vary is
                   challenging, as the control policy is required to adapt to
                   the morphology to successfully balance and advance the
                   agent. We show that a control policy based on the
                   proprioceptive state performs poorly with highly variable
                   body configurations, while an (oracle) agent with access to
                   a learned encoding of the perturbation performs
                   significantly better. We introduce DMAP, a
                   biologically-inspired, attention-based policy network
                   architecture. DMAP combines independent proprioceptive
                   processing, a distributed policy with individual controllers
                   for each joint, and an attention mechanism, to dynamically
                   gate sensory information from different body parts to
                   different controllers. Despite not having access to the
                   (hidden) morphology information, DMAP can be trained
                   end-to-end in all the considered environments, overall
                   matching or surpassing the performance of an oracle agent.
                   Thus DMAP, implementing principles from biological motor
                   control, provides a strong inductive bias for learning
                   challenging sensorimotor tasks. Overall, our work
                   corroborates the power of these principles in challenging
                   locomotion tasks.",
  month         =  sep,
  year          =  2022,
  keywords      = "unread;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.RO",
  eprint        = "2209.14218"
}

@ARTICLE{Pierzchlewicz2022-tq,
  title         = "Multi-hypothesis {3D} human pose estimation metrics favor
                   miscalibrated distributions",
  author        = "Pierzchlewicz, Pawe{\l} A and James Cotton, R and Bashiri,
                   Mohammad and Sinz, Fabian H",
  abstract      = "Due to depth ambiguities and occlusions, lifting 2D poses to
                   3D is a highly ill-posed problem. Well-calibrated
                   distributions of possible poses can make these ambiguities
                   explicit and preserve the resulting uncertainty for
                   downstream tasks. This study shows that previous attempts,
                   which account for these ambiguities via multiple hypotheses
                   generation, produce miscalibrated distributions. We identify
                   that miscalibration can be attributed to the use of
                   sample-based metrics such as minMPJPE. In a series of
                   simulations, we show that minimizing minMPJPE, as commonly
                   done, should converge to the correct mean prediction.
                   However, it fails to correctly capture the uncertainty, thus
                   resulting in a miscalibrated distribution. To mitigate this
                   problem, we propose an accurate and well-calibrated model
                   called Conditional Graph Normalizing Flow (cGNFs). Our model
                   is structured such that a single cGNF can estimate both
                   conditional and marginal densities within the same model -
                   effectively solving a zero-shot density estimation problem.
                   We evaluate cGNF on the Human~3.6M dataset and show that
                   cGNF provides a well-calibrated distribution estimate while
                   being close to state-of-the-art in terms of overall
                   minMPJPE. Furthermore, cGNF outperforms previous methods on
                   occluded joints while it remains well-calibrated.",
  month         =  oct,
  year          =  2022,
  keywords      = "own;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "2210.11179"
}

@ARTICLE{Howell2022-gc,
  title         = "Predictive Sampling: Real-time Behaviour Synthesis with
                   {MuJoCo}",
  author        = "Howell, Taylor and Gileadi, Nimrod and Tunyasuvunakool,
                   Saran and Zakka, Kevin and Erez, Tom and Tassa, Yuval",
  abstract      = "We introduce MuJoCo MPC (MJPC), an open-source, interactive
                   application and software framework for real-time predictive
                   control, based on MuJoCo physics. MJPC allows the user to
                   easily author and solve complex robotics tasks, and
                   currently supports three shooting-based planners:
                   derivative-based iLQG and Gradient Descent, and a simple
                   derivative-free method we call Predictive Sampling.
                   Predictive Sampling was designed as an elementary baseline,
                   mostly for its pedagogical value, but turned out to be
                   surprisingly competitive with the more established
                   algorithms. This work does not present algorithmic advances,
                   and instead, prioritises performant algorithms, simple code,
                   and accessibility of model-based methods via intuitive and
                   interactive software. MJPC is available at:
                   github.com/deepmind/mujoco\_mpc, a video summary can be
                   viewed at: dpmd.ai/mjpc.",
  month         =  dec,
  year          =  2022,
  keywords      = "4 behavior;read next;unread;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.RO",
  eprint        = "2212.00541"
}

@ARTICLE{Perez2023-fu,
  title         = "{CNN-Based} Action Recognition and Pose Estimation for
                   Classifying Animal Behavior from Videos: A Survey",
  author        = "Perez, Michael and Toler-Franklin, Corey",
  abstract      = "Classifying the behavior of humans or animals from videos is
                   important in biomedical fields for understanding brain
                   function and response to stimuli. Action recognition,
                   classifying activities performed by one or more subjects in
                   a trimmed video, forms the basis of many of these
                   techniques. Deep learning models for human action
                   recognition have progressed significantly over the last
                   decade. Recently, there is an increased interest in research
                   that incorporates deep learning-based action recognition for
                   animal behavior classification. However, human action
                   recognition methods are more developed. This survey presents
                   an overview of human action recognition and pose estimation
                   methods that are based on convolutional neural network (CNN)
                   architectures and have been adapted for animal behavior
                   classification in neuroscience. Pose estimation, estimating
                   joint positions from an image frame, is included because it
                   is often applied before classifying animal behavior. First,
                   we provide foundational information on algorithms that learn
                   spatiotemporal features through 2D, two-stream, and 3D CNNs.
                   We explore motivating factors that determine optimizers,
                   loss functions and training procedures, and compare their
                   performance on benchmark datasets. Next, we review animal
                   behavior frameworks that use or build upon these methods,
                   organized by the level of supervision they require. Our
                   discussion is uniquely focused on the technical evolution of
                   the underlying CNN models and their architectural
                   adaptations (which we illustrate), rather than their
                   usability in a neuroscience lab. We conclude by discussing
                   open research problems, and possible research directions.
                   Our survey is designed to be a resource for researchers
                   developing fully unsupervised animal behavior classification
                   systems of which there are only a few examples in the
                   literature.",
  month         =  jan,
  year          =  2023,
  keywords      = "4 behavior;unread;ERC Consolidator 2023",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "2301.06187"
}

@ARTICLE{Zhang2018-cs,
  title    = "Convolutional neural network models of {V1} responses to complex
              patterns",
  author   = "Zhang, Yimeng and Lee, T-S Tai Sing and Li, Ming and Liu, Fang
              and Tang, Shiming and Sing, Tai and Ming, Lee and Fang, Li and
              Shiming, Liu and Lee, T-S Tai Sing and Li, Ming and Liu, Fang and
              Tang, Shiming",
  abstract = "In this study, we evaluated the convolutional neural network
              (CNN) method for modeling V1 neurons of awake macaque monkeys in
              response to a large set of complex pattern stimuli. CNN models
              outperformed all the other baseline models, such as Gabor-based
              standard models for V1 cells and various variants of generalized
              linear models. We then systematically dissected different
              components of the CNN and found two key factors that made CNNs
              outperform other models: thresholding nonlinearity and
              convolution. In addition, we fitted our data using a pre-trained
              deep CNN via transfer learning. The deep CNN's higher layers,
              which encode more complex patterns, outperformed lower ones, and
              this result was consistent with our earlier work on the
              complexity of V1 neural code. Our study systematically evaluates
              the relative merits of different CNN components in the context of
              V1 neuron modeling.",
  journal  = "J. Comput. Neurosci.",
  pages    = "1--22",
  year     =  2018,
  keywords = "Convolutional neural network; Nonlinear regression; System
              identification; V1; convolutional neural network; nonlinear
              regression; system identification; v1;\_old;ERC Consolidator 2023"
}

@ARTICLE{Wiersma1968-xt,
  title    = "The selective responsiveness of various crayfish oculomotor
              fibers to sensory stimuli",
  author   = "Wiersma, C A and Oberjat, T",
  journal  = "Comp. Biochem. Physiol.",
  volume   =  26,
  number   =  1,
  pages    = "1--16",
  month    =  jul,
  year     =  1968,
  keywords = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Ponce2019-yn,
  title     = "Evolving Images for Visual Neurons Using a Deep Generative
               Network Reveals Coding Principles and Neuronal Preferences",
  author    = "Ponce, Carlos R and Xiao, Will and Schade, Peter F and Hartmann,
               Till S and Kreiman, Gabriel and Livingstone, Margaret S",
  abstract  = "What specific features should visual neurons encode, given the
               infinity of real-world images and the limited number of neurons
               available to represent them? We investigated neuronal
               selectivity in monkey inferotemporal cortex via the vast
               hypothesis space of a generative deep neural network, avoiding
               assumptions about features or semantic categories. A genetic
               algorithm searched this space for stimuli that maximized
               neuronal firing. This led to the evolution of rich synthetic
               images of objects with complex combinations of shapes, colors,
               and textures, sometimes resembling animals or familiar people,
               other times revealing novel patterns that did not map to any
               clear semantic category. These results expand our conception of
               the dictionary of features encoded in the cortex, and the
               approach can potentially reveal the internal representations of
               any system whose input can be captured by a generative model.",
  journal   = "Cell",
  publisher = "Elsevier",
  volume    =  177,
  number    =  4,
  pages     = "999--1009.e10",
  year      =  2019,
  keywords  = "generative adversarial network; inferotemporal cortex; neural
               networks;read;MEI \& reconstruction;ERC Consolidator 2023"
}

@ARTICLE{Eggermann2014-xp,
  title    = "Cholinergic Signals in Mouse Barrel Cortex during Active Whisker
              Sensing",
  author   = "Eggermann, Emmanuel and Kremer, Yves and Crochet, Sylvain and
              Petersen, Carl C H",
  abstract = "Summary Internal brain states affect sensory perception,
              cognition, and learning. Many neocortical areas exhibit changes
              in the pattern and synchrony of neuronal activity during quiet
              versus active behaviors. Active behaviors are typically
              associated with desynchronized cortical dynamics. Increased
              thalamic firing contributes importantly to desynchronize mouse
              barrel cortex during active whisker sensing. However, a
              whisking-related cortical state change persists after thalamic
              inactivation, which is mediated at least in part by
              acetylcholine, as we show here by using whole-cell recordings,
              local pharmacology, axonal calcium imaging, and optogenetic
              stimulation. During whisking, we find prominent cholinergic
              signals in the barrel cortex, which suppress spontaneous cortical
              activity. The desynchronized state of barrel cortex during
              whisking is therefore driven by at least two distinct signals
              with opposing functions: increased thalamic activity driving
              glutamatergic excitation of the cortex and increased cholinergic
              input suppressing spontaneous cortical activity.",
  journal  = "Cell Rep.",
  volume   =  9,
  number   =  5,
  pages    = "1654--1660",
  month    =  dec,
  year     =  2014,
  keywords = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023"
}

@ARTICLE{Wang2022-cn,
  title    = "Tuning landscapes of the ventral stream",
  author   = "Wang, Binxu and Ponce, Carlos R",
  abstract = "A goal in visual neuroscience is to explain how neurons respond
              to natural scenes. However, neurons are generally tested using
              simpler stimuli, often because they can be transformed smoothly,
              allowing the measurement of tuning functions (i.e., response
              peaks and slopes). Here, we test the idea that all classic tuning
              curves can be viewed as slices of a higher-dimensional tuning
              landscape. We use activation-maximizing stimuli (``prototypes'')
              as landmarks in a generative image space and map tuning functions
              around these peaks. We find that neurons show smooth bell-shaped
              tuning consistent with radial basis functions, spanning a vast
              image transformation range, with systematic differences in
              landscape geometry from V1 to inferotemporal cortex. By modeling
              these trends, we infer that neurons in the higher visual cortex
              have higher intrinsic feature dimensionality. Overall, these
              results suggest that visual neurons are better viewed as
              signaling distances to prototypes on an image manifold.",
  journal  = "Cell Rep.",
  volume   =  41,
  number   =  6,
  pages    = "111595",
  month    =  nov,
  year     =  2022,
  keywords = "CP: Neuroscience; V1; V4; generative image model; geometry;
              inferotemporal cortex; intrinsic dimensionality; natural image
              manifold; neural tuning; neuron-guided image synthesis; radial
              basis function; tuning; vision; visual cortex; visual
              hierarchy;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Juavinett2018-oz,
  title    = "Decision-making behaviors: weighing ethology, complexity, and
              sensorimotor compatibility",
  author   = "Juavinett, Ashley L and Erlich, Jeffrey C and Churchland, Anne K",
  abstract = "Rodent decision-making research aims to uncover the neural
              circuitry underlying the ability to evaluate alternatives and
              select appropriate actions. Designing behavioral paradigms that
              provide a solid foundation to ask questions about decision-making
              computations and mechanisms is a difficult and often
              underestimated challenge. Here, we propose three dimensions on
              which we can consider rodent decision-making tasks: ethological
              validity, task complexity, and stimulus-response compatibility.
              We review recent research through this lens, and provide
              practical guidance for researchers in the decision-making field.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  49,
  pages    = "42--50",
  month    =  apr,
  year     =  2018,
  keywords = "4 behavior;4 mouse;read next;unread;ERC Consolidator 2023"
}

@ARTICLE{Katzner2019-di,
  title    = "{V1} microcircuits underlying mouse visual behavior",
  author   = "Katzner, Steffen and Born, Gregory and Busse, Laura",
  abstract = "Visual behavior is based on the concerted activity of neurons in
              visual areas, where sensory signals are integrated with top-down
              information. In the past decade, the advent of new tools, such as
              functional imaging of populations of identified single neurons,
              high-density electrophysiology, virus-assisted circuit mapping,
              and precisely timed, cell-type specific manipulations, has
              advanced our understanding of the neuronal microcircuits
              underlying visual behavior. Studies in head-fixed mice, where
              such tools can routinely be applied, begin to provide new
              insights into the neural code of primary visual cortex (V1)
              underlying visual perception, and the micro-circuits of
              attention, predictive processing, and learning.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "191--198",
  month    =  oct,
  year     =  2019,
  keywords = "read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Chiappe2010-bm,
  title    = "Walking Modulates Speed Sensitivity in Drosophila Motion Vision",
  author   = "Chiappe, M Eugenia and Seelig, Johannes D and Reiser, Michael B
              and Jayaraman, Vivek",
  abstract = "Summary Changes in behavioral state modify neural activity in
              many systems [1, 2, 3, 4, 5]. In some vertebrates such modulation
              has been observed and interpreted in the context of attention [2]
              and sensorimotor coordinate transformations [3]. Here we report
              state-dependent activity modulations during walking in a
              visual-motor pathway of Drosophila. We used two-photon imaging to
              monitor intracellular calcium activity in motion-sensitive lobula
              plate tangential cells (LPTCs) in head-fixed Drosophila walking
              on an air-supported ball. Cells of the horizontal system (HS)---a
              subgroup of LPTCs---showed stronger calcium transients in
              response to visual motion when flies were walking rather than
              resting. The amplified responses were also correlated with
              walking speed. Moreover, HS neurons showed a relatively higher
              gain in response strength at higher temporal frequencies, and
              their optimum temporal frequency was shifted toward higher motion
              speeds. Walking-dependent modulation of HS neurons in the
              Drosophila visual system may constitute a mechanism to facilitate
              processing of higher image speeds in behavioral contexts where
              these speeds of visual motion are relevant for course
              stabilization.",
  journal  = "Curr. Biol.",
  volume   =  20,
  number   =  16,
  pages    = "1470--1475",
  month    =  aug,
  year     =  2010,
  keywords = "SYSNEURO;4 behavior;4 brainstate;read next;unread;ERC
              Consolidator 2023"
}

@ARTICLE{Ayaz2013-vv,
  title    = "Locomotion controls spatial integration in mouse visual cortex",
  author   = "Ayaz, Asl{\i} and Saleem, Aman B and Sch{\"o}lvinck, Marieke L
              and Carandini, Matteo",
  abstract = "Growing evidence indicates that responses in sensory cortex are
              modulated by factors beyond direct sensory stimulation. In
              primary visual cortex (V1), for instance, responses increase with
              locomotion. Here we show that this increase is accompanied by a
              profound change in spatial integration. We recorded from V1
              neurons in head-fixed mice placed on a spherical treadmill. We
              characterized spatial integration and found that the responses of
              most neurons were suppressed by large stimuli. As in primates,
              this surround suppression increased with stimulus contrast. These
              effects were captured by a divisive normalization model, where
              the numerator originates from a central region driving the neuron
              and the denominator originates from a larger suppressive field.
              We then studied the effects of locomotion and found that it
              markedly reduced surround suppression, allowing V1 neurons to
              integrate over larger regions of visual space. Locomotion had two
              main effects: it increased spontaneous activity, and it weakened
              the suppressive signals mediating normalization, relative to the
              driving signals. We conclude that a fundamental aspect of visual
              processing, spatial integration, is controlled by an apparently
              unrelated factor, locomotion. This control might operate through
              the mechanisms that are in place to deliver surround suppression.",
  journal  = "Curr. Biol.",
  volume   =  23,
  number   =  10,
  pages    = "890--894",
  month    =  may,
  year     =  2013,
  keywords = "4 mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Erisken2014-un,
  title    = "Effects of locomotion extend throughout the mouse early visual
              system",
  author   = "Erisken, S and Vaiceliunaite, A and Jurjut, O and Fiorini, M and
              Katzner, S and Busse, L",
  abstract = "Background Neural responses in visual cortex depend not only on
              sensory input but also on behavioral context. One such context is
              locomotion, which modulates single-neuron activity in primary
              visual cortex (V1). How locomotion affects neuronal populations
              across cortical layers and in precortical structures is not well
              understood. Results We performed extracellular multielectrode
              recordings in the visual system of mice during locomotion and
              stationary periods. We found that locomotion influenced activity
              of V1 neurons with a characteristic laminar profile and shaped
              the population response by reducing pairwise correlations.
              Although the reduction of pairwise correlations was restricted to
              cortex, locomotion slightly but consistently increased firing
              rates and controlled tuning selectivity already in the
              dorsolateral geniculate nucleus (dLGN) of the thalamus. At the
              level of the eye, increases in locomotion speed were associated
              with pupil dilation. Conclusions These findings document further,
              nonmultiplicative effects of locomotion, reaching earlier
              processing stages than cortex.",
  journal  = "Curr. Biol.",
  volume   =  24,
  number   =  24,
  pages    = "2899--2907",
  year     =  2014,
  keywords = "netgard;ERC Consolidator 2023"
}

@ARTICLE{Jin2020-wg,
  title    = "Mouse Higher Visual Areas Provide Both Distributed and
              Specialized Contributions to Visually Guided Behaviors",
  author   = "Jin, Miaomiao and Glickfeld, Lindsey L",
  abstract = "Cortical parallel processing streams segregate many diverse
              features of a sensory scene. However, some features are
              distributed across streams, begging the question of whether and
              how such distributed representations contribute to perception. We
              determined the necessity of the primary visual cortex (V1) and
              three key higher visual areas (lateromedial [LM], anterolateral
              [AL], and posteromedial [PM]) for perception of orientation and
              contrast, two features that are robustly encoded across all four
              areas. Suppressing V1, LM, or AL decreased sensitivity for both
              orientation discrimination and contrast detection, consistent
              with a role for these areas in sensory perception. In comparison,
              suppressing PM selectively increased false alarm (FA) rates
              during contrast detection, without any effect on orientation
              discrimination. This effect was not retinotopically specific,
              suggesting that suppression of PM altered sensory integration or
              the decision-making process rather than processing of local
              visual features. Thus, we find that distributed representations
              in the visual system can nonetheless support specialized
              perceptual roles for higher visual cortical areas.",
  journal  = "Curr. Biol.",
  volume   =  30,
  number   =  23,
  pages    = "4682--4692.e7",
  month    =  dec,
  year     =  2020,
  keywords = "contrast; d-prime; decision-making; false alarm; mouse visual
              cortex; optogenetics; orientation; psychophysics; sensory
              processing; speed;4 brainstate;4 mouse;read next;unread;ERC
              Consolidator 2023",
  language = "en"
}

@ARTICLE{Mathis2021-zo,
  title    = "Motor control: Neural correlates of optimal feedback control
              theory",
  author   = "Mathis, Mackenzie W and Schneider, Steffen",
  abstract = "Recent work is revealing neural correlates of a leading theory of
              motor control. By linking an elegant series of behavioral
              experiments with neural inactivation in macaques with
              computational models, a new study shows that premotor and
              parietal areas can be mapped onto a model for optimal feedback
              control.",
  journal  = "Curr. Biol.",
  volume   =  31,
  number   =  7,
  pages    = "R356--R358",
  month    =  apr,
  year     =  2021,
  keywords = "4 behavior;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Prenger2004-qu,
  title    = "Nonlinear {V1} responses to natural scenes revealed by neural
              network analysis",
  author   = "Prenger, Ryan and Wu, Michael C-K and David, Stephen V and
              Gallant, Jack L",
  abstract = "A key goal in the study of visual processing is to obtain a
              comprehensive description of the relationship between visual
              stimuli and neuronal responses. One way to guide the search for
              models is to use a general nonparametric regression algorithm,
              such as a neural network. We have developed a multilayer
              feed-forward network algorithm that can be used to characterize
              nonlinear stimulus-response mapping functions of neurons in
              primary visual cortex (area V1) using natural image stimuli. The
              network is capable of extracting several known V1 response
              properties such as: orientation and spatial frequency tuning, the
              spatial phase invariance of complex cells, and direction
              selectivity. We present details of a method for training networks
              and visualizing their properties. We also compare how well
              conventional explicit models and those developed using neural
              networks can predict novel responses to natural scenes.",
  journal  = "Neural Netw.",
  volume   =  17,
  number   = "5-6",
  pages    = "663--679",
  year     =  2004,
  keywords = "recurrent;system identification;ERC Consolidator 2023"
}

@ARTICLE{Macpherson2021-re,
  title    = "Natural and Artificial Intelligence: A brief introduction to the
              interplay between {AI} and neuroscience research",
  author   = "Macpherson, Tom and Churchland, Anne and Sejnowski, Terry and
              DiCarlo, James and Kamitani, Yukiyasu and Takahashi, Hidehiko and
              Hikida, Takatoshi",
  abstract = "Neuroscience and artificial intelligence (AI) share a long
              history of collaboration. Advances in neuroscience, alongside
              huge leaps in computer processing power over the last few
              decades, have given rise to a new generation of in silico neural
              networks inspired by the architecture of the brain. These AI
              systems are now capable of many of the advanced perceptual and
              cognitive abilities of biological systems, including object
              recognition and decision making. Moreover, AI is now increasingly
              being employed as a tool for neuroscience research and is
              transforming our understanding of brain functions. In particular,
              deep learning has been used to model how convolutional layers and
              recurrent connections in the brain's cerebral cortex control
              important functions, including visual processing, memory, and
              motor control. Excitingly, the use of neuroscience-inspired AI
              also holds great promise for understanding how changes in brain
              networks result in psychopathologies, and could even be utilized
              in treatment regimes. Here we discuss recent advancements in four
              areas in which the relationship between neuroscience and AI has
              led to major advancements in the field; (1) AI models of working
              memory, (2) AI visual processing, (3) AI analysis of big
              neuroscience datasets, and (4) computational psychiatry.",
  journal  = "Neural Netw.",
  volume   =  144,
  pages    = "603--613",
  month    =  dec,
  year     =  2021,
  keywords = "Artificial intelligence; Neuroscience; Neural imaging; Visual
              processing; Working memory; Computational psychiatry;4 behavior;4
              mouse;read;ERC Consolidator 2023"
}

@ARTICLE{Weichwald2015-ff,
  title    = "Causal interpretation rules for encoding and decoding models in
              neuroimaging",
  author   = "Weichwald, Sebastian and Meyer, Timm and {\"O}zdenizci, Ozan and
              Sch{\"o}lkopf, Bernhard and Ball, Tonio and Grosse-Wentrup,
              Moritz",
  abstract = "Causal terminology is often introduced in the interpretation of
              encoding and decoding models trained on neuroimaging data. In
              this article, we investigate which causal statements are
              warranted and which ones are not supported by empirical evidence.
              We argue that the distinction between encoding and decoding
              models is not sufficient for this purpose: relevant features in
              encoding and decoding models carry a different meaning in
              stimulus- and in response-based experimental paradigms.We show
              that only encoding models in the stimulus-based setting support
              unambiguous causal interpretations. By combining encoding and
              decoding models trained on the same data, however, we obtain
              insights into causal relations beyond those that are implied by
              each individual model type. We illustrate the empirical relevance
              of our theoretical findings on EEG data recorded during a
              visuo-motor learning task.",
  journal  = "Neuroimage",
  volume   =  110,
  pages    = "48--59",
  month    =  apr,
  year     =  2015,
  keywords = "Causal inference; Decoding models; Encoding models;
              Interpretation; Pattern recognition;read next;unread;ERC
              Consolidator 2023",
  language = "en"
}

@ARTICLE{Guclu2017-bi,
  title     = "Increasingly complex representations of natural movies across
               the dorsal stream are shared between subjects",
  author    = "G{\"u}{\c c}l{\"u}, U and van Gerven, M A J",
  abstract  = "Recently, deep neural networks (DNNs) have been shown to provide
               accurate predictions of neural responses across the ventral
               visual pathway. We here explore whether they also provide
               accurate predictions of neural responses across the dorsal
               visual pathway, which is thought to be devoted to motion
               processing and action recognition. This is achieved by training
               deep neural networks to recognize actions in videos and
               subsequently using them to predict neural responses while
               subjects are watching natural movies. Moreover, we explore
               whether dorsal stream representations are shared between
               subjects. In order to address this question, we examine if
               individual subject predictions can be made in a common
               representational space estimated via hyperalignment. Results
               show that a DNN trained for action recognition can be used to
               accurately predict how dorsal stream responds to natural movies,
               revealing a correspondence in representations of DNN layers and
               dorsal stream areas. It is also demonstrated that models
               operating in a common representational space can generalize to
               responses of multiple or even unseen individual subjects to
               novel spatio-temporal stimuli in both encoding and decoding
               settings, suggesting that a common representational space
               underlies dorsal stream responses across multiple subjects.",
  journal   = "Neuroimage",
  publisher = "Elsevier Inc.",
  volume    =  145,
  pages     = "329--336",
  year      =  2017,
  keywords  = "Decoding; Deep neural network; Dorsal stream; Encoding;
               Hyperalignment;system identification;ERC Consolidator 2023"
}

@ARTICLE{Touryan2005-pi,
  title    = "Spatial Structure of Complex Cell Receptive Fields Measured with
              Natural Images",
  author   = "Touryan, Jon and Felsen, Gidon and Dan, Yang",
  abstract = "Neuronal receptive fields (RFs) play crucial roles in visual
              processing. While the linear RFs of early neurons have been well
              studied, RFs of cortical complex cells are nonlinear and
              therefore difficult to characterize, especially in the context of
              natural stimuli. In this study, we used a nonlinear technique to
              compute the RFs of complex cells from their responses to natural
              images. We found that each RF is well described by a small number
              of subunits, which are oriented, localized, and bandpass. These
              subunits contribute to neuronal responses in a
              contrast-dependent, polarity-invariant manner, and they can
              largely predict the orientation and spatial frequency tuning of
              the cell. Although the RF structures measured with natural images
              were similar to those measured with random stimuli, natural
              images were more effective for driving complex cells, thus
              facilitating rapid identification of the subunits. The subunit RF
              model provides a useful basis for understanding cortical
              processing of natural stimuli.",
  journal  = "Neuron",
  volume   =  45,
  number   =  5,
  pages    = "781--791",
  year     =  2005,
  keywords = "read;recurrent;ERC Consolidator 2023"
}

@ARTICLE{Rust2005-ro,
  title     = "Spatiotemporal elements of macaque v1 receptive fields",
  author    = "Rust, Nicole C and Schwartz, Odelia and Movshon, J Anthony and
               Simoncelli, Eero P",
  abstract  = "Neurons in primary visual cortex (V1) are commonly classified as
               simple or complex based upon their sensitivity to the sign of
               stimulus contrast. The responses of both cell types can be
               described by a general model in which the outputs of a set of
               linear filters are nonlinearly combined. We estimated the model
               for a population of V1 neurons by analyzing the mean and
               covariance of the spatiotemporal distribution of random bar
               stimuli that were associated with spikes. This analysis reveals
               an unsuspected richness of neuronal computation within V1.
               Specifically, simple and complex cell responses are best
               described using more linear filters than the one or two found in
               standard models. Many filters revealed by the model contribute
               suppressive signals that appear to have a predominantly divisive
               influence on neuronal firing. Suppressive signals are especially
               potent in direction-selective cells, where they reduce responses
               to stimuli moving in the nonpreferred direction.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  46,
  number    =  6,
  pages     = "945--956",
  year      =  2005,
  keywords  = "Orientation Selectivity;GLM and DN;contrast gain control;ERC
               Consolidator 2023"
}

@ARTICLE{Bezdudnaya2006-ge,
  title    = "Thalamic Burst Mode and Inattention in the Awake {LGNd}",
  author   = "Bezdudnaya, Tatiana and Cano, Monica and Bereshpolova, Yulia and
              Stoelzel, Carl R and Alonso, Jose-Manuel and Swadlow, Harvey A",
  abstract = "Summary Awake mammals are often inattentive in familiar
              environments, but must still respond appropriately to relevant
              visual stimulation. Such ``inattentive vision'' has received
              little study, perhaps due to difficulties in controlling eye
              position in this state. In rabbits, eye position is exceedingly
              stable in both alert and inattentive states. Here, we exploit
              this stability to examine temporal filtering of visual
              information in LGNd neurons as rabbits alternate between
              EEG-defined states. Within a single second of shifting from alert
              to an inattentive state, both peak temporal frequency and
              bandwidth were sharply reduced, and burst frequency increased
              dramatically. However, spatial dimensions of receptive field
              centers showed no significant state dependence. We conclude that
              extremely rapid and significant changes in temporal filtering and
              bursting occur in the LGNd as awake subjects shift between alert
              and inattentive states.",
  journal  = "Neuron",
  volume   =  49,
  number   =  3,
  pages    = "421--432",
  month    =  feb,
  year     =  2006,
  keywords = "SYSNEURO;4 behavior;4 brainstate;read next;unread;ERC
              Consolidator 2023"
}

@ARTICLE{Niell2010-bs,
  title     = "Modulation of Visual Responses by Behavioral State in Mouse
               Visual Cortex",
  author    = "Niell, Cristopher M and Stryker, Michael P",
  abstract  = "Studies of visual processing in rodents have conventionally been
               performed on anesthetized animals, precluding examination of the
               effects of behavior on visually evoked responses. We have now
               studied the response properties of neurons in primary visual
               cortex of awake mice that were allowed to run on a freely
               rotating spherical treadmill with their heads fixed. Most
               neurons showed more than a doubling of visually evoked firing
               rate as the animal transitioned from standing still to running,
               without changes in spontaneous firing or stimulus selectivity.
               Tuning properties in the awake animal were similar to those
               measured previously in anesthetized animals. Response magnitude
               in the lateral geniculate nucleus did not increase with
               locomotion, demonstrating that the striking change in
               responsiveness did not result from peripheral effects at the
               eye. Interestingly, some narrow-spiking cells were spontaneously
               active during running but suppressed by visual stimuli. These
               results demonstrate powerful cell-type-specific modulation of
               visual processing by behavioral state in awake mice.
               \copyright{} 2010 Elsevier Inc. All rights reserved.",
  journal   = "Neuron",
  publisher = "Elsevier Ltd",
  volume    =  65,
  number    =  4,
  pages     = "472--479",
  year      =  2010,
  keywords  = "SYSNEURO;system identification;brain state;SFB 1456 Mathematic
               of Experiment;ERC Consolidator 2023"
}

@ARTICLE{Franklin2011-lr,
  title    = "Computational mechanisms of sensorimotor control",
  author   = "Franklin, David W and Wolpert, Daniel M",
  abstract = "In order to generate skilled and efficient actions, the motor
              system must find solutions to several problems inherent in
              sensorimotor control, including nonlinearity, nonstationarity,
              delays, redundancy, uncertainty, and noise. We review these
              problems and five computational mechanisms that the brain may use
              to limit their deleterious effects: optimal feedback control,
              impedance control, predictive control, Bayesian decision theory,
              and sensorimotor learning. Together, these computational
              mechanisms allow skilled and fluent sensorimotor behavior.",
  journal  = "Neuron",
  volume   =  72,
  number   =  3,
  pages    = "425--442",
  month    =  nov,
  year     =  2011,
  keywords = "4 behavior;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Andermann2011-vw,
  title    = "Functional specialization of mouse higher visual cortical areas",
  author   = "Andermann, Mark L and Kerlin, Aaron M and Roumis, Demetris K and
              Glickfeld, Lindsey L and Reid, R Clay",
  abstract = "The mouse is emerging as an important model for understanding how
              sensory neocortex extracts cues to guide behavior, yet little is
              known about how these cues are processed beyond primary cortical
              areas. Here, we used two-photon calcium imaging in awake mice to
              compare visual responses in primary visual cortex (V1) and in two
              downstream target areas, AL and PM. Neighboring V1 neurons had
              diverse stimulus preferences spanning five octaves in spatial and
              temporal frequency. By contrast, AL and PM neurons responded best
              to distinct ranges of stimulus parameters. Most strikingly, AL
              neurons preferred fast-moving stimuli while PM neurons preferred
              slow-moving stimuli. By contrast, neurons in V1, AL, and PM
              demonstrated similar selectivity for stimulus orientation but not
              for stimulus direction. Based on these findings, we predict that
              area AL helps guide behaviors involving fast-moving stimuli
              (e.g., optic flow), while area PM helps guide behaviors involving
              slow-moving objects.",
  journal  = "Neuron",
  volume   =  72,
  number   =  6,
  pages    = "1025--1039",
  month    =  dec,
  year     =  2011,
  keywords = "4 behavior;4 mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Bennett2013-rk,
  title    = "Subthreshold mechanisms underlying state-dependent modulation of
              visual responses",
  author   = "Bennett, Corbett and Arroyo, Sergio and Hestrin, Shaul",
  abstract = "The processing of sensory information varies widely across
              behavioral states. However, little is known about how behavioral
              states modulate the intracellular activity of cortical neurons to
              effect changes in sensory responses. Here, we performed
              whole-cell recordings from neurons in upper-layer primary visual
              cortex of awake mice during locomotion and quiet wakefulness. We
              found that the signal-to-noise ratio for sensory responses was
              improved during locomotion by two mechanisms: (1) a decrease in
              membrane potential variability leading to a reduction in
              background firing rates and (2) an enhancement in the amplitude
              and reliability of visually evoked subthreshold responses
              mediated by an increase in total conductance and a depolarization
              of the stimulus-evoked reversal potential. Consistent with the
              enhanced signal-to-noise ratio for visual responses during
              locomotion, we demonstrate that performance is improved in a
              visual detection task during this behavioral state.",
  journal  = "Neuron",
  volume   =  80,
  number   =  2,
  pages    = "350--357",
  month    =  oct,
  year     =  2013,
  keywords = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Vinck2015-wy,
  title     = "Arousal and locomotion make distinct contributions to cortical
               activity patterns and visual encoding",
  author    = "Vinck, Martin and Batista-Brito, Renata and Knoblich, Ulf and
               Cardin, Jessica A",
  abstract  = "Spontaneous and sensory-evoked cortical activity is highly
               state-dependent, yet relatively little is known about
               transitions between distinct waking states. Patterns of activity
               in mouse V1 differ dramatically between quiescence and
               locomotion, but this difference could be explained by either
               motor feedback or a change in arousal levels. We recorded single
               cells and local field potentials from area V1 in mice head-fixed
               on a running wheel and monitored pupil diameter to assay
               arousal. Using naturally occurring and induced state
               transitions, we dissociated arousal and locomotion effects in
               V1. Arousal suppressed spontaneous firing and strongly altered
               the temporal patterning of population activity. Moreover,
               heightened arousal increased the signal-to-noise ratio of visual
               responses and reduced noise correlations. In contrast, increased
               firing in anticipation of and during movement was attributable
               to locomotion effects. Our findings suggest complementary roles
               of arousal and locomotion in promoting functional flexibility in
               cortical circuits.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  86,
  number    =  3,
  pages     = "740--754",
  month     =  may,
  year      =  2015,
  keywords  = "4 behavior;read next;unread;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Wiltschko2015-ey,
  title    = "Mapping {Sub-Second} Structure in Mouse Behavior",
  author   = "Wiltschko, Alexander B and Johnson, Matthew J and Iurilli,
              Giuliano and Peterson, Ralph E and Katon, Jesse M and Pashkovski,
              Stan L and Abraira, Victoria E and Adams, Ryan P and Datta,
              Sandeep Robert",
  abstract = "Complex animal behaviors are likely built from simpler modules,
              but their systematic identification in mammals remains a
              significant challenge. Here we use depth imaging to show that 3D
              mouse pose dynamics are structured at the sub-second timescale.
              Computational modeling of these fast dynamics effectively
              describes mouse behavior as a series of reused and stereotyped
              modules with defined transition probabilities. We demonstrate
              this combined 3D imaging and machine learning method can be used
              to unmask potential strategies employed by the brain to adapt to
              the environment, to capture both predicted and previously hidden
              phenotypes caused by genetic or neural manipulations, and to
              systematically expose the global structure of behavior within an
              experiment. This work reveals that mouse body language is built
              from identifiable components and is organized in a predictable
              fashion; deciphering this language establishes an objective
              framework for characterizing the influence of environmental cues,
              genes and neural activity on behavior.",
  journal  = "Neuron",
  volume   =  88,
  number   =  6,
  pages    = "1121--1135",
  month    =  dec,
  year     =  2015,
  keywords = "4 behavior;not read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Semedo2019-ll,
  title    = "Cortical Areas Interact through a Communication Subspace",
  author   = "Semedo, Jo{\~a}o D and Zandvakili, Amin and Machens, Christian K
              and Yu, Byron M and Kohn, Adam",
  abstract = "Most brain functions involve interactions among multiple,
              distinct areas or nuclei. For instance, visual processing in
              primates requires the appropriate relaying of signals across many
              distinct cortical areas. Yet our understanding of how populations
              of neurons in interconnected brain areas communicate is in its
              infancy. Here we investigate how trial-to-trial fluctuations of
              population responses in primary visual cortex (V1) are related to
              simultaneously recorded population responses in area V2. Using
              dimensionality reduction methods, we find that V1-V2 interactions
              occur through a communication subspace: V2 fluctuations are
              related to a small subset of V1 population activity patterns,
              distinct from the largest fluctuations shared among neurons
              within V1. In contrast, interactions between subpopulations
              within V1 are less selective. We propose that the communication
              subspace may be a general, population-level mechanism by which
              activity can be selectively routed across brain areas.",
  journal  = "Neuron",
  volume   =  102,
  number   =  1,
  pages    = "249--259.e4",
  year     =  2019,
  keywords = "unread;primate vision;ERC Consolidator 2023"
}

@ARTICLE{Datta2019-qj,
  title    = "Computational Neuroethology: A Call to Action",
  author   = "Datta, Sandeep Robert and Anderson, David J and Branson, Kristin
              and Perona, Pietro and Leifer, Andrew",
  abstract = "The brain is worthy of study because it is in charge of behavior.
              A flurry of recent technical advances in measuring and
              quantifying naturalistic behaviors provide an important
              opportunity for advancing brain science. However, the problem of
              understanding unrestrained behavior in the context of neural
              recordings and manipulations remains unsolved, and developing
              approaches to addressing this challenge is critical. Here we
              discuss considerations in computational neuroethology---the
              science of quantifying naturalistic behaviors for understanding
              the brain---and propose strategies to evaluate progress. We point
              to open questions that require resolution and call upon the
              broader systems neuroscience community to further develop and
              leverage measures of naturalistic, unrestrained behavior, which
              will enable us to more effectively probe the richness and
              complexity of the brain.",
  journal  = "Neuron",
  volume   =  104,
  number   =  1,
  pages    = "11--24",
  month    =  oct,
  year     =  2019,
  keywords = "read;4 behavior;requires action;ERC Consolidator 2023"
}

@ARTICLE{Voigts2019-sv,
  title    = "Somatic and Dendritic Encoding of Spatial Variables in
              Retrosplenial Cortex Differs during {2D} Navigation",
  author   = "Voigts, Jakob and Harnett, Mark T",
  abstract = "Active amplification of organized synaptic inputs in dendrites
              can endow individual neurons with the ability to perform complex
              computations. However, whether dendrites in behaving animals
              perform independent local computations is not known. Such
              activity may be particularly important for complex behavior,
              where neurons integrate multiple streams of information.
              Head-restrained imaging has yielded important insights into
              cellular and circuit function, but this approach limits behavior
              and the underlying computations. We describe a method for
              full-featured 2-photon imaging in awake mice during free
              locomotion with volitional head rotation. We examine head
              direction and position encoding in simultaneously imaged apical
              tuft dendrites and their respective cell bodies in retrosplenial
              cortex, an area that encodes multi-modal navigational
              information. Activity in dendrites was not determined solely by
              somatic activity but reflected distinct navigational variables,
              fulfilling the requirements for dendritic computation. Our
              approach provides a foundation for studying sub-cellular
              processes during complex behaviors.",
  journal  = "Neuron",
  year     =  2019,
  keywords = "unread;4 topics;ERC Consolidator 2023"
}

@ARTICLE{Schroder2020-jl,
  title    = "Arousal Modulates Retinal Output",
  author   = "Schr{\"o}der, Sylvia and Steinmetz, Nicholas A and Krumin,
              Michael and Pachitariu, Marius and Rizzi, Matteo and Lagnado,
              Leon and Harris, Kenneth D and Carandini, Matteo",
  abstract = "Summary At various stages of the visual system, visual responses
              are modulated by arousal. Here, we find that in mice this
              modulation operates as early as in the first synapse from the
              retina and even in retinal axons. To measure retinal activity in
              the awake, intact brain, we imaged the synaptic boutons of
              retinal axons in the superior colliculus. Their activity depended
              not only on vision but also on running speed and pupil size,
              regardless of retinal illumination. Arousal typically reduced
              their visual responses and selectivity for direction and
              orientation. Recordings from retinal axons in the optic tract
              revealed that arousal modulates the firing of some retinal
              ganglion cells. Arousal had similar effects postsynaptically in
              colliculus neurons, independent of activity in the other main
              source of visual inputs to the colliculus, the primary visual
              cortex. These results indicate that arousal modulates activity at
              every stage of the mouse visual system.",
  journal  = "Neuron",
  volume   =  107,
  number   =  3,
  pages    = "487--495.e9",
  month    =  aug,
  year     =  2020,
  keywords = "vision; retina; arousal; locomotion; superior colliculus;4
              behavior;4 brainstate;read next;unread;ERC Consolidator 2023"
}

@ARTICLE{Kao2021-yf,
  title    = "Optimal anticipatory control as a theory of motor preparation: A
              thalamo-cortical circuit model",
  author   = "Kao, Ta-Chu and Sadabadi, Mahdieh S and Hennequin, Guillaume",
  abstract = "Across a range of motor and cognitive tasks, cortical activity
              can be accurately described by low-dimensional dynamics unfolding
              from specific initial conditions on every trial. These
              ``preparatory states'' largely determine the subsequent evolution
              of both neural activity and behavior, and their importance raises
              questions regarding how they are, or ought to be, set. Here, we
              formulate motor preparation as optimal anticipatory control of
              future movements and show that the solution requires a form of
              internal feedback control of cortical circuit dynamics. In
              contrast to a simple feedforward strategy, feedback control
              enables fast movement preparation by selectively controlling the
              cortical state in the small subspace that matters for the
              upcoming movement. Feedback but not feedforward control explains
              the orthogonality between preparatory and movement activity
              observed in reaching monkeys. We propose a circuit model in which
              optimal preparatory control is implemented as a thalamo-cortical
              loop gated by the basal ganglia.",
  journal  = "Neuron",
  volume   =  109,
  number   =  9,
  pages    = "1567--1581.e12",
  month    =  may,
  year     =  2021,
  keywords = "manifold; movement preparation; neural circuits; neural
              population dynamics; nullspace; optimal control; thalamo-cortical
              loop;4 behavior;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Parker2022-ac,
  title    = "Joint coding of visual input and eye/head position in {V1} of
              freely moving mice",
  author   = "Parker, Philip R L and Abe, Elliott T T and Leonard, Emmalyn S P
              and Martins, Dylan M and Niell, Cristopher M",
  abstract = "Visual input during natural behavior is highly dependent on
              movements of the eyes and head, but how information about eye and
              head position is integrated with visual processing during free
              movement is unknown, as visual physiology is generally performed
              under head fixation. To address this, we performed single-unit
              electrophysiology in V1 of freely moving mice while
              simultaneously measuring the mouse's eye position, head
              orientation, and the visual scene from the mouse's perspective.
              From these measures, we mapped spatiotemporal receptive fields
              during free movement based on the gaze-corrected visual input.
              Furthermore, we found a significant fraction of neurons tuned for
              eye and head position, and these signals were integrated with
              visual responses through a multiplicative mechanism in the
              majority of modulated neurons. These results provide new insight
              into coding in the mouse V1 and, more generally, provide a
              paradigm for investigating visual physiology under natural
              conditions, including active sensing and ethological behavior.",
  journal  = "Neuron",
  volume   =  110,
  number   =  23,
  pages    = "3897--3906.e5",
  month    =  dec,
  year     =  2022,
  keywords = "ecological perception; gain modulation; receptive fields; visual
              cortex; visual physiology;4 behavior;4 mouse;requires
              action;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Parker2020-jz,
  title    = "{Movement-Related} Signals in Sensory Areas: Roles in Natural
              Behavior",
  author   = "Parker, Philip R L and Brown, Morgan A and Smear, Matthew C and
              Niell, Cristopher M",
  abstract = "Recent studies have demonstrated prominent and widespread
              movement-related signals in the brain of head-fixed mice, even in
              primary sensory areas. However, it is still unknown what role
              these signals play in sensory processing. Why are these sensory
              areas `contaminated' by movement signals? During natural
              behavior, animals actively acquire sensory information as they
              move through the environment and use this information to guide
              ongoing actions. In this context, movement-related signals could
              allow sensory systems to predict self-induced sensory changes and
              extract additional information about the environment. In this
              review we summarize recent findings on the presence of
              movement-related signals in sensory areas and discuss how their
              study, in the context of natural freely moving behaviors, could
              advance models of sensory processing.",
  journal  = "Trends Neurosci.",
  year     =  2020,
  keywords = "unread;read next;behavior;ERC Consolidator 2023"
}

@ARTICLE{Zipser1988-nh,
  title    = "A back-propagation programmed network that simulates response
              properties of a subset of posterior parietal neurons",
  author   = "Zipser, David and Andersen, Richard A",
  abstract = "Neurons in area 7a of the posterior parietal cortex of monkeys
              respond to both the retinal location of a visual stimulus and the
              position of the eyes and by combining these signals represent the
              spatial location of external objects. A neural network model,
              programmed using back-propagation learning, can decode this
              spatial information from area 7a neurons and accounts for their
              observed response properties.",
  journal  = "Nature",
  volume   =  331,
  number   =  6158,
  pages    = "679--684",
  year     =  1988,
  keywords = "system identification;recurrent;system identification;ERC
              Consolidator 2023"
}

@ARTICLE{Treue1996-lp,
  title     = "Attentional modulation of visual motion processing in cortical
               areas {MT} and {MST}",
  author    = "Treue, Stefan and Maunsell, John H R",
  abstract  = "THE visual system is constantly inundated with information
               received by the eyes, only a fraction of which seems to reach
               visual awareness. This selection process is one of the functions
               ascribed to visual attention1--6. Although many studies have
               investigated the role of attention in shaping neuronal
               representations in the visual cortex, few have focused on
               attentional modulation of neuronal signals related to visual
               motion. Here we report that the responses of direction-selective
               neurons in monkey visual cortex are greatly influenced by
               attention, and that this modulation occurs as early in the
               cortical hierarchy as the level of the middle temporal visual
               area (MT). Our finding demonstrates a stronger and earlier
               influence of attention on motion processing along the dorsal
               visual pathway than previously recognized.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  382,
  number    =  6591,
  pages     = "539--541",
  month     =  aug,
  year      =  1996,
  keywords  = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Pillow2008-me,
  title    = "Spatio-temporal correlations and visual signalling in a complete
              neuronal population",
  author   = "Pillow, Jonathan W and Shlens, Jonathon and Paninski, Liam and
              Sher, Alexander and Litke, Alan M and Chichilnisky, E J and
              Simoncelli, Eero P",
  abstract = "Correlated activity between sensory neurons governs both the
              stimulus information conveyed by a neural population and how
              downstream neurons can extract it. Although previous studies
              looking at pairs of cells have examined correlations, their
              functional origin and impact on the neural code are still not
              understood. Pillow et al. address the question in a complete
              population of primate retinal ganglion cells. Fitting the
              physiological data to a model of multi-neuron spike responses,
              the authors find that a significant fraction of what is usually
              considered single-cell noise in trial-to-trial response
              variability can be explained by correlations, and that a
              significant amount of sensory information can be decoded from the
              correlation structure. The functional significance of correlated
              firing in a complete population of macaque parasol retinal
              ganglion cells using a model of multi-neuron spike responses is
              analysed. Fitting the physiological data to a model of
              multi-neuron spike responses, it is found that a significant
              fraction of what is usually considered single-cell noise in
              trial-to-trial response variability can be explained by
              correlations, and that a significant amount of sensory
              information can be decoded from the correlation structure.
              Statistical dependencies in the responses of sensory neurons
              govern both the amount of stimulus information conveyed and the
              means by which downstream neurons can extract it. Although a
              variety of measurements indicate the existence of such
              dependencies1,2,3, their origin and importance for neural coding
              are poorly understood. Here we analyse the functional
              significance of correlated firing in a complete population of
              macaque parasol retinal ganglion cells using a model of
              multi-neuron spike responses4,5. The model, with parameters fit
              directly to physiological data, simultaneously captures both the
              stimulus dependence and detailed spatio-temporal correlations in
              population responses, and provides two insights into the
              structure of the neural code. First, neural encoding at the
              population level is less noisy than one would expect from the
              variability of individual neurons: spike times are more precise,
              and can be predicted more accurately when the spiking of
              neighbouring neurons is taken into account. Second, correlations
              provide additional sensory information: optimal, model-based
              decoding that exploits the response correlation structure
              extracts 20\% more information about the visual scene than
              decoding under the assumption of independence, and preserves 40\%
              more visual information than optimal linear decoding6. This
              model-based approach reveals the role of correlated activity in
              the retinal coding of visual stimuli, and provides a general
              framework for understanding the importance of correlated activity
              in populations of neurons.",
  journal  = "Nature",
  volume   =  454,
  number   =  7207,
  pages    = "995--999",
  year     =  2008,
  keywords = "read;system identification;microns;ERC Consolidator 2023"
}

@ARTICLE{Kao2015-aa,
  title     = "Single-trial dynamics of motor cortex and their applications to
               brain-machine interfaces",
  author    = "Kao, Jonathan C and Nuyujukian, Paul and Ryu, Stephen I and
               Churchland, Mark M and Cunningham, John P and Shenoy, Krishna V",
  abstract  = "Increasing evidence suggests that neural population responses
               have their own internal drive, or dynamics, that describe how
               the neural population evolves through time. An important
               prediction of neural dynamical models is that previously
               observed neural activity is informative of noisy
               yet-to-be-observed activity on single-trials, and may thus have
               a denoising effect. To investigate this prediction, we built and
               characterized dynamical models of single-trial motor cortical
               activity. We find these models capture salient dynamical
               features of the neural population and are informative of future
               neural activity on single trials. To assess how neural dynamics
               may beneficially denoise single-trial neural activity, we
               incorporate neural dynamics into a brain-machine interface
               (BMI). In online experiments, we find that a neural dynamical
               BMI achieves substantially higher performance than its
               non-dynamical counterpart. These results provide evidence that
               neural dynamics beneficially inform the temporal evolution of
               neural activity on single trials and may directly impact the
               performance of BMIs.",
  journal   = "Nat. Commun.",
  publisher = "Nature Publishing Group",
  volume    =  6,
  number    = "May",
  year      =  2015,
  keywords  = "unread;brain state;ERC Consolidator 2023"
}

@ARTICLE{Maimon2010-sa,
  title     = "Active flight increases the gain of visual motion processing in
               Drosophila",
  author    = "Maimon, Gaby and Straw, Andrew D and Dickinson, Michael H",
  abstract  = "This paper reports the first recording from brain neurons of
               flying Drosophila. The responses of visual interneurons to
               moving grate stimuli were substantially modulated by flight, as
               compared with the resting situation. We developed a technique
               for performing whole-cell patch-clamp recordings from
               genetically identified neurons in behaving Drosophila. We
               focused on the properties of visual interneurons during tethered
               flight, but this technique generalizes to different cell types
               and behaviors. We found that the peak-to-peak responses of a
               class of visual motion--processing interneurons, the
               vertical-system visual neurons (VS cells), doubled when flies
               were flying compared with when they were at rest. Thus, the gain
               of the VS cells is not fixed, but is instead behaviorally
               flexible and changes with locomotor state. Using voltage clamp,
               we found that the passive membrane resistance of VS cells was
               reduced during flight, suggesting that the elevated gain was a
               result of increased synaptic drive from upstream
               motion-sensitive inputs. The ability to perform patch-clamp
               recordings in behaving Drosophila promises to help unify the
               understanding of behavior at the gene, cell and circuit levels.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  volume    =  13,
  number    =  3,
  pages     = "393--399",
  month     =  feb,
  year      =  2010,
  keywords  = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Saleem2013-fx,
  title    = "Integration of visual motion and locomotion in mouse visual
              cortex",
  author   = "Saleem, Aman B and Ayaz, Asl{\i} Asli and Jeffery, Kathryn J and
              Harris, Kenneth D and Carandini, Matteo",
  abstract = "The primary visual cortex (V1) carries signals related to visual
              speed, and its responses are also affected by run speed. Here the
              authors report that nearly half of the V1 neurons were reliably
              driven by combinations of visual speed and run speed. As a
              population, V1 neurons predicted a linear combination of visual
              and run speed better than visual or run speeds alone. Successful
              navigation through the world requires accurate estimation of
              one's own speed. To derive this estimate, animals integrate
              visual speed gauged from optic flow and run speed gauged from
              proprioceptive and locomotor systems. The primary visual cortex
              (V1) carries signals related to visual speed, and its responses
              are also affected by run speed. To study how V1 combines these
              signals during navigation, we recorded from mice that traversed a
              virtual environment. Nearly half of the V1 neurons were reliably
              driven by combinations of visual speed and run speed. These
              neurons performed a weighted sum of the two speeds. The weights
              were diverse across neurons, and typically positive. As a
              population, V1 neurons predicted a linear combination of visual
              and run speeds better than either visual or run speeds alone.
              These data indicate that V1 in the mouse participates in a
              multimodal processing system that integrates visual motion and
              locomotion during navigation.",
  journal  = "Nat. Neurosci.",
  volume   =  16,
  number   =  12,
  pages    = "1864--1869",
  year     =  2013,
  keywords = "unread;rodent vision;brain state;ERC Consolidator 2023"
}

@ARTICLE{Yamins2016-ob,
  title    = "Using goal-driven deep learning models to understand sensory
              cortex",
  author   = "Yamins, Daniel L K and DiCarlo, James J",
  abstract = "Fueled by innovation in the computer vision and artificial
              intelligence communities, recent developments in computational
              neuroscience have used goal-driven hierarchical convolutional
              neural networks (HCNNs) to make strides in modeling neural
              single-unit and population responses in higher visual cortical
              areas. In this Perspective, we review the recent progress in a
              broader modeling context and describe some of the key technical
              innovations that have supported it. We then outline how the
              goal-driven HCNN approach can be used to delve even more deeply
              into understanding the development and organization of sensory
              cortical processing.",
  journal  = "Nat. Neurosci.",
  volume   =  19,
  number   =  3,
  pages    = "356--365",
  month    =  mar,
  year     =  2016,
  keywords = "read;microns;system identification;2021 Reconstruction;ERC
              Consolidator 2023",
  language = "en"
}

@ARTICLE{Todorov2004-yb,
  title     = "Optimality principles in sensorimotor control",
  author    = "Todorov, Emanuel",
  abstract  = "The sensorimotor system is a product of evolution, development,
               learning and adaptation---which work on different time scales to
               improve behavioral performance. Consequently, many theories of
               motor function are based on 'optimal performance': they quantify
               task goals as cost functions, and apply the sophisticated tools
               of optimal control theory to obtain detailed behavioral
               predictions. The resulting models, although not without
               limitations, have explained more empirical phenomena than any
               other class. Traditional emphasis has been on optimizing desired
               movement trajectories while ignoring sensory feedback. Recent
               work has redefined optimality in terms of feedback control laws,
               and focused on the mechanisms that generate behavior online.
               This approach has allowed researchers to fit previously
               unrelated concepts and observations into what may become a
               unified theoretical framework for interpreting motor function.
               At the heart of the framework is the relationship between
               high-level goals, and the real-time sensorimotor control
               strategies most suitable for accomplishing those goals.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  volume    =  7,
  number    =  9,
  pages     = "907--915",
  month     =  aug,
  year      =  2004,
  keywords  = "4 behavior;read;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Todorov2002-xj,
  title    = "Optimal feedback control as a theory of motor coordination",
  author   = "Todorov, Emanuel and Jordan, Michael I",
  abstract = "A central problem in motor control is understanding how the many
              biomechanical degrees of freedom are coordinated to achieve a
              common goal. An especially puzzling aspect of coordination is
              that behavioral goals are achieved reliably and repeatedly with
              movements rarely reproducible in their detail. Existing
              theoretical frameworks emphasize either goal achievement or the
              richness of motor variability, but fail to reconcile the two.
              Here we propose an alternative theory based on stochastic optimal
              feedback control. We show that the optimal strategy in the face
              of uncertainty is to allow variability in redundant
              (task-irrelevant) dimensions. This strategy does not enforce a
              desired trajectory, but uses feedback more intelligently,
              correcting only those deviations that interfere with task goals.
              From this framework, task-constrained variability, goal-directed
              corrections, motor synergies, controlled parameters, simplifying
              rules and discrete coordination modes emerge naturally. We
              present experimental results from a range of motor tasks to
              support this theory.",
  journal  = "Nat. Neurosci.",
  volume   =  5,
  number   =  11,
  pages    = "1226--1235",
  month    =  nov,
  year     =  2002,
  keywords = "4 behavior;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Franke2022-do,
  title    = "State-dependent pupil dilation rapidly shifts visual feature
              selectivity",
  author   = "Franke, Katrin and Willeke, Konstantin F and Ponder, Kayla and
              Galdamez, Mario and Zhou, Na and Muhammad, Taliah and Patel,
              Saumil and Froudarakis, Emmanouil and Reimer, Jacob and Sinz,
              Fabian H and Tolias, Andreas S",
  abstract = "To increase computational flexibility, the processing of sensory
              inputs changes with behavioural context. In the visual system,
              active behavioural states characterized by motor activity and
              pupil dilation1,2 enhance sensory responses, but typically leave
              the preferred stimuli of neurons unchanged2-9. Here we find that
              behavioural state also modulates stimulus selectivity in the
              mouse visual cortex in the context of coloured natural scenes.
              Using population imaging in behaving mice, pharmacology and deep
              neural network modelling, we identified a rapid shift in colour
              selectivity towards ultraviolet stimuli during an active
              behavioural state. This was exclusively caused by state-dependent
              pupil dilation, which resulted in a dynamic switch from rod to
              cone photoreceptors, thereby extending their role beyond night
              and day vision. The change in tuning facilitated the decoding of
              ethological stimuli, such as aerial predators against the
              twilight sky10. For decades, studies in neuroscience and
              cognitive science have used pupil dilation as an indirect measure
              of brain state. Our data suggest that, in addition,
              state-dependent pupil dilation itself tunes visual
              representations to behavioural demands by differentially
              recruiting rods and cones on fast timescales.",
  journal  = "Nature",
  volume   =  610,
  number   =  7930,
  pages    = "128--134",
  month    =  oct,
  year     =  2022,
  keywords = "read;own;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Mathis2018-lk,
  title     = "{DeepLabCut}: markerless pose estimation of user-defined body
               parts with deep learning",
  author    = "Mathis, A and Mamidanna, P and Cury, K M and Abe, T and Murthy,
               V N and Mathis, M W and Bethge, M",
  journal   = "Nat. Neurosci.",
  publisher = "Springer US",
  volume    =  21,
  number    =  9,
  pages     = "1281--1289",
  year      =  2018,
  keywords  = "\_imported;ERC Consolidator 2023"
}

@ARTICLE{Clancy2019-ta,
  title     = "Locomotion-dependent remapping of distributed cortical networks",
  author    = "Clancy, Kelly B and Orsolic, Ivana and Mrsic-Flogel, Thomas D",
  abstract  = "The interactions between neocortical areas are fluid and
               state-dependent, but how individual neurons couple to
               cortex-wide network dynamics remains poorly understood. We
               correlated the spiking of neurons in primary visual (V1) and
               retrosplenial (RSP) cortex to activity across dorsal cortex,
               recorded simultaneously by widefield calcium imaging. Neurons
               were correlated with distinct and reproducible patterns of
               activity across the cortical surface; while some fired
               predominantly with their local area, others coupled to activity
               in distal areas. The extent of distal coupling was predicted by
               how strongly neurons correlated with the local network. Changes
               in brain state triggered by locomotion strengthened affiliations
               of V1 neurons with higher visual and motor areas, while
               strengthening distal affiliations of RSP neurons with sensory
               cortices. Thus, the diverse coupling of individual neurons to
               cortex-wide activity patterns is restructured by running in an
               area-specific manner, resulting in a shift in the mode of
               cortical processing during locomotion.",
  journal   = "Nat. Neurosci.",
  publisher = "Springer US",
  year      =  2019,
  keywords  = "unread;brain state;ERC Consolidator 2023"
}

@ARTICLE{Musall2019-kd,
  title     = "Single-trial neural dynamics are dominated by richly varied
               movements",
  author    = "Musall, Simon and Kaufman, Matthew T and Juavinett, Ashley L and
               Gluf, Steven and Churchland, Anne K",
  abstract  = "When experts are immersed in a task, do their brains prioritize
               task-related activity? Most efforts to understand neural
               activity during well-learned tasks focus on cognitive
               computations and task-related movements. We wondered whether
               task-performing animals explore a broader movement landscape and
               how this impacts neural activity. We characterized movements
               using video and other sensors and measured neural activity using
               widefield and two-photon imaging. Cortex-wide activity was
               dominated by movements, especially uninstructed movements not
               required for the task. Some uninstructed movements were aligned
               to trial events. Accounting for them revealed that neurons with
               similar trial-averaged activity often reflected utterly
               different combinations of cognitive and movement variables.
               Other movements occurred idiosyncratically, accounting for
               trial-by-trial fluctuations that are often considered `noise'.
               This held true throughout task-learning and for extracellular
               Neuropixels recordings that included subcortical areas. Our
               observations argue that animals execute expert decisions while
               performing richly varied, uninstructed movements that profoundly
               shape neural activity. The authors use a linear model to reveal
               how neural activity patterns are related to cognition or
               movements. They find that uninstructed movements dominate
               single-cell and population activity throughout the brain,
               outpacing task-related activity.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  volume    =  22,
  number    =  10,
  pages     = "1677--1686",
  month     =  sep,
  year      =  2019,
  keywords  = "4 behavior;4 mouse;read;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Walker2019-yw,
  title     = "Inception loops discover what excites neurons most using deep
               predictive models",
  author    = "Walker, E Y and Sinz, F H and Cobos, E and Muhammad, T and
               Froudarakis, E and Fahey, P G and Ecker, A S and Reimer, J and
               Pitkow, X and Tolias, A S",
  abstract  = "Finding sensory stimuli that drive neurons optimally is central
               to understanding information processing in the brain. However,
               optimizing sensory input is difficult due to the predominantly
               nonlinear nature of sensory processing and high dimensionality
               of the input. We developed `inception loops', a closed-loop
               experimental paradigm combining in vivo recordings from
               thousands of neurons with in silico nonlinear response modeling.
               Our end-to-end trained, deep-learning-based model predicted
               thousands of neuronal responses to arbitrary, new natural input
               with high accuracy and was used to synthesize optimal
               stimuli---most exciting inputs (MEIs). For mouse primary visual
               cortex (V1), MEIs exhibited complex spatial features that
               occurred frequently in natural scenes but deviated strikingly
               from the common notion that Gabor-like stimuli are optimal for
               V1. When presented back to the same neurons in vivo, MEIs drove
               responses significantly better than control stimuli. Inception
               loops represent a widely applicable technique for dissecting the
               neural mechanisms of sensation.",
  journal   = "Nat. Neurosci.",
  publisher = "Springer US",
  year      =  2019,
  keywords  = "own;\_imported;CRCNS;2021 Reconstruction;U24;SFB 1456 Mathematic
               of Experiment;ERC Consolidator 2023"
}

@ARTICLE{Richards2019-lm,
  title    = "A deep learning framework for neuroscience",
  author   = "Richards, Blake A and Lillicrap, Timothy P and Beaudoin, Philippe
              and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and
              Clopath, Claudia and Costa, Rui Ponte and de Berker, Archy and
              Ganguli, Surya and Gillon, Colleen J and Hafner, Danijar and
              Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and
              Lindsay, Grace W and Miller, Kenneth D and Naud, Richard and
              Pack, Christopher C and Poirazi, Panayiota and Roelfsema, Pieter
              and Sacramento, Jo{\~a}o and Saxe, Andrew and Scellier, Benjamin
              and Schapiro, Anna C and Senn, Walter and Wayne, Greg and Yamins,
              Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien,
              Denis and Kording, Konrad P",
  abstract = "Systems neuroscience seeks explanations for how the brain
              implements a wide variety of perceptual, cognitive and motor
              tasks. Conversely, artificial intelligence attempts to design
              computational systems based on the tasks they will have to solve.
              In artificial neural networks, the three components specified by
              design are the objective functions, the learning rules and the
              architectures. With the growing success of deep learning, which
              utilizes brain-inspired architectures, these three designed
              components have increasingly become central to how we model,
              engineer and optimize complex artificial learning systems. Here
              we argue that a greater focus on these components would also
              benefit systems neuroscience. We give examples of how this
              optimization-based framework can drive theoretical and
              experimental progress in neuroscience. We contend that this
              principled perspective on systems neuroscience will help to
              generate more rapid progress.",
  journal  = "Nat. Neurosci.",
  volume   =  22,
  number   =  11,
  pages    = "1761--1770",
  month    =  nov,
  year     =  2019,
  keywords = "4 mouse;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Wiltschko2020-zd,
  title    = "Revealing the structure of pharmacobehavioral space through
              motion sequencing",
  author   = "Wiltschko, Alexander B and Tsukahara, Tatsuya and Zeine, Ayman
              and Anyoha, Rockwell and Gillis, Winthrop F and Markowitz,
              Jeffrey E and Peterson, Ralph E and Katon, Jesse and Johnson,
              Matthew J and Datta, Sandeep Robert",
  abstract = "Understanding how genes, drugs and neural circuits influence
              behavior requires the ability to effectively organize information
              about similarities and differences within complex behavioral
              datasets. Motion Sequencing (MoSeq) is an ethologically inspired
              behavioral analysis method that identifies modular components of
              three-dimensional mouse body language called 'syllables'. Here,
              we show that MoSeq effectively parses behavioral differences and
              captures similarities elicited by a panel of neuroactive and
              psychoactive drugs administered to a cohort of nearly 700 mice.
              MoSeq identifies syllables that are characteristic of individual
              drugs, a finding we leverage to reveal specific on- and
              off-target effects of both established and candidate therapeutics
              in a mouse model of autism spectrum disorder. These results
              demonstrate that MoSeq can meaningfully organize large-scale
              behavioral data, illustrate the power of a fundamentally modular
              description of behavior and suggest that behavioral syllables
              represent a new class of druggable target.",
  journal  = "Nat. Neurosci.",
  volume   =  23,
  number   =  11,
  pages    = "1433--1443",
  month    =  nov,
  year     =  2020,
  keywords = "4 behavior;not read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Urai2022-fz,
  title     = "Large-scale neural recordings call for new insights to link
               brain and behavior",
  author    = "Urai, Anne E and Doiron, Brent and Leifer, Andrew M and
               Churchland, Anne K",
  abstract  = "Neuroscientists today can measure activity from more neurons
               than ever before, and are facing the challenge of connecting
               these brain-wide neural recordings to computation and behavior.
               In the present review, we first describe emerging tools and
               technologies being used to probe large-scale brain activity and
               new approaches to characterize behavior in the context of such
               measurements. We next highlight insights obtained from
               large-scale neural recordings in diverse model systems, and
               argue that some of these pose a challenge to traditional
               theoretical frameworks. Finally, we elaborate on existing
               modeling frameworks to interpret these data, and argue that the
               interpretation of brain-wide neural recordings calls for new
               theoretical approaches that may depend on the desired level of
               understanding. These advances in both neural recordings and
               theory development will pave the way for critical advances in
               our understanding of the brain. Neuroscientists can measure
               activity from more neurons than ever before, garnering new
               insights and posing challenges to traditional theoretical
               frameworks. New frameworks may help researchers use these
               observations to shed light on brain function.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  volume    =  25,
  number    =  1,
  pages     = "11--19",
  month     =  jan,
  year      =  2022,
  keywords  = "4 behavior;4 mouse;read;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Ashwood2022-ck,
  title     = "Mice alternate between discrete strategies during perceptual
               decision-making",
  author    = "Ashwood, Zoe C and Roy, Nicholas A and Stone, Iris R and Urai,
               Anne E and Churchland, Anne K and Pouget, Alexandre and Pillow,
               Jonathan W",
  abstract  = "Classical models of perceptual decision-making assume that
               subjects use a single, consistent strategy to form decisions, or
               that decision-making strategies evolve slowly over time. Here we
               present new analyses suggesting that this common view is
               incorrect. We analyzed data from mouse and human decision-making
               experiments and found that choice behavior relies on an
               interplay among multiple interleaved strategies. These
               strategies, characterized by states in a hidden Markov model,
               persist for tens to hundreds of trials before switching, and
               often switch multiple times within a session. The identified
               decision-making strategies were highly consistent across mice
               and comprised a single `engaged' state, in which decisions
               relied heavily on the sensory stimulus, and several biased
               states in which errors frequently occurred. These results
               provide a powerful alternate explanation for `lapses' often
               observed in rodent behavioral experiments, and suggest that
               standard measures of performance mask the presence of major
               changes in strategy across trials. The authors implement
               model-based analyses to uncover strategies used by mice and
               humans during sensory decision-making. Contrary to common
               wisdom, mice do not lapse and, instead, switch between sustained
               engaged and disengaged states.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  volume    =  25,
  number    =  2,
  pages     = "201--212",
  month     =  feb,
  year      =  2022,
  keywords  = "4 behavior;4 mouse;read next;unread;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Lau2002-gb,
  title    = "Computational subunits of visual cortical neurons revealed by
              artificial neural networks",
  author   = "Lau, B and Stanley, G B and Dan, Y",
  abstract = "A crucial step toward understanding visual processing is to
              obtain a comprehensive description of the relationship between
              visual stimuli and neuronal responses. Many neurons in the visual
              cortex exhibit nonlinear responses, making it difficult to
              characterize their stimulus--response relationships. Here, we
              recorded the responses of primary visual cortical neurons of the
              cat to spatiotemporal random-bar stimuli and trained artificial
              neural networks to predict the response of each neuron. The
              random initial connections in the networks consistently converged
              to regular patterns. Analyses of these connection patterns showed
              that the response of each complex cell to the random-bar stimuli
              could be well approximated by the sum of a small number of
              subunits resembling simple cells. The direction selectivity of
              each complex cell measured with drifting gratings was also well
              predicted by the combination of these subunits, indicating the
              generality of the model. These results are consistent with a
              simple functional model for complex cells and demonstrate the
              usefulness of the neural network method for revealing the
              stimulus--response transformations of nonlinear neurons.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  99,
  number   =  13,
  pages    = "8974--8979",
  year     =  2002,
  keywords = "system identification;recurrent;ERC Consolidator 2023"
}

@ARTICLE{Yamins2014-cg,
  title    = "Performance-optimized hierarchical models predict neural
              responses in higher visual cortex",
  author   = "Yamins, Daniel L K and Hong, Ha and Cadieu, Charles F and
              Solomon, Ethan A and Seibert, Darren and DiCarlo, James J",
  abstract = "The ventral visual stream underlies key human visual object
              recognition abilities. However, neural encoding in the higher
              areas of the ventral stream remains poorly understood. Here, we
              describe a modeling approach that yields a quantitatively
              accurate model of inferior temporal (IT) cortex, the highest
              ventral cortical area. Using high-throughput computational
              techniques, we discovered that, within a class of biologically
              plausible hierarchical neural network models, there is a strong
              correlation between a model's categorization performance and its
              ability to predict individual IT neural unit response data. To
              pursue this idea, we then identified a high-performing neural
              network that matches human performance on a range of recognition
              tasks. Critically, even though we did not constrain this model to
              match neural data, its top output layer turns out to be highly
              predictive of IT spiking responses to complex naturalistic images
              at both the single site and population levels. Moreover, the
              model's intermediate layers are highly predictive of neural
              responses in the V4 cortex, a midlevel visual area that provides
              the dominant cortical input to IT. These results show that
              performance optimization---applied in a biologically appropriate
              model class---can be used to build quantitative predictive models
              of neural processing.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  111,
  number   =  23,
  pages    = "8619--8624",
  year     =  2014,
  keywords = "\_imported;ERC Consolidator 2023"
}

@ARTICLE{Tang2018-gn,
  title    = "Recurrent computations for visual pattern completion",
  author   = "Tang, Hanlin and Schrimpf, Martin and Lotter, William and
              Moerman, Charlotte and Paredes, Ana and Caro, Josue Ortega and
              Hardesty, Walter and Cox, David and Kreiman, Gabriel and Ortega,
              Josue",
  abstract = "Making inferences from partial information constitutes a critical
              aspect of cognition. During visual perception, pattern completion
              enables recognition of poorly visible or occluded objects. We
              combined psychophysics, physiology, and computational models to
              test the hypothesis that pattern completion is implemented by
              recurrent computations and present three pieces of evidence that
              are consistent with this hypothesis. First, subjects robustly
              recognized objects even when they were rendered <15\% visible,
              but recognition was largely impaired when processing was
              interrupted by backward masking. Second, invasive physiological
              responses along the human ventral cortex exhibited visually
              selective responses to partially visible objects that were
              delayed compared with whole objects, suggesting the need for
              additional computations. These physiological delays were
              correlated with the effects of backward masking. Third,
              state-of-the-art feed-forward computational architectures were
              not robust to partial visibility. However, recognition
              performance was recovered when the model was augmented with
              attractor-based recurrent connectivity. The recurrent model was
              able to predict which images of heavily occluded objects were
              easier or harder for humans to recognize, could capture the
              effect of introducing a backward mask on recognition behavior,
              and was consistent with the physiological delays along the human
              ventral visual stream. These results provide a strong argument of
              plausibility for the role of recurrent computations in making
              visual inferences from partial information.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  115,
  number   =  35,
  pages    = "201719397",
  year     =  2018,
  keywords = "unread;man, brains and machines;ERC Consolidator 2023"
}

@ARTICLE{Dyballa2018-zr,
  title    = "Flow stimuli reveal ecologically appropriate responses in mouse
              visual cortex",
  author   = "Dyballa, Luciano and Hoseini, Mahmood S and Dadarlat, Maria C and
              Zucker, Steven W and Stryker, Michael P",
  abstract = "Assessments of the mouse visual system based on spatial-frequency
              analysis imply that its visual capacity is low, with few neurons
              responding to spatial frequencies greater than 0.5 cycles per
              degree. However, visually mediated behaviors, such as prey
              capture, suggest that the mouse visual system is more precise. We
              introduce a stimulus class---visual flow patterns---that is more
              like what the mouse would encounter in the natural world than are
              sine-wave gratings but is more tractable for analysis than are
              natural images. We used 128-site silicon microelectrodes to
              measure the simultaneous responses of single neurons in the
              primary visual cortex (V1) of alert mice. While holding
              temporal-frequency content fixed, we explored a class of drifting
              patterns of black or white dots that have energy only at higher
              spatial frequencies. These flow stimuli evoke strong visually
              mediated responses well beyond those predicted by
              spatial-frequency analysis. Flow responses predominate in higher
              spatial-frequency ranges (0.15--1.6 cycles per degree), many are
              orientation or direction selective, and flow responses of many
              neurons depend strongly on sign of contrast. Many cells exhibit
              distributed responses across our stimulus ensemble. Together,
              these results challenge conventional linear approaches to visual
              processing and expand our understanding of the mouse's visual
              capacity to behaviorally relevant ranges.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  115,
  number   =  44,
  pages    = "11304--11309",
  year     =  2018,
  keywords = "4 behavior;read next;unread;ERC Consolidator 2023"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Patchell1971-zk,
  title     = "Separability, neutrality and certainty equivalence",
  author    = "Patchell, J W and Jacobs, O L R",
  abstract  = "Abstract Studies of optimal stochastic control problems have
               drawn attention to three properties: separability, neutrality
               and certainty equivalence. The relationships between these
               properties have not yet been fully explored. This paper gives
               definitions of all three properties, summarizes well-known
               results about them and discusses the relationships between them.
               It is shown that separability is not the same as, but is a
               necessary condition for, certainty equivalence. It is
               conjectured that neutrality is a sufficient condition for
               certainty equivalence.",
  journal   = "Int. J. Control",
  publisher = "Taylor \& Francis",
  volume    =  13,
  number    =  2,
  pages     = "337--342",
  month     =  feb,
  year      =  1971,
  keywords  = "4 behavior;read;ERC Consolidator 2023"
}

@ARTICLE{Conant1970-td,
  title     = "Every good regulator of a system must be a model of that system",
  author    = "Conant, Roger C and Ross Ashby, W",
  abstract  = "The design of a complex regulator often includes the making of a
               model of the system to be regulated. The making of such a model
               has hitherto been regarded as optional, as merely one of many
               possible ways. In this paper a theorem is presented which shows,
               under very broad conditions, that any regulator that is
               maximally both successful and simple must be isomorphic with the
               system being regulated. (The exact assumptions are given.)
               Making a model is thus necessary. The theorem has the
               interesting corollary that the living brain, so far as it is to
               be successful and efficient as a regulator for survival, must
               proceed, in learning, by the formation of a model (or models) of
               its environment.",
  journal   = "Int. J. Syst. Sci.",
  publisher = "Taylor \& Francis",
  volume    =  1,
  number    =  2,
  pages     = "89--97",
  month     =  oct,
  year      =  1970,
  keywords  = "unread;ERC Consolidator 2023"
}

@ARTICLE{Paninski2004-ax,
  title    = "Maximum likelihood estimation of cascade point-process neural
              encoding models",
  author   = "Paninski, Liam",
  journal  = "Network: Computation in Neural Systems",
  volume   =  15,
  number   =  4,
  pages    = "243--262",
  year     =  2004,
  keywords = "\_imported;ERC Consolidator 2023"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Horrocks2023-ik,
  title    = "Walking humans and running mice: perception and neural encoding
              of optic flow during self-motion",
  author   = "Horrocks, Edward A B and Mareschal, Isabelle and Saleem, Aman B",
  abstract = "Locomotion produces full-field optic flow that often dominates
              the visual motion inputs to an observer. The perception of optic
              flow is in turn important for animals to guide their heading and
              interact with moving objects. Understanding how locomotion
              influences optic flow processing and perception is therefore
              essential to understand how animals successfully interact with
              their environment. Here, we review research investigating how
              perception and neural encoding of optic flow are altered during
              self-motion, focusing on locomotion. Self-motion has been found
              to influence estimation and sensitivity for optic flow speed and
              direction. Nonvisual self-motion signals also increase
              compensation for self-driven optic flow when parsing the visual
              motion of moving objects. The integration of visual and nonvisual
              self-motion signals largely follows principles of Bayesian
              inference and can improve the precision and accuracy of
              self-motion perception. The calibration of visual and nonvisual
              self-motion signals is dynamic, reflecting the changing
              visuomotor contingencies across different environmental contexts.
              Throughout this review, we consider experimental research using
              humans, non-human primates and mice. We highlight experimental
              challenges and opportunities afforded by each of these species
              and draw parallels between experimental findings. These findings
              reveal a profound influence of locomotion on optic flow
              processing and perception across species. This article is part of
              a discussion meeting issue 'New approaches to 3D vision'.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  378,
  number   =  1869,
  pages    = "20210450",
  month    =  jan,
  year     =  2023,
  keywords = "human vision; locomotion; mouse vision; optic flow;
              psychophysics;4 behavior;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Cadena2017-rb,
  title    = "Deep convolutional models improve predictions of macaque {V1}
              responses to natural images",
  author   = "Cadena, S A and Denfield, G H and Walker, E Y and Gatys, L A and
              Tolias, A S and Bethge, M and Ecker, A S",
  abstract = "Despite great efforts over several decades, our best models of
              primary visual cortex (V1) still predict neural responses quite
              poorly when probed with natural stimuli, highlighting our limited
              understanding of the nonlinear computations in V1. At the same
              time, recent advances in machine learning have shown that deep
              neural networks can learn highly nonlinear functions for visual
              information processing. Two approaches based on deep learning
              have recently been successfully applied to neural data: transfer
              learning for predicting neural activity in higher areas of the
              primate ventral stream and data-driven models to predict retina
              and V1 neural activity of mice. However, so far there exists no
              comparison between the two approaches and neither of them has
              been used to model the early primate visual system. Here, we test
              the ability of both approaches to predict neural responses to
              natural images in V1 of awake monkeys. We found that both deep
              learning approaches outperformed classical linear- nonlinear and
              wavelet-based feature representations building on existing V1
              encoding theories. On our dataset, transfer learning and
              data-driven models performed similarly, while the data-driven
              model employed a much simpler architecture. Thus, multi-layer
              CNNs set the new state of the art for predicting neural responses
              to natural images in primate V1. Having such good predictive
              in-silico models opens the door for quantitative studies of yet
              unknown nonlinear computations in V1 without being limited by the
              available experimental time.",
  journal  = "PLoS Comput. Biol.",
  pages    = "201764",
  year     =  2017,
  keywords = "read;system identification;\_imported;2021 Reconstruction;2022
              Lurz, Bashiri;ERC Consolidator 2023"
}

@ARTICLE{Froudarakis2020-xh,
  title    = "Object manifold geometry across the mouse cortical visual
              hierarchy",
  author   = "Froudarakis, Emmanouil and Cohen, Uri and Diamantaki, Maria and
              Walker, Edgar Y and Reimer, Jacob and Berens, Philipp and
              Sompolinsky, Haim and Tolias, Andreas S",
  abstract = "Despite variations in appearance we robustly recognize objects.
              Neuronal populations responding to objects presented under
              varying conditions form object manifolds and hierarchically
              organized visual areas are thought to untangle pixel intensities
              into linearly decodable object representations. However, the
              associated changes in the geometry of object manifolds along the
              cortex remain unknown. Using home cage training we showed that
              mice are capable of invariant object recognition. We
              simultaneously recorded the responses of thousands of neurons to
              measure the information about object identity available across
              the visual cortex and found that lateral visual areas LM, LI and
              AL carry more linearly decodable object identity information
              compared to other visual areas. We applied the theory of linear
              separability of manifolds, and found that the increase in
              classification capacity is associated with a decrease in the
              dimension and radius of the object manifold, identifying features
              of the population code that enable invariant object coding.",
  journal  = "bioRxiv",
  pages    = "2020.08.20.258798",
  year     =  2020,
  keywords = "unread;rodent vision;ERC Consolidator 2023"
}

@INPROCEEDINGS{Lurz2020-ua,
  title      = "Generalization in data-driven models of primary visual cortex",
  booktitle  = "Proceedings of the International Conference for Learning
                Representations ({ICLR})",
  author     = "Lurz, Konstantin-Klemens and Bashiri, Mohammad and Willeke,
                Konstantin and Jagadish, Akshay K and Wang, Eric and Walker,
                Edgar Y and Cadena, Santiago A and Muhammad, Taliah and Cobos,
                Erick and Tolias, Andreas S and Ecker, Alexander S and Sinz,
                Fabian H",
  abstract   = "Deep neural networks (DNN) have set new standards at predicting
                responses of neural populations to visual input. Most such DNNs
                consist of a convolutional network (core) shared across all
                neurons which learns a representation of neural computation in
                visual cortex and a neuron-specific readout that linearly
                combines the relevant features in this representation. The goal
                of this paper is to test whether such a representation is
                indeed generally characteristic for visual cortex, i.e.
                generalizes between animals of a species, and what factors
                contribute to obtaining such a generalizing core. To push all
                non-linear computations into the core where the generalizing
                cortical features should be learned, we devise a novel readout
                that reduces the number of parameters per neuron in the readout
                by up to two orders of magnitude compared to the previous
                state-of-the-art. It does so by taking advantage of retinotopy
                and learns a Gaussian distribution over the neuron's receptive
                field position. With this new readout we train our network on
                neural responses from mouse primary visual cortex (V1) and
                obtain a gain in performance of 7\% compared to the previous
                state-of-the-art network. We then investigate whether the
                convolutional core indeed captures general cortical features by
                using the core in transfer learning to a different animal. When
                transferring a core trained on thousands of neurons from
                various animals and scans we exceed the performance of training
                directly on that animal by 12\%, and outperform a commonly used
                VGG16 core pre-trained on imagenet by 33\%. In addition,
                transfer learning with our data-driven core is more
                data-efficient than direct training, achieving the same
                performance with only 40\% of the data. Our model with its
                novel readout thus sets a new state-of-the-art for neural
                response prediction in mouse visual cortex from natural images,
                generalizes between animals, and captures better characteristic
                cortical features than current task-driven pre-training
                approaches such as VGG16. \#\#\# Competing Interest Statement
                The authors have declared no competing interest.",
  pages      = "2020.10.05.326256",
  month      =  oct,
  year       =  2020,
  keywords   = "own;CRCNS;SFB 1456 Mathematic of Experiment;ERC Consolidator
                2023",
  language   = "en",
  conference = "ICLR 2021"
}

@ARTICLE{Shi_undated-cq,
  title    = "A Convolutional Network Architecture Driven by Mouse
              Neuroanatomical Data",
  author   = "Shi, Jianghong and Buice, Michael A and Shea-Brown, Eric and
              Mihalas, Stefan and Tripp, Bryan",
  keywords = "unread;inductive bias;rodent vision;ERC Consolidator 2023"
}

@UNPUBLISHED{Horrocks2021-re,
  title    = "Distinct neural dynamics underlie the encoding of visual speed in
              stationary and running mice",
  author   = "Horrocks, Edward A B and Saleem, Aman B",
  abstract = "Sensory experiences are often driven by an animal's self-motion
              and locomotion is known to modulate neural responses in the mouse
              visual system. This modulation is hypothesised to improve the
              processing of behaviourally relevant visual inputs, which may
              change rapidly during locomotion. However, little is known about
              how locomotion modulates the temporal dynamics (time courses) of
              visually-evoked neural responses. Here, we analysed the temporal
              dynamics of single neuron and population responses to dot field
              stimuli moving at a range of visual speeds using the Visual
              Coding dataset from the Allen Institute for Brain Science[1][1].
              Single neuron responses had diverse temporal dynamics that varied
              between stationary and running sessions. Increased dynamic range
              and more reliable responses in running sessions enabled faster,
              stronger and more persistent encoding of visual speed. Population
              activity reflected the temporal dynamics of single neuron
              responses, including their modulation by locomotor state - neural
              trajectories of population activity made more direct transitions
              between baseline and stimulus steady states in running sessions.
              The structure of population coding also changed with locomotor
              state -- population activity prioritised the encoding of visual
              speed in running, but not stationary sessions. Our results reveal
              a profound influence of locomotion on the temporal dynamics of
              neural responses. We demonstrate that during locomotion, mouse
              visual areas prioritise the encoding of potentially
              fast-changing, behaviourally relevant visual features. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest. [1]: \#ref-1",
  journal  = "bioRxiv",
  pages    = "2021.06.11.447904",
  month    =  jun,
  year     =  2021,
  keywords = "4 color MEI;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@UNPUBLISHED{Nayebi2021-mn,
  title    = "Shallow Unsupervised Models Best Predict Neural Responses in
              Mouse Visual Cortex",
  author   = "Nayebi, Aran and Kong, Nathan C L and Zhuang, Chengxu and
              Gardner, Justin L and Norcia, Anthony M and Yamins, Daniel L K",
  abstract = "Task-optimized deep convolutional neural networks are the most
              quantitatively accurate models of the primate ventral visual
              stream. However, such networks are implausible as models of the
              mouse visual system because mouse visual cortex has both lower
              retinal resolution and a shallower hierarchy than the primate.
              Moreover, the category supervision deep networks typically
              receive is neither ethologically relevant to the mouse in
              semantic content, nor realistic in quantity. As a result,
              standard supervised deep neural networks have proven
              quantitatively ineffective at modeling mouse visual data. Here,
              we develop and evaluate models that remedy these structural and
              functional gaps. We first demonstrate that shallow hierarchical
              architectures applied to lower resolution images improve match to
              neural responses, both in electro-physiological and calcium
              imaging data. We then show that networks trained using
              contrastive embedding methods, a recent unsupervised learning
              objective that requires no semantic labeling, achieve neural
              prediction performance that substantially exceed that of the same
              architectures trained in a supervised manner, across a wide
              variety of architecture types. Combining these better structural
              and functional priors yields models that are the most
              quantitatively accurate match to mouse visual responses to
              natural scenes, significantly surpassing that of prior attempts
              using primate-specific models, and approaching the inter-animal
              consistency level of the data itself. We further find that these
              shallow unsupervised models transfer to a wide variety of
              non-categorical visual tasks better than categorization-trained
              models. Taken together, our results suggest that mouse visual
              cortex is a low-resolution, shallow network that makes best use
              of the mouse's limited resources to create a light-weight,
              general-purpose visual system -- in contrast to the deep,
              high-resolution, and more task-specific visual system of
              primates. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.06.16.448730",
  month    =  aug,
  year     =  2021,
  keywords = "4 mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@UNPUBLISHED{Luongo2021-ci,
  title    = "Mice and primates use distinct strategies for visual segmentation",
  author   = "Luongo, Francisco J and Liu, Lu and Ho, Chun Lum Andy and Hesse,
              Janis K and Wekselblatt, Joseph B and Lanfranchi, Francesco and
              Huber, Daniel and Tsao, Doris Y",
  abstract = "The rodent visual system has attracted great interest in recent
              years due to its experimental tractability, but the fundamental
              mechanisms used by the mouse to represent the visual world remain
              unclear. In the primate, researchers have argued from both
              behavioral and neural evidence that a key step in visual
              representation is ``figure-ground segmentation,'' the delineation
              of figures as distinct from backgrounds [[1][1]--[4][2]]. To
              determine if mice also show behavioral and neural signatures of
              figure-ground segmentation, we trained mice on a figure-ground
              segmentation task where figures were defined by gratings and
              naturalistic textures moving counterphase to the background.
              Unlike primates, mice were severely limited in their ability to
              segment figure from ground using the opponent motion cue, with
              segmentation behavior strongly dependent on the specific carrier
              pattern. Remarkably, when mice were forced to localize
              naturalistic patterns defined by opponent motion, they adopted a
              strategy of brute force memorization of texture patterns. In
              contrast, primates, including humans, macaques, and mouse lemurs,
              could readily segment figures independent of carrier pattern
              using the opponent motion cue. Consistent with mouse behavior,
              neural responses to the same stimuli recorded in mouse visual
              areas V1, RL, and LM also did not support texture-invariant
              segmentation of figures using opponent motion. Modeling revealed
              that the texture dependence of both the mouse's behavior and
              neural responses could be explained by a feedforward neural
              network lacking explicit segmentation capabilities. These
              findings reveal a fundamental limitation in the ability of mice
              to segment visual objects compared to primates. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest. [1]: \#ref-1 [2]: \#ref-4",
  journal  = "bioRxiv",
  pages    = "2021.07.04.451059",
  month    =  jul,
  year     =  2021,
  keywords = "4 mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@UNPUBLISHED{De_Gee2022-ir,
  title    = "Mice regulate their attentional intensity and arousal to exploit
              increases in task utility",
  author   = "de Gee, J W and Mridha, Z and Hudson, M and Shi, Y and Ramsaywak,
              H and Smith, S and Karediya, N and Thompson, M and Jaspe, K and
              Zhang, W and McGinley, M J",
  abstract = "To meet their survival needs, organisms must continuously select
              which sensory stimuli to attend to and decide how much attention
              to pay. Attention's selective aspect has been a cornerstone of
              behavioral and physiological study, whereas attentional intensity
              is poorly understood. Autonomic arousal is thought to strongly
              influence attentional intensity, but evidence is lacking,
              including regarding if and how organisms self-regulate their
              arousal to match attentional intensity to its utility. Here, we
              developed an auditory attentional intensity task for head-fixed
              mice and vary task utility by changing reward size. We record
              pupil size and walking speed as proxies of arousal and
              exploration, respectively. Using simple performance metrics and
              sequential sampling modeling, we find that mice increase their
              attentional intensity during periods of high task utility. The
              utility-related attentional boost is partially mediated by
              stabilization of pupil-linked arousal around an optimal mid-sized
              level, and an associated reduction in exploratory behavior. In
              sum, self-regulation of arousal partially implements strategic
              attentional intensity allocation. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.03.04.482962",
  month    =  mar,
  year     =  2022,
  keywords = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@UNPUBLISHED{Cadena2022-im,
  title    = "Diverse task-driven modeling of macaque {V4} reveals functional
              specialization towards semantic tasks",
  author   = "Cadena, Santiago A and Willeke, Konstantin F and Restivo, Kelli
              and Denfield, George and Sinz, Fabian H and Bethge, Matthias and
              Tolias, Andreas S and Ecker, Alexander S",
  abstract = "Responses to natural stimuli in area V4 -- a mid-level area of
              the visual ventral stream -- are well predicted by features from
              convolutional neural networks (CNNs) trained on image
              classification. This result has been taken as evidence for the
              functional role of V4 in object classification. However, we
              currently do not know if and to what extent V4 plays a role in
              solving other computational objectives. Here, we investigated
              normative accounts of V4 by predicting macaque single-neuron
              responses to natural images from the representations extracted by
              23 CNNs trained on different computer vision tasks including
              semantic, geometric, 2D, and 3D visual tasks. We found that
              semantic classification tasks do indeed provide the best
              predictive features for V4. Other tasks (3D in particular)
              followed very closely in performance, but a similar pattern of
              tasks performance emerged when predicting the activations of a
              network exclusively trained on object recognition. Thus, our
              results support V4's main functional role in semantic processing.
              At the same time, they suggest that V4's affinity to various 3D
              and 2D stimulus features found by electrophysiologists could be a
              corollary of a semantic functional goal. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2022.05.18.492503",
  month    =  may,
  year     =  2022,
  keywords = "read;own;ERC Consolidator 2023",
  language = "en"
}

@UNPUBLISHED{Di_Santo2022-zw,
  title    = "Unifying model for three forms of contextual modulation including
              feedback input from higher visual areas",
  author   = "Di Santo, Serena and Dipoppa, Mario and Keller, Andreas and Roth,
              Morgane and Scanziani, Massimo and Miller, Kenneth D",
  abstract = "Neural responses to a localized visual stimulus are modulated by
              the content of its surrounding. This phenomenon manifests in
              several forms of contextual modulation, including three
              interrelated properties of the visual cortex: surround
              suppression, inverse response and surround facilitation. We
              devise a unified biologically realistic circuit model accounting
              for all these phenomena and show that i) surround suppression in
              L2/3 is only partially due to the recruitment of lateral
              inhibition; ii) long-range feedback projections are necessary for
              inverse response and iii) the width of the response profile in
              the feedback layer determines inverse size tuning. The model
              predicts the modulations induced by silencing
              somatostatin-expressing cells or higher visual areas or changing
              the stimulus contrast. These predictions are consistent with the
              experimental observations when available and can be tested in
              existing setups otherwise. We then show the robustness of the
              identified mechanisms in a model with three interneuron
              subclasses, built to fit the classical responses and able to
              predict inverse size-tuning curves. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.05.27.493753",
  month    =  may,
  year     =  2022,
  keywords = "4 mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@UNPUBLISHED{Hofling2022-wr,
  title    = "A chromatic feature detector in the retina signals visual context
              changes",
  author   = "H{\"o}fling, Larissa and Szatko, Klaudia P and Behrens, Christian
              and Qiu, Yongrong and Klindt, David A and Jessen, Zachary and
              Schwartz, Gregory W and Bethge, Matthias and Berens, Philipp and
              Franke, Katrin and Ecker, Alexander S and Euler, Thomas",
  abstract = "The retina transforms patterns of light into visual feature
              representations supporting behaviour. These representations are
              distributed across various types of retinal ganglion cells
              (RGCs), whose spatial and temporal tuning properties have been
              extensively studied in many model organisms, including the mouse.
              However, it has been difficult to link the potentially nonlinear
              retinal transformations of natural visual inputs to specific
              ethological purposes. Here, we discover a novel selectivity to
              chromatic contrast in an RGC type that allows the detection of
              transitions of the horizon across a retinal region. We trained a
              convolutional neural network (CNN) model on large-scale
              functional recordings of RGC responses to natural mouse movies,
              and then used this model to search in silico for stimuli that
              maximally excite distinct types of RGCs. This procedure predicted
              centre colour-opponency in transient Suppressed-by-Contrast RGCs
              (tSbC), a cell type whose function is being debated. We confirmed
              experimentally that these cells indeed responded very selectively
              to Green-OFF, UV-ON contrasts, which we found to be
              characteristic of transitions from ground to sky in the visual
              scene, as might be elicited by head-or eye-movements across the
              horizon. Because tSbCs reliably detected these transitions, we
              suggest a role for this RGC type in providing contextual
              information (i.e. sky or ground) necessary for the selection of
              appropriate behavioural responses to other stimuli, such as
              looming objects. Our work showcases how a combination of
              experiments with natural stimuli and computational modelling
              allows discovering novel types of stimulus selectivity and
              identifying their potential ethological relevance. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.11.30.518492",
  month    =  dec,
  year     =  2022,
  keywords = "ERC Consolidator 2023",
  language = "en"
}

@UNPUBLISHED{Cobos2022-rr,
  title    = "It takes neurons to understand neurons: Digital twins of visual
              cortex synthesize neural metamers",
  author   = "Cobos, Erick and Muhammad, Taliah and Fahey, Paul G and Ding,
              Zhiwei and Ding, Zhuokun and Reimer, Jacob and Sinz, Fabian H and
              Tolias, Andreas S",
  abstract = "Metamers, images that are perceived as equal, are a useful tool
              to study representations of natural images in biological and
              artificial vision systems. We synthesized metamers for the mouse
              visual system by inverting a deep encoding model to find an image
              that matched the observed neural activity to the original
              presented image. When testing the resulting images in
              physiological experiments we found that they most closely
              reproduced the neural activity of the original image when
              compared to other decoding methods, even when tested in a
              different animal whose neural activity was not used to produce
              the metamer. This demonstrates that deep encoding models do
              capture general characteristic properties of biological visual
              systems and can be used to define a meaningful perceptual loss
              for the visual system. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.12.09.519708",
  month    =  dec,
  year     =  2022,
  keywords = "own;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Christensen2017-bx,
  title    = "Running reduces firing but improves coding in rodent higher-order
              visual cortex",
  author   = "Christensen, Amelia J and Pillow, Jonathan W",
  abstract = "Running profoundly alters stimulus-response properties in mouse
              primary visual cortex (V1), but its effects in higher-order
              visual cortex remain unknown. Here we systematically investigated
              how locomotion modulates visual responses across six visual areas
              and three cortical layers using a massive dataset from the Allen
              Brain Institute. Although running has been shown to increase
              firing in V1, we found that it suppressed firing in higher-order
              visual areas. Despite this reduction in gain, visual responses
              during running could be decoded more accurately than visual
              responses during stationary periods. We show that this effect was
              not attributable to changes in noise correlations, and propose
              that it instead arises from increased reliability of single
              neuron responses during running.",
  journal  = "bioRxiv",
  year     =  2017,
  keywords = "Anatomy; Artificial intelligence; Bioinformatics; Biology;
              Neuron; Pattern recognition; Visual cortex;brain state;ERC
              Consolidator 2023"
}

@INCOLLECTION{Sinz2018-sk,
  title     = "Stimulus domain transfer in recurrent models for large scale
               cortical population prediction on video",
  booktitle = "Advances in Neural Information Processing Systems 31",
  author    = "Sinz, F and Ecker, A S and Fahey, P and Walker, E and Cobos, E
               and Froudarakis, E and Yatsenko, D and Pitkow, X and Reimer, J
               and Tolias, A",
  abstract  = "To better understand the representations in visual cortex, we
               need to generate better predictions of neural activity in awake
               animals presented with their ecological input: natural video.
               Despite recent advances in models for static images, models for
               predicting responses to natural video are scarce and standard
               linear-nonlinear models perform poorly. We developed a new deep
               recurrent network architecture that predicts inferred spiking
               activity of thousands of mouse V1 neurons simultaneously
               recorded with two-photon microscopy, while accounting for
               confounding factors such as the animal's gaze position and brain
               state changes related to running state and pupil dilation.
               Powerful system identification models provide an opportunity to
               gain insight into cortical functions through in silico
               experiments that can subsequently be tested in the brain.
               However, in many cases this approach requires that the model is
               able to generalize to stimulus statistics that it was not
               trained on, such as band-limited noise and other parameterized
               stimuli. We investigated these domain transfer properties in our
               model and find that our model trained on natural images is able
               to correctly predict the orientation tuning of neurons in
               responses to artificial noise stimuli. Finally, we show that we
               can fully generalize from movies to noise and maintain high
               predictive performance on both stimulus domains by fine-tuning
               only the final layer's weights on a network otherwise trained on
               natural movies. The converse, however, is not true.",
  year      =  2018,
  keywords  = "read;own;\_imported;2021 Reconstruction;SFB 1456 Mathematic of
               Experiment;ERC Consolidator 2023"
}

@UNPUBLISHED{Schnabel2018-tb,
  title    = "Feedforward and feedback processing during figure-ground
              perception in mice",
  author   = "Schnabel, Ulf H and Kirchberger, Lisa and van Beest, Enny H and
              Mukherjee, Sreedeep and Barsegyan, Areg and Lorteije, Jeannette A
              M and van der Togt, Chris and Self, Matthew W and Roelfsema,
              Pieter R",
  abstract = "Abstract The segregation of figures from the background is an
              important first step in the analysis of a visual scene.
              Figure-ground segregation is thought to rely on interactions
              between the primary visual cortex (area V1) and higher visual
              areas. Upon presentation of a new image, the initial V1 responses
              reflect the information in the neurons9 receptive fields (RFs),
              whereas later activity is context-dependent so that the
              representations of figures are enhanced relative to the
              background1-3. It is unknown if the figural response enhancement
              in V1 plays a role in perception and the mechanisms that produce
              it are not well understood. We trained mice to report a
              contrast-defined figure or a figure on a textured background that
              required figure-ground segregation, and optogenetically silenced
              V1 activity at different time-points. Suppression of early V1
              activity interfered with both visual tasks, but suppression of
              the later activity selectively interfered with figure-ground
              perception. Using widefield imaging, we observed that figures
              also elicited stronger activity than the background in higher
              visual areas, and we used optogenetics to demonstrate that the
              extra activity is fed back to enhance the V1 figure
              representation. Within V1, figures increased the activity of
              pyramidal cells, parvalbumin (PV) and vasoactive intestinal
              peptide (VIP) positive interneurons but they decreased the
              activity of somatostatin-positive (SOM) interneurons. These
              results support the view that VIP interneurons inhibit
              SOM-interneurons to disinhibit the cortical column4. Our results
              demonstrate that figure-ground modulation of V1 neurons
              contributes to perception. We expect that the observed
              interactions between lower and higher brain regions generalize to
              other sensory modalities and that they will inform
              neurobiologically realistic models of scene perception.One
              sentence summary Figure-ground perception in mice depends on
              reciprocal interactions between the primary visual cortex and
              higher cortical areas, with specific roles for PV-, VIP- and
              SOM-positive interneurons.",
  journal  = "bioRxiv",
  pages    = "456459",
  month    =  oct,
  year     =  2018,
  keywords = "4 mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Russell2019-dq,
  title    = "The influence of visual cortex on perception is modulated by
              behavioural state",
  author   = "Russell, Lloyd E and Yang, Zidan and Tan, Pei Lynn and Fi{\c
              s}ek, Mehmet and Packer, Adam M and Dalgleish, Henry W P and
              Chettih, Selmaan and Harvey, Christopher D and H{\"a}usser,
              Michael and Tan, Lynn Pei and Fi{\c s}ek, Mehmet and Packer, Adam
              M and Dalgleish, Henry W P and Chettih, Selmaan and Harvey,
              Christopher D and H{\"a}usser, Michael",
  abstract = "Our understanding of the link between neural activity and
              perception remains incomplete. Microstimulation and optogenetic
              experiments have shown that manipulating cortical activity can
              influence sensory-guided behaviour or elicit artificial percepts.
              And yet, some perceptual tasks can still be solved when sensory
              cortex is silenced or removed, suggesting that cortical activity
              may not always be essential. Reconciling these findings, and
              providing a quantitative framework linking cortical activity and
              behaviour, requires knowledge of the identity of the cells being
              activated during the behaviour, the engagement of the local and
              downstream networks, and the cortical and behavioural state.
              Here, we performed two-photon population calcium imaging in L2/3
              primary visual cortex (V1) of headfixed mice performing a visual
              detection task while simultaneously activating specific groups of
              neurons using targeted two-photon optogenetics during low
              contrast visual stimulation. Only activation of groups of cells
              with similar tuning to the relevant visual stimulus led to a
              measurable bias of detection behaviour. Targeted photostimulation
              revealed signatures of centre-surround, predominantly inhibitory
              and like-to-like connectivity motifs in the local network which
              shaped the visual stimulus representation and partially explained
              the change in stimulus detectability. Moreover, the behavioural
              effects depended on overall performance: when the task was
              challenging for the mouse, V1 activity was more closely linked to
              performance, and cortical stimulation boosted perception. In
              contrast, when the task was easy, V1 activity was less
              informative about performance and cortical stimulation suppressed
              stimulus detection. Altogether, we find that both the selective
              routing of information through functionally specific circuits,
              and the prevailing cortical state, make similarly large
              contributions to explaining the behavioural response to
              photostimulation. Our results thus help to reconcile
              contradictory findings about the involvement of primary sensory
              cortex in behavioural tasks, suggesting that the influence of
              cortical activity on behaviour is dynamically reassigned
              depending on the demands of the task.",
  journal  = "bioRxiv",
  pages    = "706010",
  year     =  2019,
  keywords = "unread;brain state;ERC Consolidator 2023"
}

@ARTICLE{Scarselli2009-gy,
  title    = "The graph neural network model",
  author   = "Scarselli, Franco and Gori, Marco and Tsoi, A C Ah Chung and
              Hagenbuchner, Markus and Monfardini, Gabriele",
  abstract = "Many underlying relationships among data in several areas of
              science and engineering, e.g., computer vision, molecular
              chemistry, molecular biology, pattern recognition, and data
              mining, can be represented in terms of graphs. In this paper, we
              propose a new neural network model, called graph neural network
              (GNN) model, that extends existing neural network methods for
              processing the data represented in graph domains. This GNN model,
              which can directly process most of the practically useful types
              of graphs, e.g., acyclic, cyclic, directed, and undirected,
              implements a function tau(G,n) is an element of IR(m) that maps a
              graph G and one of its nodes n into an m-dimensional Euclidean
              space. A supervised learning algorithm is derived to estimate the
              parameters of the proposed GNN model. The computational cost of
              the proposed algorithm is also considered. Some experimental
              results are shown to validate the proposed learning algorithm,
              and to demonstrate its generalization capabilities.",
  journal  = "IEEE Trans. Neural Netw.",
  volume   =  20,
  number   =  1,
  pages    = "61--80",
  year     =  2009,
  keywords = "4 Projects;netgard;SFB 1456 Mathematic of Experiment;ERC
              Consolidator 2023"
}

@ARTICLE{Kreiman2020-rq,
  title    = "Beyond the feedforward sweep: feedback computations in the visual
              cortex",
  author   = "Kreiman, Gabriel and Serre, Thomas",
  abstract = "Visual perception involves the rapid formation of a coarse image
              representation at the onset of visual processing, which is
              iteratively refined by late computational processes. These early
              versus late time windows approximately map onto feedforward and
              feedback processes, respectively. State-of-the-art convolutional
              neural networks, the main engine behind recent machine vision
              successes, are feedforward architectures. Their successes and
              limitations provide critical information regarding which visual
              tasks can be solved by purely feedforward processes and which
              require feedback mechanisms. We provide an overview of recent
              work in cognitive neuroscience and machine vision that highlights
              the possible role of feedback processes for both visual
              recognition and beyond. We conclude by discussing important open
              questions for future research.",
  journal  = "Ann. N. Y. Acad. Sci.",
  volume   =  1464,
  number   =  1,
  pages    = "222--241",
  year     =  2020,
  keywords = "unread;man, brains and machines;ERC Consolidator 2023"
}

@ARTICLE{Schultz1997-xu,
  title    = "A neural substrate of prediction and reward",
  author   = "Schultz, W and Dayan, P and Montague, P R",
  abstract = "The capacity to predict future events permits a creature to
              detect, model, and manipulate the causal structure of its
              interactions with its environment. Behavioral experiments suggest
              that learning is driven by changes in the expectations about
              future salient events such as rewards and punishments.
              Physiological work has recently complemented these studies by
              identifying dopaminergic neurons in the primate whose fluctuating
              output apparently signals changes or errors in the predictions of
              future salient and rewarding events. Taken together, these
              findings can be understood through quantitative theories of
              adaptive optimizing control.",
  journal  = "Science",
  volume   =  275,
  number   =  5306,
  pages    = "1593--1599",
  month    =  mar,
  year     =  1997,
  keywords = "4 behavior;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Spitzer1988-kq,
  title    = "Increased Attention Enhances Both Behavioral and Neuronal
              Performance",
  author   = "Spitzer, Hedva and Desimone, Robert and Moran, Jeffrey",
  abstract = "Single cells were recorded from cortical area V4 of two rhesus
              monkeys (Macaca mulatta) trained on a visual discrimination task
              with two levels of difficulty. Behavioral evidence indicated that
              the monkeys' discriminative abilities improved when the task was
              made more difficult. Correspondingly, neuronal responses to
              stimuli became larger and more selective in the difficult task. A
              control experiment demonstrated that changes in general arousal
              could not account for the effects of task difficulty on neuronal
              responses. It is concluded that increasing the amount of
              attention directed toward a stimulus can enhance the
              responsiveness and selectivity of the neurons that process it.",
  journal  = "Science",
  volume   =  240,
  number   =  4850,
  pages    = "338--340",
  year     =  1988,
  keywords = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023"
}

@ARTICLE{Stringer2019-lt,
  title    = "Spontaneous behaviors drive multidimensional, brainwide activity",
  author   = "Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas
              and Reddy, Charu Bai and Carandini, Matteo and Harris, Kenneth D",
  abstract = "Neuronal populations in sensory cortex produce variable responses
              to sensory stimuli and exhibit intricate spontaneous activity
              even without external sensory input. Cortical variability and
              spontaneous activity have been variously proposed to represent
              random noise, recall of prior experience, or encoding of ongoing
              behavioral and cognitive variables. Recording more than 10,000
              neurons in mouse visual cortex, we observed that spontaneous
              activity reliably encoded a high-dimensional latent state, which
              was partially related to the mouse's ongoing behavior and was
              represented not just in visual cortex but also across the
              forebrain. Sensory inputs did not interrupt this ongoing signal
              but added onto it a representation of external stimuli in
              orthogonal dimensions. Thus, visual cortical population activity,
              despite its apparently noisy structure, reliably encodes an
              orthogonal fusion of sensory and multidimensional behavioral
              information.",
  journal  = "Science",
  volume   =  364,
  number   =  6437,
  year     =  2019,
  keywords = "4 behavior;4 mouse;read next;unread;brain state;SFB 1456
              Mathematic of Experiment;ERC Consolidator 2023"
}

@ARTICLE{Bashivan2019-ry,
  title    = "Neural population control via deep image synthesis",
  author   = "Bashivan, Pouya and Kar, Kohitij and DiCarlo, James J",
  abstract = "Particular deep artificial neural networks (ANNs) are today's
              most accurate models of the primate brain's ventral visual
              stream. Using an ANN-driven image synthesis method, we found that
              luminous power patterns (i.e., images) can be applied to primate
              retinae to predictably push the spiking activity of targeted V4
              neural sites beyond naturally occurring levels. This method,
              although not yet perfect, achieves unprecedented independent
              control of the activity state of entire populations of V4 neural
              sites, even those with overlapping receptive fields. These
              results show how the knowledge embedded in today's ANN models
              might be used to noninvasively set desired internal brain states
              at neuron-level resolution, and suggest that more accurate ANN
              models would produce even more accurate control.",
  journal  = "Science",
  volume   =  364,
  number   =  6439,
  year     =  2019,
  keywords = "read;MEI \& reconstruction;CRCNS;2021 Reconstruction;ERC
              Consolidator 2023"
}

@ARTICLE{Marshel2019-ph,
  title    = "Cortical layer-specific critical dynamics triggering perception",
  author   = "Marshel, James H and Kim, Yoon Seok and Machado, Timothy A and
              Quirin, Sean and Benson, Brandon and Kadmon, Jonathan and Raja,
              Cephra and Chibukhchyan, Adelaida and Ramakrishnan, Charu and
              Inoue, Masatoshi and Shane, Janelle C and McKnight, Douglas J and
              Yoshizawa, Susumu and Kato, Hideaki E and Ganguli, Surya and
              Deisseroth, Karl",
  abstract = "Perceptual experiences may arise from neuronal activity patterns
              in mammalian neocortex. We probed mouse neocortex during visual
              discrimination using a red-shifted channelrhodopsin (ChRmine,
              discovered through structure-guided genome mining) alongside
              multiplexed multiphoton-holography (MultiSLM), achieving control
              of individually specified neurons spanning large cortical volumes
              with millisecond precision. Stimulating a critical number of
              stimulus-orientation-selective neurons drove widespread
              recruitment of functionally related neurons, a process enhanced
              by (but not requiring) orientation-discrimination task learning.
              Optogenetic targeting of orientation-selective ensembles elicited
              correct behavioral discrimination. Cortical layer-specific
              dynamics were apparent, as emergent neuronal activity
              asymmetrically propagated from layer 2/3 to layer 5, and smaller
              layer 5 ensembles were as effective as larger layer 2/3 ensembles
              in eliciting orientation discrimination behavior. Population
              dynamics emerging after optogenetic stimulation both correctly
              predicted behavior and resembled natural internal representations
              of visual stimuli at cellular resolution over volumes of cortex.",
  journal  = "Science",
  volume   =  365,
  number   =  6453,
  month    =  aug,
  year     =  2019,
  keywords = "unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Marshel2019-id,
  title    = "Cortical layer--specific critical dynamics triggering perception",
  author   = "Marshel, James H and Kim, Yoon Seok and Machado, Timothy A and
              Quirin, Sean and Benson, Brandon and Kadmon, Jonathan and Raja,
              Cephra and Chibukhchyan, Adelaida and Ramakrishnan, Charu and
              Inoue, Masatoshi and Shane, Janelle C and McKnight, Douglas J and
              Yoshizawa, Susumu and Kato, Hideaki E and Ganguli, Surya and
              Deisseroth, Karl",
  abstract = "Perceptual experiences may arise from neuronal activity patterns
              in mammalian neocortex. We probed mouse neocortex during visual
              discrimination using a red-shifted channelrhodopsin (ChRmine,
              discovered through structure-guided genome mining) alongside
              multiplexed multiphoton-holography (MultiSLM), achieving control
              of individually specified neurons spanning large cortical volumes
              with millisecond precision. Stimulating a critical number of
              stimulus-orientation-selective neurons drove widespread
              recruitment of functionally related neurons, a process enhanced
              by (but not requiring) orientation-discrimination task learning.
              Optogenetic targeting of orientation-selective ensembles elicited
              correct behavioral discrimination. Cortical layer--specific
              dynamics were apparent, as emergent neuronal activity
              asymmetrically propagated from layer 2/3 to layer 5, and smaller
              layer 5 ensembles were as effective as larger layer 2/3 ensembles
              in eliciting orientation discrimination behavior. Population
              dynamics emerging after optogenetic stimulation both correctly
              predicted behavior and resembled natural internal representations
              of visual stimuli at cellular resolution over volumes of cortex.",
  journal  = "Science",
  volume   =  365,
  number   =  6453,
  pages    = "eaaw5202",
  year     =  2019,
  keywords = "unread;primate vision;ERC Consolidator 2023"
}

@ARTICLE{Luo2021-br,
  title     = "Architectures of neuronal circuits",
  author    = "Luo, Liqun",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  373,
  number    =  6559,
  month     =  sep,
  year      =  2021,
  keywords  = "read next;unread;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Froudarakis2019-yt,
  title    = "The Visual Cortex in Context",
  author   = "Froudarakis, Emmanouil and Fahey, Paul G and Reimer, Jacob and
              Smirnakis, Stelios M and Tehovnik, Edward J and Tolias, Andreas S",
  abstract = "In this article, we review the anatomical inputs and outputs to
              the mouse primary visual cortex, area V1. Our survey of data from
              the Allen Institute Mouse Connectivity project indicates that
              mouse V1 is highly interconnected with both cortical and
              subcortical brain areas. This pattern of innervation allows for
              computations that depend on the state of the animal and on
              behavioral goals, which contrasts with simple feedforward,
              hierarchical models of visual processing. Thus, to have an
              accurate description of the function of V1 during mouse behavior,
              its involvement with the rest of the brain circuitry has to be
              considered. Finally, it remains an open question whether the
              primary visual cortex of higher mammals displays the same degree
              of sensorimotor integration in the early visual system.",
  journal  = "Annual Review of Vision Science",
  volume   =  5,
  pages    = "317--339",
  year     =  2019,
  keywords = "V1 circuits; behavioral state; corticofugal projections;
              corticopetal projections; sensorimotor control; transcortical
              projections;4 behavior;4 mouse;read;rodent vision;ERC
              Consolidator 2023"
}

@ARTICLE{Glickfeld2017-fk,
  title    = "{Higher-Order} Areas of the Mouse Visual Cortex",
  author   = "Glickfeld, Lindsey L and Olsen, Shawn R",
  abstract = "The brain has evolved to transform sensory information in the
              environment into neural representations that can be used for
              perception and action. Higher-order sensory cortical areas, with
              their increasingly complex receptive fields and integrative
              properties, are thought to be critical nodes for this function.
              This is especially true in the primate visual cortex, in which
              functionally specialized areas are engaged in parallel streams to
              support diverse computations. Recent anatomical and physiological
              studies of the mouse visual cortex have revealed a similarly
              complex network of specialized higher-order areas. This structure
              provides a useful model for determining the synaptic and circuit
              mechanisms through which information is transformed across
              distinct processing stages. In this review, we summarize the
              current knowledge on the layout, connectivity, and functional
              properties of the higher visual areas in the mouse. In addition,
              we speculate on the contribution of these areas to perception and
              action, and how knowledge of the mouse visual system can inform
              us about the principles that govern information processing in
              integrated networks.",
  journal  = "Annu Rev Vis Sci",
  volume   =  3,
  pages    = "251--273",
  month    =  sep,
  year     =  2017,
  keywords = "connectivity; functional specialization; hierarchical and
              parallel processing; higher visual area; mouse; visual cortex;4
              mouse;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Mikulasch2022-mc,
  title    = "Visuomotor Mismatch Responses as a Hallmark of Explaining Away in
              Causal Inference",
  author   = "Mikulasch, Fabian A and Rudelt, Lucas and Priesemann, Viola",
  abstract = "How are visuomotor mismatch responses in primary visual cortex
              embedded into cortical processing? We here show that mismatch
              responses can be understood as the result of a cooperation of
              motor and visual areas to jointly explain optic flow. This
              cooperation requires that optic flow is not explained redundantly
              by both areas, meaning that optic flow inputs to V1 that are
              predictable from motor neurons should be canceled (i.e.,
              explained away). As a result, neurons in V1 represent only
              external causes of optic flow, which could allow the animal to
              easily detect movements that are independent of its own
              locomotion. We implement the proposed model in a spiking neural
              network, where coding errors are computed in dendrites and
              synaptic weights are learned with voltage-dependent plasticity
              rules. We find that both positive and negative mismatch responses
              arise, providing an alternative to the prevailing idea that
              visuomotor mismatch responses are linked to dedicated neurons for
              error computation. These results also provide a new perspective
              on several other recent observations of cross-modal neural
              interactions in cortex.",
  journal  = "Neural Comput.",
  volume   =  35,
  number   =  1,
  pages    = "27--37",
  month    =  dec,
  year     =  2022,
  keywords = "read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Prins2012-gn,
  title    = "The psychometric function: the lapse rate revisited",
  author   = "Prins, Nicolaas",
  abstract = "In their influential paper, Wichmann and Hill (2001) have shown
              that the threshold and slope estimates of a psychometric function
              may be severely biased when it is assumed that the lapse rate
              equals zero but lapses do, in fact, occur. Based on a large
              number of simulated experiments, Wichmann and Hill claim that
              threshold and slope estimates are essentially unbiased when one
              allows the lapse rate to vary within a rectangular prior during
              the fitting procedure. Here, I replicate Wichmann and Hill's
              finding that significant bias in parameter estimates results when
              one assumes that the lapse rate equals zero but lapses do occur,
              but fail to replicate their finding that freeing the lapse rate
              eliminates this bias. Instead, I show that significant and
              systematic bias remains in both threshold and slope estimates
              even when one frees the lapse rate according to Wichmann and
              Hill's suggestion. I explain the mechanisms behind the bias and
              propose an alternative strategy to incorporate the lapse rate
              into psychometric function models, which does result in
              essentially unbiased parameter estimates.",
  journal  = "J. Vis.",
  volume   =  12,
  number   =  6,
  month    =  jun,
  year     =  2012,
  keywords = "4 behavior;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Datta2019-vq,
  title    = "{Q\&A}: Understanding the composition of behavior",
  author   = "Datta, Sandeep Robert",
  abstract = "Understanding the brain requires understanding behavior. New
              machine vision and learning techniques are poised to
              revolutionize our ability to analyze behaviors exhibited by
              animals in the laboratory. Here we describe one such method,
              Motion Sequencing (MoSeq), which combines three-dimensional (3D)
              imaging with unsupervised machine learning techniques to identify
              the syllables and grammar that comprise mouse body language. This
              Q\&A situates MoSeq within the array of novel methods currently
              being developed for behavioral analysis, enumerates its relative
              strengths and weaknesses, and describes its future trajectory.",
  journal  = "BMC Biol.",
  volume   =  17,
  number   =  1,
  pages    = "44",
  month    =  may,
  year     =  2019,
  keywords = "4 behavior;read;ERC Consolidator 2023",
  language = "en"
}

@INPROCEEDINGS{Klindt2017-sb,
  title     = "Neural system identification for large populations separating
               ``what'' and ``where''",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Klindt, D A and Ecker, A S and Euler, T and Bethge, M",
  abstract  = "Neuroscientists classify neurons into different types that
               perform similar computations at different locations in the
               visual field. Traditional methods for neural system
               identification do not capitalize on this separation of 'what'
               and 'where'. Learning deep convolutional feature spaces that are
               shared among many neurons provides an exciting path forward, but
               the architectural design needs to account for data limitations:
               While new experimental techniques enable recordings from
               thousands of neurons, experimental time is limited so that one
               can sample only a small fraction of each neuron's response
               space. Here, we show that a major bottleneck for fitting
               convolutional neural networks (CNNs) to neural data is the
               estimation of the individual receptive field locations, a
               problem that has been scratched only at the surface thus far. We
               propose a CNN architecture with a sparse readout layer
               factorizing the spatial (where) and feature (what) dimensions.
               Our network scales well to thousands of neurons and short
               recordings and can be trained end-to-end. We evaluate this
               architecture on ground-truth data to explore the challenges and
               limitations of CNN-based system identification. Moreover, we
               show that our network model outperforms current state-of-the art
               system identification models of mouse primary visual cortex.",
  pages     = "4--6",
  year      =  2017,
  keywords  = "system identification;ERC Consolidator 2023"
}

@ARTICLE{Adelson1985-re,
  title    = "Spatiotemporal energy models for the perception of motion",
  author   = "Adelson, E H and Bergen, J R",
  abstract = "A motion sequence may be represented as a single pattern in x-y-t
              space; a velocity of motion corresponds to a three-dimensional
              orientation in this space. Motion sinformation can be extracted
              by a system that responds to the oriented spatiotemporal energy.
              We discuss a class of models for human motion mechanisms in which
              the first stage consists of linear filters that are oriented in
              space-time and tuned in spatial frequency. The outputs of
              quadrature pairs of such filters are squared and summed to give a
              measure of motion energy. These responses are then fed into an
              opponent stage. Energy models can be built from elements that are
              consistent with known physiology and psychophysics, and they
              permit a qualitative understanding of a variety of motion
              phenomena.",
  journal  = "J. Opt. Soc. Am.",
  volume   =  2,
  number   =  2,
  pages    = "284--299",
  month    =  feb,
  year     =  1985,
  keywords = "\_imported;ERC Consolidator 2023"
}

@ARTICLE{Cadieu2014-gc,
  title    = "Deep neural networks rival the representation of primate {IT}
              cortex for core visual object recognition",
  author   = "Cadieu, Charles F and Hong, Ha and Yamins, Daniel L K and Pinto,
              Nicolas and Ardila, Diego and Solomon, Ethan A and Majaj, Najib J
              and DiCarlo, James J",
  abstract = "The primate visual system achieves remarkable visual object
              recognition performance even in brief presentations, and under
              changes to object exemplar, geometric transformations, and
              background variation (a.k.a. core visual object recognition).
              This remarkable performance is mediated by the representation
              formed in inferior temporal (IT) cortex. In parallel, recent
              advances in machine learning have led to ever higher performing
              models of object recognition using artificial deep neural
              networks (DNNs). It remains unclear, however, whether the
              representational performance of DNNs rivals that of the brain. To
              accurately produce such a comparison, a major difficulty has been
              a unifying metric that accounts for experimental limitations,
              such as the amount of noise, the number of neural recording
              sites, and the number of trials, and computational limitations,
              such as the complexity of the decoding classifier and the number
              of classifier training examples. In this work, we perform a
              direct comparison that corrects for these experimental
              limitations and computational considerations. As part of our
              methodology, we propose an extension of ``kernel analysis'' that
              measures the generalization accuracy as a function of
              representational complexity. Our evaluations show that, unlike
              previous bio-inspired models, the latest DNNs rival the
              representational performance of IT cortex on this visual object
              recognition task. Furthermore, we show that models that perform
              well on measures of representational performance also perform
              well on measures of representational similarity to IT, and on
              measures of predicting individual IT multi-unit responses.
              Whether these DNNs rely on computational mechanisms similar to
              the primate visual system is yet to be determined, but, unlike
              all previous bio-inspired models, that possibility cannot be
              ruled out merely on representational performance grounds.",
  journal  = "PLoS Comput. Biol.",
  volume   =  10,
  number   =  12,
  pages    = "e1003963",
  year     =  2014,
  keywords = "\_imported;ERC Consolidator 2023"
}

@ARTICLE{Antolik2016-va,
  title    = "Model Constrained by Visual Hierarchy Improves Prediction of
              Neural Responses to Natural Scenes",
  author   = "Antol{\'\i}k, J and Hofer, S B and Bednar, J A and Mrsic-flogel,
              T D",
  journal  = "PLoS Comput. Biol.",
  pages    = "1--22",
  year     =  2016,
  keywords = "microns;ERC Consolidator 2023"
}

@ARTICLE{Burg2021-yg,
  title    = "Learning divisive normalization in primary visual cortex",
  author   = "Burg, Max F and Cadena, Santiago A and Denfield, George H and
              Walker, Edgar Y and Tolias, Andreas S and Bethge, Matthias and
              Ecker, Alexander S",
  abstract = "Divisive normalization (DN) is a prominent computational building
              block in the brain that has been proposed as a canonical cortical
              operation. Numerous experimental studies have verified its
              importance for capturing nonlinear neural response properties to
              simple, artificial stimuli, and computational studies suggest
              that DN is also an important component for processing natural
              stimuli. However, we lack quantitative models of DN that are
              directly informed by measurements of spiking responses in the
              brain and applicable to arbitrary stimuli. Here, we propose a DN
              model that is applicable to arbitrary input images. We test its
              ability to predict how neurons in macaque primary visual cortex
              (V1) respond to natural images, with a focus on nonlinear
              response properties within the classical receptive field. Our
              model consists of one layer of subunits followed by learned
              orientation-specific DN. It outperforms linear-nonlinear and
              wavelet-based feature representations and makes a significant
              step towards the performance of state-of-the-art convolutional
              neural network (CNN) models. Unlike deep CNNs, our compact DN
              model offers a direct interpretation of the nature of
              normalization. By inspecting the learned normalization pool of
              our model, we gained insights into a long-standing question about
              the tuning properties of DN that update the current textbook
              description: we found that within the receptive field oriented
              features were normalized preferentially by features with similar
              orientation rather than non-specifically as currently assumed.",
  journal  = "PLoS Comput. Biol.",
  volume   =  17,
  number   =  6,
  pages    = "e1009028",
  month    =  jun,
  year     =  2021,
  keywords = "read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Chebolu2022-tb,
  title    = "Vigilance, arousal, and acetylcholine: Optimal control of
              attention in a simple detection task",
  author   = "Chebolu, Sahiti and Dayan, Peter and Lloyd, Kevin",
  abstract = "Paying attention to particular aspects of the world or being more
              vigilant in general can be interpreted as forms of 'internal'
              action. Such arousal-related choices come with the benefit of
              increasing the quality and situational appropriateness of
              information acquisition and processing, but incur potentially
              expensive energetic and opportunity costs. One implementational
              route for these choices is widespread ascending neuromodulation,
              including by acetylcholine (ACh). The key computational question
              that elective attention poses for sensory processing is when it
              is worthwhile paying these costs, and this includes consideration
              of whether sufficient information has yet been collected to
              justify the higher signal-to-noise ratio afforded by greater
              attention and, particularly if a change in attentional state is
              more expensive than its maintenance, when states of heightened
              attention ought to persist. We offer a partially observable
              Markov decision-process treatment of optional attention in a
              detection task, and use it to provide a qualitative model of the
              results of studies using modern techniques to measure and
              manipulate ACh in rodents performing a similar task.",
  journal  = "PLoS Comput. Biol.",
  volume   =  18,
  number   =  10,
  pages    = "e1010642",
  month    =  oct,
  year     =  2022,
  keywords = "4 behavior;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Glaser2020-ax,
  title    = "Machine Learning for Neural Decoding",
  author   = "Glaser, Joshua I and Benjamin, Ari S and Chowdhury, Raeed H and
              Perich, Matthew G and Miller, Lee E and Kording, Konrad P",
  abstract = "Despite rapid advances in machine learning tools, the majority of
              neural decoding approaches still use traditional methods. Modern
              machine learning tools, which are versatile and easy to use, have
              the potential to significantly improve decoding performance. This
              tutorial describes how to effectively apply these algorithms for
              typical decoding problems. We provide descriptions, best
              practices, and code for applying common machine learning methods,
              including neural networks and gradient boosting. We also provide
              detailed comparisons of the performance of various methods at the
              task of decoding spiking activity in motor cortex, somatosensory
              cortex, and hippocampus. Modern methods, particularly neural
              networks and ensembles, significantly outperform traditional
              approaches, such as Wiener and Kalman filters. Improving the
              performance of neural decoding algorithms allows neuroscientists
              to better understand the information contained in a neural
              population and can help to advance engineering applications such
              as brain-machine interfaces. Our code package is available at
              github.com/kordinglab/neural\_decoding.",
  journal  = "eNeuro",
  volume   =  7,
  number   =  4,
  month    =  aug,
  year     =  2020,
  keywords = "Deep learning; Hippocampus; Machine learning; Motor cortex;
              Neural data analysis; Neural decoding; Somatosensory cortex;read
              next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Garrett2014-zm,
  title    = "Topography and areal organization of mouse visual cortex",
  author   = "Garrett, Marina E and Nauhaus, Ian and Marshel, James H and
              Callaway, Edward M",
  abstract = "To guide future experiments aimed at understanding the mouse
              visual system, it is essential that we have a solid handle on the
              global topography of visual cortical areas. Ideally, the method
              used to measure cortical topography is objective, robust, and
              simple enough to guide subsequent targeting of visual areas in
              each subject. We developed an automated method that uses
              retinotopic maps of mouse visual cortex obtained with intrinsic
              signal imaging (Schuett et al., 2002; Kalatsky and Stryker, 2003;
              Marshel et al., 2011) and applies an algorithm to automatically
              identify cortical regions that satisfy a set of quantifiable
              criteria for what constitutes a visual area. This approach
              facilitated detailed parcellation of mouse visual cortex,
              delineating nine known areas (primary visual cortex, lateromedial
              area, anterolateral area, rostrolateral area, anteromedial area,
              posteromedial area, laterointermediate area, posterior area, and
              postrhinal area), and revealing two additional areas that have
              not been previously described as visuotopically mapped in mice
              (laterolateral anterior area and medial area). Using the
              topographic maps and defined area boundaries from each animal, we
              characterized several features of map organization, including
              variability in area position, area size, visual field coverage,
              and cortical magnification. We demonstrate that higher areas in
              mice often have representations that are incomplete or biased
              toward particular regions of visual space, suggestive of
              specializations for processing specific types of information
              about the environment. This work provides a comprehensive
              description of mouse visuotopic organization and describes
              essential tools for accurate functional localization of visual
              areas.",
  journal  = "Journal of Neuroscience",
  volume   =  34,
  number   =  37,
  pages    = "12587--12600",
  month    =  sep,
  year     =  2014,
  keywords = "extrastriate; imaging; mouse; retinotopy; topography; visual
              cortex;4 brainstate;read next;unread;rodent vision;ERC
              Consolidator 2023",
  language = "en"
}

@ARTICLE{Cohen2022-hy,
  title    = "Recent Advances at the Interface of Neuroscience and Artificial
              Neural Networks",
  author   = "Cohen, Yarden and Engel, Tatiana A and Langdon, Christopher and
              Lindsay, Grace W and Ott, Torben and Peters, Megan A K and Shine,
              James M and Breton-Provencher, Vincent and Ramaswamy, Srikanth",
  abstract = "Biological neural networks adapt and learn in diverse behavioral
              contexts. Artificial neural networks (ANNs) have exploited
              biological properties to solve complex problems. However, despite
              their effectiveness for specific tasks, ANNs are yet to realize
              the flexibility and adaptability of biological cognition. This
              review highlights recent advances in computational and
              experimental research to advance our understanding of biological
              and artificial intelligence. In particular, we discuss critical
              mechanisms from the cellular, systems, and cognitive neuroscience
              fields that have contributed to refining the architecture and
              training algorithms of ANNs. Additionally, we discuss how recent
              work used ANNs to understand complex neuronal correlates of
              cognition and to process high throughput behavioral data.",
  journal  = "J. Neurosci.",
  volume   =  42,
  number   =  45,
  pages    = "8514--8523",
  month    =  nov,
  year     =  2022,
  keywords = "artificial neural networks; behavior; cognition; neuromodulators;
              plasticity; vision;4 mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{McAdams1999-cs,
  title     = "Effects of Attention on {Orientation-Tuning} Functions of Single
               Neurons in Macaque Cortical Area {V4}",
  author    = "McAdams, Carrie J and Maunsell, John H R",
  abstract  = "We examined how attention affected the orientation tuning of 262
               isolated neurons in extrastriate area V4 and 135 neurons in area
               V1 of two rhesus monkeys. The animals were trained to perform a
               delayed match-to-sample task in which oriented stimuli were
               presented in the receptive field of the neuron being recorded.
               On some trials the animals were instructed to pay attention to
               those stimuli, and on other trials they were instructed to pay
               attention to other stimuli outside the receptive field. In this
               way, orientation-tuning curves could be constructed from
               neuronal responses collected in two behavioral states: one in
               which those stimuli were attended by the animal and one in which
               those stimuli were ignored by the animal. We fit Gaussians to
               the neuronal responses to twelve different orientations for each
               behavioral state. Although attention enhanced the responses of
               V4 neurons (median 26\% increase) and V1 neurons (median 8\%
               increase), selectivity, as measured by the width of its
               orientation-tuning curve, was not systematically altered by
               attention. The effects of attention were consistent with a
               multiplicative scaling of the driven response to all
               orientations. We also found that attention did not cause
               systematic changes in the undriven activity of the neurons.",
  journal   = "J. Neurosci.",
  publisher = "Society for Neuroscience",
  volume    =  19,
  number    =  1,
  pages     = "431--441",
  month     =  jan,
  year      =  1999,
  keywords  = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023",
  language  = "en"
}

@ARTICLE{Zagha2022-fc,
  title    = "The Importance of Accounting for Movement When Relating Neuronal
              Activity to Sensory and Cognitive Processes",
  author   = "Zagha, Edward and Erlich, Jeffrey C and Lee, Soohyun and Lur,
              Gyorgy and O'Connor, Daniel H and Steinmetz, Nicholas A and
              Stringer, Carsen and Yang, Hongdian",
  abstract = "A surprising finding of recent studies in mouse is the dominance
              of widespread movement-related activity throughout the brain,
              including in early sensory areas. In awake subjects, failing to
              account for movement risks misattributing movement-related
              activity to other (e.g., sensory or cognitive) processes. In this
              article, we (1) review task designs for separating task-related
              and movement-related activity, (2) review three ``case studies''
              in which not considering movement would have resulted in
              critically different interpretations of neuronal function, and
              (3) discuss functional couplings that may prevent us from ever
              fully isolating sensory, motor, and cognitive-related activity.
              Our main thesis is that neural signals related to movement are
              ubiquitous, and therefore ought to be considered first and
              foremost when attempting to correlate neuronal activity with
              task-related processes.",
  journal  = "J. Neurosci.",
  volume   =  42,
  number   =  8,
  pages    = "1375--1382",
  month    =  feb,
  year     =  2022,
  keywords = "behavior; cognition; movement; neural coding; sensorimotor;4
              mouse;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Huk2018-ez,
  title    = "Beyond {Trial-Based} Paradigms: Continuous Behavior, Ongoing
              Neural Activity, and Natural Stimuli",
  author   = "Huk, Alexander and Bonnen, Kathryn and He, Biyu J",
  abstract = "The vast majority of experiments examining perception and
              behavior are conducted using experimental paradigms that adhere
              to a rigid trial structure: each trial consists of a brief and
              discrete series of events and is regarded as independent from all
              other trials. The assumptions underlying this structure ignore
              the reality that natural behavior is rarely discrete, brain
              activity follows multiple time courses that do not necessarily
              conform to the trial structure, and the natural environment has
              statistical structure and dynamics that exhibit long-range
              temporal correlation. Modern advances in statistical modeling and
              analysis offer tools that make it feasible for experiments to
              move beyond rigid independent and identically distributed trial
              structures. Here we review literature that serves as evidence for
              the feasibility and advantages of moving beyond trial-based
              paradigms to understand the neural basis of perception and
              cognition. Furthermore, we propose a synthesis of these efforts,
              integrating the characterization of natural stimulus properties
              with measurements of continuous neural activity and behavioral
              outputs within the framework of sensory-cognitive-motor loops.
              Such a framework provides a basis for the study of natural
              statistics, naturalistic tasks, and/or slow fluctuations in brain
              activity, which should provide starting points for important
              generalizations of analytical tools in neuroscience and
              subsequent progress in understanding the neural basis of
              perception and cognition.",
  journal  = "J. Neurosci.",
  volume   =  38,
  number   =  35,
  pages    = "7551--7558",
  month    =  aug,
  year     =  2018,
  keywords = "read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Murgas2020-as,
  title    = "Unique Spatial Integration in Mouse Primary Visual Cortex and
              Higher Visual Areas",
  author   = "Murgas, Kevin A and Wilson, Ashley M and Michael, Valerie and
              Glickfeld, Lindsey L",
  abstract = "Neurons in the visual system integrate over a wide range of
              spatial scales. This diversity is thought to enable both local
              and global computations. To understand how spatial information is
              encoded across the mouse visual system, we use two-photon imaging
              to measure receptive fields (RFs) and size-tuning in primary
              visual cortex (V1) and three downstream higher visual areas
              (HVAs: LM (lateromedial), AL (anterolateral), and PM
              (posteromedial)) in mice of both sexes. Neurons in PM, compared
              with V1 or the other HVAs, have significantly larger RF sizes and
              less surround suppression, independent of stimulus eccentricity
              or contrast. To understand how this specialization of RFs arises
              in the HVAs, we measured the spatial properties of V1 inputs to
              each area. Spatial integration of V1 axons was remarkably similar
              across areas and significantly different from the tuning of
              neurons in their target HVAs. Thus, unlike other visual features
              studied in this system, specialization of spatial integration in
              PM cannot be explained by specific projections from V1 to the
              HVAs. Further, the differences in RF properties could not be
              explained by differences in convergence of V1 inputs to the HVAs.
              Instead, our data suggest that distinct inputs from other areas
              or connectivity within PM may support the area's unique ability
              to encode global features of the visual scene, whereas V1, LM,
              and AL may be more specialized for processing local
              features.SIGNIFICANCE STATEMENT Surround suppression is a common
              feature of visual processing whereby large stimuli are less
              effective at driving neuronal responses than smaller stimuli.
              This is thought to enhance efficiency in the population code and
              enable higher-order processing of visual information, such as
              figure-ground segregation. However, this comes at the expense of
              global computations. Here we find that surround suppression is
              not equally represented across mouse visual areas: primary visual
              cortex has substantially more surround suppression than higher
              visual areas, and one higher area has significantly less
              suppression than two others examined, suggesting that these areas
              have distinct functional roles. Thus, we have identified a novel
              dimension of specialization in the mouse visual cortex that may
              enable both local and global computations.",
  journal  = "J. Neurosci.",
  volume   =  40,
  number   =  9,
  pages    = "1862--1873",
  month    =  feb,
  year     =  2020,
  keywords = "calcium imaging; contrast; mouse visual cortex; normalization;
              size tuning; surround suppression;4 behavior;4 mouse;read
              next;unread;ERC Consolidator 2023",
  language = "en"
}

@BOOK{Dadarlat2017-jw,
  title    = "Locomotion Enhances Neural Encoding of Visual Stimuli in Mouse
              {V1}",
  author   = "Dadarlat, Maria C and Stryker, Michael P",
  abstract = "Neurons in mouse primary visual cortex (V1) are selective for
              particular properties of visual stimuli. Locomotion causes a
              change in cortical state that leaves their selectivity unchanged
              but strengthens their responses. Both locomotion and the change
              in cortical state are thought to be initiated by projections from
              the mesencephalic locomotor region, the latter through a
              disinhibitory circuit in V1. By recording simultaneously from a
              large number of single neurons in alert mice viewing moving
              gratings, we investigated the relationship between locomotion and
              the information contained within the neural population. We found
              that locomotion improved encoding of visual stimuli in V1 by two
              mechanisms. First, locomotion-induced increases in firing rates
              enhanced the mutual information between visual stimuli and single
              neuron responses over a fixed window of time. Second, stimulus
              discriminability was improved, even for fixed population firing
              rates, because of a decrease in noise correlations across the
              population. These two mechanisms contributed differently to
              improvements in discriminability across cortical layers, with
              changes in firing rates most important in the upper layers and
              changes in noise correlations most important in layer V.
              Together, these changes resulted in a threefold to fivefold
              reduction in the time needed to precisely encode grating
              direction and orientation. These results support the hypothesis
              that cortical state shifts during locomotion to accommodate an
              increased load on the visual system when mice are
              moving.SIGNIFICANCE STATEMENT This paper contains three novel
              findings about the representation of information in neurons
              within the primary visual cortex of the mouse. First, we show
              that locomotion reduces by at least a factor of 3 the time needed
              for information to accumulate in the visual cortex that allows
              the distinction of different visual stimuli. Second, we show that
              the effect of locomotion is to increase information in cells of
              all layers of the visual cortex. Third, we show that the means by
              which information is enhanced by locomotion differs between the
              upper layers, where the major effect is the increasing of firing
              rates, and in layer V, where the major effect is the reduction in
              noise correlations.",
  volume   =  37,
  pages    = "3764--3775",
  year     =  2017,
  keywords = "read;behavior;brain state;color MEI;ERC Consolidator 2023"
}

@ARTICLE{Vintch2015-gc,
  title    = "A Convolutional Subunit Model for Neuronal Responses in Macaque
              {V1}",
  author   = "Vintch, B and Movshon, J A and Simoncelli, E P",
  abstract = "The response properties of neurons in the early stages of the
              visual system can be described using the rectified responses of a
              set of self-similar, spatially shifted linear filters. In macaque
              primary visual cortex (V1), simple cell responses can be captured
              with a single filter, whereas complex cells combine a set of
              filters, creating position invariance. These filters cannot be
              estimated using standard methods, such as spike-triggered
              averaging. Subspace methods like spike-triggered covariance can
              recover multiple filters but require substantial amounts of data,
              and recover an orthogonal basis for the subspace in which the
              filters reside, rather than the filters themselves. Here, we
              assume a linear-nonlinear-linear-nonlinear (LN-LN) cascade model
              in which the first LN stage consists of shifted
              (``convolutional'') copies of a single filter, followed by a
              common instantaneous nonlinearity. We refer to these initial LN
              elements as the ``subunits'' of the receptive field, and we allow
              two independent sets of subunits, each with its own filter and
              nonlinearity. The second linear stage computes a weighted sum of
              the subunit responses and passes the result through a final
              instantaneous nonlinearity. We develop a procedure to directly
              fit this model to electrophysiological data. When fit to data
              from macaque V1, the subunit model significantly outperforms
              three alternatives in terms of cross-validated accuracy and
              efficiency, and provides a robust, biologically plausible account
              of receptive field structure for all cell types encountered in
              V1. SIGNIFICANCE STATEMENT We present a new subunit model for
              neurons in primary visual cortex that significantly outperforms
              three alternative models in terms of cross-validated accuracy and
              efficiency, and provides a robust and biologically plausible
              account of the receptive field structure in these neurons across
              the full spectrum of response properties.",
  journal  = "J. Neurosci.",
  volume   =  35,
  number   =  44,
  pages    = "14829--14841",
  year     =  2015,
  keywords = "V1; model; receptive field;
              subunits;netgard;microns;recurrent;ERC Consolidator 2023"
}

@ARTICLE{Mineault2016-fk,
  title    = "Enhanced Spatial Resolution During Locomotion and Heightened
              Attention in Mouse Primary Visual Cortex",
  author   = "Mineault, Patrick J and Tring, Elaine and Trachtenberg, Joshua T
              and Ringach, Dario L",
  abstract = "We do not fully understand how behavioral state modulates the
              processing and transmission of sensory signals. Here, we studied
              the cortical representation of the retinal image in mice that
              spontaneously switched between a state of rest and a constricted
              pupil, and one of active locomotion and a dilated pupil,
              indicative of heightened attention. We measured the selectivity
              of neurons in primary visual cortex for orientation and spatial
              frequency, as well as their response gain, in these two
              behavioral states. Consistent with prior studies, we found that
              preferred orientation and spatial frequency remained invariant
              across states, whereas response gain increased during locomotion
              relative to rest. Surprisingly, relative gain, defined as the
              ratio between the gain during locomotion and the gain during
              rest, was not uniform across the population. Cells tuned to high
              spatial frequencies showed larger relative gain compared with
              those tuned to lower spatial frequencies. The preferential
              enhancement of high-spatial-frequency information was also
              reflected in our ability to decode the stimulus from population
              activity. Finally, we show that changes in gain originate from
              shifts in the operating point of neurons along a spiking
              nonlinearity as a function of behavioral state. Differences in
              the relative gain experienced by neurons with high and low
              spatial frequencies are due to corresponding differences in how
              these cells shift their operating points between behavioral
              states. SIGNIFICANCE STATEMENT How behavioral state modulates the
              processing and transmission of sensory signals remains poorly
              understood. Here, we show that the mean firing rate and neuronal
              gain increase during locomotion as a result in a shift of the
              operating point of neurons. We define relative gain as the ratio
              between the gain of neurons during locomotion and rest.
              Interestingly, relative gain is higher in cells with preferences
              for higher spatial frequencies than those with
              low-spatial-frequency selectivity. This means that, during a
              state of locomotion and heightened attention, the population
              activity in primary visual cortex can support better spatial
              acuity, a phenomenon that parallels the improved spatial
              resolution observed in human subjects during the allocation of
              spatial attention.",
  journal  = "J. Neurosci.",
  volume   =  36,
  number   =  24,
  pages    = "6382--6392",
  year     =  2016,
  keywords = "unread;read next;rodent vision;ERC Consolidator 2023"
}

@ARTICLE{Guclu2015-hv,
  title    = "Deep Neural Networks Reveal a Gradient in the Complexity of
              Neural Representations across the Ventral Stream",
  author   = "G{\"u}{\c c}l{\"u}, Umut and van Gerven, Marcel A J",
  abstract = "Converging evidence suggests that the primate ventral visual
              pathway encodes increasingly complex stimulus features in
              downstream areas. We quantitatively show that there indeed exists
              an explicit gradient for feature complexity in the ventral
              pathway of the human brain. This was achieved by mapping
              thousands of stimulus features of increasing complexity across
              the cortical sheet using a deep neural network. Our approach also
              revealed a fine-grained functional specialization of downstream
              areas of the ventral stream. Furthermore, it allowed decoding of
              representations from human brain activity at an unsurpassed
              degree of accuracy, confirming the quality of the developed
              approach. Stimulus features that successfully explained neural
              responses indicate that population receptive fields were
              explicitly tuned for object categorization. This provides strong
              support for the hypothesis that object categorization is a
              guiding principle in the functional organization of the primate
              ventral stream.",
  journal  = "J. Neurosci.",
  volume   =  35,
  number   =  27,
  pages    = "10005--10014",
  year     =  2015,
  keywords = "ERC Consolidator 2023"
}

@ARTICLE{Hilton2020-jz,
  title     = "Understanding {RL} vision",
  author    = "Hilton, Jacob and Cammarata, Nick and Carter, Shan and Goh,
               Gabriel and Olah, Chris",
  journal   = "Distill",
  publisher = "Distill Working Group",
  volume    =  5,
  number    =  11,
  month     =  nov,
  year      =  2020,
  keywords  = "4 behavior;read next;unread;ERC Consolidator 2023"
}

@UNPUBLISHED{Bowers2022-oq,
  title    = "Deep Problems with Neural Network Models of Human Vision",
  author   = "Bowers, Jeffrey S and Malhotra, Gaurav and Dujmovi{\'c}, Marin
              and Montero, Milton L and Tsvetkov, Christian and Biscione,
              Valerio and Puebla, Guillermo and Adolfi, Federico G and Hummel,
              John and Heaton, Rachel F and al., Et",
  abstract = "Deep neural networks (DNNs) have had extraordinary successes in
              classifying photographic images of objects and are often
              described as the best models of biological vision. This
              conclusion is largely based on three sets of findings: (1) DNNs
              are more accurate than any other model in classifying images
              taken from various datasets, (2) DNNs do the best job in
              predicting the pattern of human errors in classifying objects
              taken from various behavioral benchmark datasets, and (3) DNNs do
              the best job in predicting brain signals in response to images
              taken from various brain benchmark datasets (e.g., single cell
              responses or fMRI data). However, most behavioral and brain
              benchmarks report the outcomes of observational experiments that
              do not manipulate any independent variables, and we show that the
              good prediction on these datasets may be mediated by DNNs that
              share little overlap with biological vision. More
              problematically, we show that DNNs account for almost no results
              from psychological research. This contradicts the common claim
              that DNNs are good, let alone the best, models of human object
              recognition. We argue that theorists interested in developing
              biologically plausible models of human vision need to direct
              their attention to explaining psychological findings. More
              generally, theorists need to build models that explain the
              results of experiments that manipulate independent variables
              designed to test hypotheses rather than compete on predicting
              observational data. We conclude by briefly summarizing various
              promising modelling approaches that focus on psychological data.",
  month    =  apr,
  year     =  2022,
  keywords = "Brain-Score; Computational Neuroscience; Convolutional Neural
              Network; Deep Neural Networks; Human Vision; Object
              Identification; Object Recognition; Representational Similarity
              Analysis;unread;complexity;complexity;ERC Consolidator 2023"
}

@ARTICLE{Benyamini2015-sr,
  title    = "Optimal feedback control successfully explains changes in neural
              modulations during experiments with brain-machine interfaces",
  author   = "Benyamini, Miri and Zacksenhouse, Miriam",
  abstract = "Recent experiments with brain-machine-interfaces (BMIs) indicate
              that the extent of neural modulations increased abruptly upon
              starting to operate the interface, and especially after the
              monkey stopped moving its hand. In contrast, neural modulations
              that are correlated with the kinematics of the movement remained
              relatively unchanged. Here we demonstrate that similar changes
              are produced by simulated neurons that encode the relevant
              signals generated by an optimal feedback controller during
              simulated BMI experiments. The optimal feedback controller relies
              on state estimation that integrates both visual and
              proprioceptive feedback with prior estimations from an internal
              model. The processing required for optimal state estimation and
              control were conducted in the state-space, and neural recording
              was simulated by modeling two populations of neurons that encode
              either only the estimated state or also the control signal. Spike
              counts were generated as realizations of doubly stochastic
              Poisson processes with linear tuning curves. The model
              successfully reconstructs the main features of the kinematics and
              neural activity during regular reaching movements. Most
              importantly, the activity of the simulated neurons successfully
              reproduces the observed changes in neural modulations upon
              switching to brain control. Further theoretical analysis and
              simulations indicate that increasing the process noise during
              normal reaching movement results in similar changes in neural
              modulations. Thus, we conclude that the observed changes in
              neural modulations during BMI experiments can be attributed to
              increasing process noise associated with the imperfect BMI
              filter, and, more directly, to the resulting increase in the
              variance of the encoded signals associated with state estimation
              and the required control signal.",
  journal  = "Front. Syst. Neurosci.",
  volume   =  9,
  pages    = "71",
  month    =  may,
  year     =  2015,
  keywords = "brain-machine interfaces; computational motor control; neural
              modulations; optimal feedback control; process noise;4
              behavior;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Bohnslav2021-gz,
  title    = "{DeepEthogram}, a machine learning pipeline for supervised
              behavior classification from raw pixels",
  author   = "Bohnslav, James P and Wimalasena, Nivanthika K and Clausing,
              Kelsey J and Dai, Yu Y and Yarmolinsky, David A and Cruz,
              Tom{\'a}s and Kashlan, Adam D and Chiappe, M Eugenia and Orefice,
              Lauren L and Woolf, Clifford J and Harvey, Christopher D",
  abstract = "Videos of animal behavior are used to quantify researcher-defined
              behaviors of interest to study neural function, gene mutations,
              and pharmacological therapies. Behaviors of interest are often
              scored manually, which is time-consuming, limited to few
              behaviors, and variable across researchers. We created
              DeepEthogram: software that uses supervised machine learning to
              convert raw video pixels into an ethogram, the behaviors of
              interest present in each video frame. DeepEthogram is designed to
              be general-purpose and applicable across species, behaviors, and
              video-recording hardware. It uses convolutional neural networks
              to compute motion, extract features from motion and images, and
              classify features into behaviors. Behaviors are classified with
              above 90\% accuracy on single frames in videos of mice and flies,
              matching expert-level human performance. DeepEthogram accurately
              predicts rare behaviors, requires little training data, and
              generalizes across subjects. A graphical interface allows
              beginning-to-end analysis without end-user programming.
              DeepEthogram's rapid, automatic, and reproducible labeling of
              researcher-defined behaviors of interest may accelerate and
              enhance supervised behavior analysis. Code is available at:
              https://github.com/jbohnslav/deepethogram.",
  journal  = "Elife",
  volume   =  10,
  month    =  sep,
  year     =  2021,
  keywords = "D. melanogaster; behavior analysis; computer vision; deep
              learning; mouse; neuroscience;read next;unread;ERC Consolidator
              2023",
  language = "en"
}

@ARTICLE{Holmgren2021-jv,
  title    = "Visual pursuit behavior in mice maintains the pursued prey on the
              retinal region with least optic flow",
  author   = "Holmgren, Carl D and Stahr, Paul and Wallace, Damian J and Voit,
              Kay-Michael and Matheson, Emily J and Sawinski, Juergen and
              Bassetto, Giacomo and Kerr, Jason Nd",
  abstract = "Mice have a large visual field that is constantly stabilized by
              vestibular ocular reflex (VOR) driven eye rotations that counter
              head-rotations. While maintaining their extensive visual coverage
              is advantageous for predator detection, mice also track and
              capture prey using vision. However, in the freely moving animal
              quantifying object location in the field of view is challenging.
              Here, we developed a method to digitally reconstruct and quantify
              the visual scene of freely moving mice performing a visually
              based prey capture task. By isolating the visual sense and
              combining a mouse eye optic model with the head and eye
              rotations, the detailed reconstruction of the digital environment
              and retinal features were projected onto the corneal surface for
              comparison, and updated throughout the behavior. By quantifying
              the spatial location of objects in the visual scene and their
              motion throughout the behavior, we show that the prey image
              consistently falls within a small area of the VOR-stabilized
              visual field. This functional focus coincides with the region of
              minimal optic flow within the visual field and consequently area
              of minimal motion-induced image-blur, as during pursuit mice ran
              directly toward the prey. The functional focus lies in the
              upper-temporal part of the retina and coincides with the reported
              high density-region of Alpha-ON sustained retinal ganglion cells.",
  journal  = "Elife",
  volume   =  10,
  month    =  oct,
  year     =  2021,
  keywords = "eye movements; freely moving behavior; methods development;
              mouse; neuroscience; optic flow; prey capture; vision;4
              behavior;4 mouse;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Straub2022-we,
  title    = "Putting perception into action with inverse optimal control for
              continuous psychophysics",
  author   = "Straub, Dominik and Rothkopf, Constantin A",
  abstract = "Psychophysical methods are a cornerstone of psychology, cognitive
              science, and neuroscience where they have been used to quantify
              behavior and its neural correlates for a vast range of mental
              phenomena. Their power derives from the combination of controlled
              experiments and rigorous analysis through signal detection
              theory. Unfortunately, they require many tedious trials and
              preferably highly trained participants. A recently developed
              approach, continuous psychophysics, promises to transform the
              field by abandoning the rigid trial structure involving binary
              responses and replacing it with continuous behavioral adjustments
              to dynamic stimuli. However, what has precluded wide adoption of
              this approach is that current analysis methods do not account for
              the additional variability introduced by the motor component of
              the task and therefore recover perceptual thresholds that are
              larger compared to equivalent traditional psychophysical
              experiments. Here, we introduce a computational analysis
              framework for continuous psychophysics based on Bayesian inverse
              optimal control. We show via simulations and previously published
              data that this not only recovers the perceptual thresholds but
              additionally estimates subjects' action variability, internal
              behavioral costs, and subjective beliefs about the experimental
              stimulus dynamics. Taken together, we provide further evidence
              for the importance of including acting uncertainties, subjective
              beliefs, and, crucially, the intrinsic costs of behavior, even in
              experiments seemingly only investigating perception.",
  journal  = "Elife",
  volume   =  11,
  month    =  sep,
  year     =  2022,
  keywords = "continuous psychophysics; human; inverse reinforcement learning;
              neuroscience; optimal control; perception and action; rational
              analysis;read;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Singer2018-sf,
  title    = "Sensory cortex is optimised for prediction of future input",
  author   = "Singer, Y and Teramoto, Y and Willmore, B D B and King, A J and
              Schnupp, J W H and Harper, N S",
  abstract = "Neurons in sensory cortex are tuned to diverse features in
              natural scenes. But what determines which features neurons become
              selective to? Here we explore the idea that neuronal selectivity
              is optimised to represent features in the recent sensory past
              that best predict immediate future inputs. We tested this
              hypothesis using simple feedforward neural networks, which were
              trained to predict the next few video or audio frames in clips of
              natural scenes. The networks developed receptive fields that
              closely matched those of real cortical neurons in different
              mammalian species, including the oriented spatial tuning of
              primary visual cortex, the frequency selectivity of primary
              auditory cortex and, most notably, their temporal tuning
              properties. Furthermore, the better a network predicted future
              inputs the more closely its receptive fields resembled those in
              the brain. This suggests that sensory processing is optimised to
              extract those features with the most capacity to predict future
              input.",
  journal  = "Elife",
  volume   =  7,
  pages    = "e31557",
  year     =  2018,
  keywords = "unread;normative theories;ERC Consolidator 2023"
}

@UNPUBLISHED{Cadena2019-jw,
  title    = "How well do deep neural networks trained on object recognition
              characterize the mouse visual system?",
  author   = "Cadena, Santiago A and Sinz, Fabian H and Muhammad, Taliah and
              Froudarakis, Emmanouil and Cobos, Erick and Walker, Edgar Y and
              Reimer, Jake and Bethge, Matthias and Tolias, Andreas and Ecker,
              Alexander S",
  abstract = "Recent work on modeling neural responses in the primate visual
              system has benefited from deep neural networks trained on
              large-scale object recognition, and found a hierarchical
              correspondence between layers of the artificial neural network
              and brain areas along the ventral visual stream. However, we
              neither know whether such task-optimized networks enable equally
              good models of the rodent visual system, nor if a similar
              hierarchical correspondence exists. Here, we address these
              questions in the mouse visual system by extracting features at
              several layers of a convolutional neural network (CNN) trained on
              ImageNet to predict the responses of thousands of neurons in four
              visual areas (V1, LM, AL, RL) to natural images. We found that
              the CNN features outperform classical subunit energy models, but
              found no evidence for an order of the areas we recorded via a
              correspondence to the hierarchy of CNN layers. Moreover, the same
              CNN but with random weights provided an equivalently useful
              feature space for predicting neural responses. Our results
              suggest that object recognition as a high-level task does not
              provide more discriminative features to characterize the mouse
              visual system than a random network. Unlike in the primate,
              training on ethologically relevant visually guided behaviors --
              beyond static object recognition -- may be needed to unveil the
              functional organization of the mouse visual cortex.",
  month    =  sep,
  year     =  2019,
  keywords = "own;SFB 1456 Mathematic of Experiment;ERC Consolidator 2023"
}

@ARTICLE{Schultheis2021-pu,
  title    = "Inverse optimal control adapted to the noise characteristics of
              the human sensorimotor system",
  author   = "Schultheis, Matthias and Straub, Dominik and Rothkopf, Constantin
              A",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  34,
  pages    = "9429--9442",
  year     =  2021,
  keywords = "read;ERC Consolidator 2023"
}

@INPROCEEDINGS{Merel2020-hf,
  title     = "Deep neuroethology of a virtual rodent",
  booktitle = "International Conference on Learning Representations",
  author    = "Merel, Josh and Aldarondo, Diego and Marshall, Jesse and Tassa,
               Yuval and Wayne, Greg and Olveczky, Bence",
  abstract  = "Parallel developments in neuroscience and deep learning have led
               to mutually productive exchanges, pushing our understanding of
               real and artificial neural networks in sensory and cognitive
               systems. However, this interaction between fields is less
               developed in the study of motor control. In this work, we
               develop a virtual rodent as a platform for the grounded study of
               motor activity in artificial models of embodied control. We then
               use this platform to study motor activity across contexts by
               training a model to solve four complex tasks. Using methods
               familiar to neuroscientists, we describe the behavioral
               representations and algorithms employed by different layers of
               the network using a neuroethological approach to characterize
               motor activity relative to the rodent's behavior and goals. We
               find that the model uses two classes of representations which
               respectively encode the task-specific behavioral strategies and
               task-invariant behavioral kinematics. These representations are
               reflected in the sequential activity and population dynamics of
               neural subpopulations. Overall, the virtual rodent facilitates
               grounded collaborations between deep reinforcement learning and
               motor neuroscience.",
  month     =  feb,
  year      =  2020,
  keywords  = "4 mouse;4 behavior;read;ERC Consolidator 2023"
}

@ARTICLE{Rezende2015-mx,
  title    = "Variational Inference with Normalizing Flows",
  author   = "Rezende, Danilo Jimenez and Mohamed, Shakir",
  abstract = "The choice of approximate posterior distribution is one of the
              core problems in variational inference. Most applications of
              variational inference employ simple families of posterior
              approximations in order to allow for efficient inference,
              focusing on mean-field or other simple structured approximations.
              This restriction has a significant impact on the quality of
              inferences made using variational methods. We introduce a new
              approach for specifying flexible, arbitrarily complex and
              scalable approximate posterior distributions. Our approximations
              are distributions constructed through a normalizing flow, whereby
              a simple initial density is transformed into a more complex one
              by applying a sequence of invertible transformations until a
              desired level of complexity is attained. We use this view of
              normalizing flows to develop categories of finite and
              infinitesimal flows and provide a unified view of approaches for
              constructing rich posterior approximations. We demonstrate that
              the theoretical advantages of having posteriors that better match
              the true posterior, combined with the scalability of amortized
              variational approaches, provides a clear improvement in
              performance and applicability of variational inference.",
  journal  = "1505.05770",
  year     =  2015,
  keywords = "unread;read next;probabilistic networks;2021 Bashiri Latent
              Flow;ERC Consolidator 2023"
}

@ARTICLE{Colonnier1981-oj,
  title    = "[Number of neurons and synapses in the visual cortex of different
              species]",
  author   = "Colonnier, M and O'Kusky, J",
  abstract = "The number of neurons under 1 mm2 of visual cortex (area 17) is
              about 200 000 in monkey and man, and it varies between 45 000 and
              70 000 in non-primates which have been studied. The number per
              hemisphere increases with the surface of area 17, passing from
              less than 1 million in mouse to about 538 million in man. The
              number of synapses under 1 mm2 of visual cortex has been
              estimated by different authors at between 480 million (mouse) and
              1270 million (rat) : the number per hemisphere increases with
              brain size from 32 billion in rat to 3 084 billion (x10(9)) in
              man. The number of synapses per neurons tends to be higher in
              species with fewer neurons per mm3. Our laminar study in monkey
              shows this correlation at the level of each lamina : those having
              the largest number of neurons per mm3 have the least number of
              synapses per neuron.",
  journal  = "Rev. Can. Biol.",
  volume   =  40,
  number   =  1,
  pages    = "91--99",
  month    =  mar,
  year     =  1981,
  keywords = "ERC Consolidator 2023",
  language = "fr"
}

@INPROCEEDINGS{Batty2019-nc,
  title     = "{BehaveNet}: nonlinear embedding and Bayesian neural decoding of
               behavioral videos",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Batty, Eleanor and Whiteway, Matthew and Saxena, Shreya and
               Biderman, Dan and Abe, Taiga and Musall, Simon and Gillis,
               Winthrop and Markowitz, Jeffrey and Churchland, Anne and
               Cunningham, John P and Datta, Sandeep R and Linderman, Scott and
               Paninski, Liam",
  editor    = "Wallach, H and Larochelle, H and Beygelzimer, A and
               d\textbackslashtextquotesingle Alch{\'e}-Buc, F and Fox, E and
               Garnett, R",
  publisher = "Curran Associates, Inc.",
  volume    =  32,
  year      =  2019,
  keywords  = "4 behavior;read next;unread;ERC Consolidator 2023"
}

@ARTICLE{Lehky1992-wf,
  title    = "Predicting responses of nonlinear neurons in monkey striate
              cortex to complex patterns",
  author   = "Lehky, S R R S R R and Sejnowski, T J J and Desimone, R",
  abstract = "The overwhelming majority of neurons in primate visual cortex are
              nonlinear. For those cells, the techniques of linear system
              analysis, used with some success to model retinal ganglion cells
              and striate simple cells, are of limited applicability. As a
              start toward understanding the properties of nonlinear visual
              neurons, we have recorded responses of striate complex cells to
              hundreds of images, including both simple stimuli (bars and
              sinusoids) as well as complex stimuli (random textures and 3-D
              shaded surfaces). The latter set tended to give the strongest
              response. We created a neural network model for each neuron using
              an iterative optimization algorithm. The recorded responses to
              some stimulus patterns (the training set) were used to create the
              model, while responses to other patterns were reserved for
              testing the networks. The networks predicted recorded responses
              to training set patterns with a median correlation of 0.95. They
              were able to predict responses to test stimuli not in the
              training set with a correlation of 0.78 overall, and a
              correlation of 0.65 for complex stimuli considered alone. Thus,
              they were able to capture much of the input/output transfer
              function of the neurons, even for complex patterns. Examining
              connection strengths within each network, different parts of the
              network appeared to handle information at different spatial
              scales. To gain further insights, the network models were
              inverted to construct ``optimal'' stimuli for each cell, and
              their receptive fields were mapped with high-resolution spots.
              The receptive field properties of complex cells could not be
              reduced to any simpler mathematical formulation than the network
              models themselves.",
  journal  = "J. Neurosci.",
  volume   =  12,
  number   =  9,
  pages    = "3568--3581",
  year     =  1992,
  keywords = "Animals; Female; Forecasting; Macaca mulatta; Nerve Net; Nerve
              Net: physiology; Neural Networks (Computer); Neurons; Neurons:
              physiology; Photic Stimulation; Visual Cortex; Visual Cortex:
              cytology; Visual Cortex: physiology; Visual Perception; Visual
              Perception: physiology;recurrent;inception;system
              identification;ERC Consolidator 2023"
}

@ARTICLE{Hubel1959-zs,
  title    = "Receptive fields of single neurones in the cat's striate cortex",
  author   = "Hubel, D H and Wiesel, T N",
  journal  = "J. Physiol.",
  volume   =  148,
  pages    = "574--591",
  year     =  1959,
  keywords = "cerebral cortex; cerebral cortex physiology; neurons; neurons
              physiology;\_imported;ERC Consolidator 2023"
}

@INPROCEEDINGS{Ecker2018-gz,
  title     = "A rotation-equivariant convolutional neural network model of
               primary visual cortex",
  booktitle = "International Conference on Learning Representations",
  author    = "Ecker, Alexander S and Sinz, Fabian H and Froudarakis, Emmanouil
               and Fahey, Paul G and Cadena, Santiago A and Walker, Edgar Y and
               Cobos, Erick and Reimer, Jacob and Tolias, Andreas S and Bethge,
               Matthias",
  abstract  = "Classical models describe primary visual cortex (V1) as a filter
               bank of orientation-selective linear-nonlinear (LN) or energy
               models, but these models fail to predict neural responses to
               natural stimuli accurately. Recent work shows that convolutional
               neural networks (CNNs) can be trained to predict V1 activity
               more accurately, but it remains unclear which features are
               extracted by V1 neurons beyond orientation selectivity and phase
               invariance. Here we work towards systematically studying V1
               computations by categorizing neurons into groups that perform
               similar computations. We present a framework for identifying
               common features independent of individual neurons' orientation
               selectivity by using a rotation-equivariant convolutional neural
               network, which automatically extracts every feature at multiple
               different orientations. We fit this rotation-equivariant CNN to
               responses of a population of 6000 neurons to natural images
               recorded in mouse primary visual cortex using two-photon
               imaging. We show that our rotation-equivariant network
               outperforms a regular CNN with the same number of feature maps
               and reveals a number of common features, which are shared by
               many V1 neurons and are pooled sparsely to predict neural
               activity. Our findings are a first step towards a powerful new
               tool to study the nonlinear functional organization of visual
               cortex.",
  month     =  feb,
  year      =  2018,
  keywords  = "4 mouse;read;ERC Consolidator 2023"
}

@ARTICLE{Kindel2017-xs,
  title    = "Using deep learning to reveal the neural code for images in
              primary visual cortex",
  author   = "Kindel, William F and Christensen, Elijah D and Zylberberg, Joel",
  abstract = "Primary visual cortex (V1) is the first stage of cortical image
              processing, and a major effort in systems neuroscience is devoted
              to understanding how it encodes information about visual stimuli.
              Within V1, many neurons respond selectively to edges of a given
              preferred orientation: these are known as simple or complex
              cells, and they are well-studied. Other neurons respond to
              localized center-surround image features. Still others respond
              selectively to certain image stimuli, but the specific features
              that excite them are unknown. Moreover, even for the simple and
              complex cells-- the best-understood V1 neurons-- it is
              challenging to predict how they will respond to natural image
              stimuli. Thus, there are important gaps in our understanding of
              how V1 encodes images. To fill this gap, we train deep
              convolutional neural networks to predict the firing rates of V1
              neurons in response to natural image stimuli, and find that 15\%
              of these neurons are within 10\% of their theoretical limit of
              predictability. For these well predicted neurons, we invert the
              predictor network to identify the image features (receptive
              fields) that cause the V1 neurons to spike. In addition to those
              with previously-characterized receptive fields (Gabor wavelet and
              center-surround), we identify neurons that respond predictably to
              higher-level textural image features that are not localized to
              any particular region of the image.",
  year     =  2017,
  keywords = "4 Projects;recurrent;inception;phase coding;ERC Consolidator 2023"
}

@ARTICLE{Kalweit2020-ru,
  title    = "Deep inverse q-learning with constraints",
  author   = "Kalweit, Gabriel and Huegle, Maria and Werling, Moritz and
              Boedecker, Joschka",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  pages    = "14291--14302",
  year     =  2020,
  keywords = "read;ERC Consolidator 2023"
}

@INPROCEEDINGS{Hoogeboom2021-zs,
  title     = "Learning Discrete Distributions by Dequantization",
  booktitle = "Third Symposium on Advances in Approximate Bayesian Inference",
  author    = "Hoogeboom, Emiel and Cohen, Taco and Tomczak, Jakub Mikolaj",
  year      =  2021,
  keywords  = "read;ERC Consolidator 2023"
}

@ARTICLE{Heeger1992-xx,
  title    = "Normalization of cell responses in cat striate cortex",
  author   = "Heeger, D J",
  abstract = "Simple cells in the striate cortex have been depicted as
              half-wave-rectified linear operators. Complex cells have been
              depicted as energy mechanisms, constructed from the squared sum
              of the outputs of quadrature pairs of linear operators. However,
              the linear/energy model falls short of a complete explanation of
              striate cell responses. In this paper, a modified version of the
              linear/energy model is presented in which striate cells mutually
              inhibit one another, effectively normalizing their responses with
              respect to stimulus contrast. This paper reviews experimental
              measurements of striate cell responses, and shows that the new
              model explains a significantly larger body of physiological data.",
  journal  = "Vis. Neurosci.",
  volume   =  9,
  number   =  2,
  pages    = "181--197",
  year     =  1992,
  keywords = "adaptation; animals; biological; cats; contrast sensitivity;
              mathematics; models; ocular; physiology; visual cortex; visual
              pathways;\_imported;ERC Consolidator 2023"
}

@INPROCEEDINGS{Child2022-fw,
  title     = "Very Deep {VAEs} Generalize Autoregressive Models and Can
               Outperform Them on Images",
  booktitle = "International Conference on Learning Representations",
  author    = "Child, Rewon",
  abstract  = "We present a hierarchical VAE that, for the first time,
               generates samples quickly $\textit\{and\}$ outperforms the
               PixelCNN in log-likelihood on all natural image benchmarks. We
               begin by observing that, in theory, VAEs can actually represent
               autoregressive models, as well as faster, better models if they
               exist, when made sufficiently deep. Despite this, autoregressive
               models have historically outperformed VAEs in log-likelihood. We
               test if insufficient depth explains why by scaling a VAE to
               greater stochastic depth than previously explored and evaluating
               it CIFAR-10, ImageNet, and FFHQ. In comparison to the PixelCNN,
               these very deep VAEs achieve higher likelihoods, use fewer
               parameters, generate samples thousands of times faster, and are
               more easily applied to high-resolution images. Qualitative
               studies suggest this is because the VAE learns efficient
               hierarchical visual representations. We release our source code
               and models at https://github.com/openai/vdvae.",
  month     =  feb,
  year      =  2022,
  keywords  = "read;ERC Consolidator 2023"
}

@ARTICLE{Cisek_undated-kf,
  title    = "{BEYOND} {THE} {COMPUTER} {METAPHOR}: {BEHAVIOR} {AS}
              {INTERACTION}",
  author   = "Cisek, Paul",
  keywords = "unread;ERC Consolidator 2023"
}

@INPROCEEDINGS{Batty2016-do,
  title    = "Multilayer network models of primate retinal ganglion cells",
  author   = "Batty, E and Merel, J and Brackbill, N and Heitman, A and Sher, A
              and Litke, A and Chichilnisky, E J and Paninski, L",
  year     =  2016,
  keywords = "microns;recurrent;ERC Consolidator 2023"
}

@ARTICLE{Safarani2021-yy,
  title    = "Towards robust vision by multi-task learning on monkey visual
              cortex",
  author   = "Safarani, Shahd and Nix, Arne and Willeke, Konstantin and Cadena,
              Santiago and Restivo, Kelli and Denfield, George and Tolias,
              Andreas and Sinz, Fabian",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  34,
  pages    = "739--751",
  month    =  dec,
  year     =  2021,
  keywords = "own;SFB 1456 Mathematic of Experiment;ERC Consolidator 2023"
}

@ARTICLE{Barlow1972-eh,
  title    = "Single units and sensation: A neuron doctrine for perceptual
              psychology?",
  author   = "Barlow, H B",
  journal  = "Perception",
  volume   =  1,
  pages    = "371--394",
  year     =  1972,
  keywords = "read;read next;\_imported;ERC Consolidator 2023"
}

@INPROCEEDINGS{Bashiri2021-or,
  title     = "A flow-based latent state generative model of neural population
               responses to natural images",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Bashiri, Mohammad and Walker, Edgar and Lurz, Konstantin-Klemens
               and Jagadish, Akshay and Muhammad, Taliah and Ding, Zhiwei and
               Ding, Zhuokun and Tolias, Andreas and Sinz, Fabian",
  editor    = "Ranzato, M and Beygelzimer, A and Dauphin, Y and Liang, P S and
               Vaughan, J Wortman",
  publisher = "Curran Associates, Inc.",
  volume    =  34,
  pages     = "15801--15815",
  month     =  dec,
  year      =  2021,
  keywords  = "own;SFB 1456 Mathematic of
               Experiment;NeurIPS-2021-a-flow-based-latent-state-generative-model-of-neural-population-responses-to-natural-images-Bibtex.bib;ERC
               Consolidator 2023"
}

@MISC{Vasilyev2020-ep,
  title        = "Optimal control of eye-movements during visual search",
  author       = "Vasilyev, A Y",
  abstract     = "We study the problem of an optimal oculomotor control during
                  the execution of visual search tasks. We introduce a
                  computational model of human eye movements, which takes into
                  account various constraints of the human visual and
                  oculomotor systems. In the model, the choice of the
                  subsequent fixation location is posed as a problem of a
                  stochastic optimal control, which relies on reinforcement
                  learning methods. We show that if biological constraints are
                  taken into account, the trajectories simulated under a
                  learned policy share both basic statistical properties and a
                  scaling behaviour with human eye movements. We validated our
                  model simulations with human psychophysical eye-tracking
                  experiments.",
  year         =  2020,
  howpublished = "\url{https://api.deepai.org/publication-download-pdf/optimal-control-of-eye-movements-during-visual-search}",
  note         = "Accessed: 2023-1-3",
  keywords     = "4 behavior;read next;unread;ERC Consolidator 2023"
}

@ARTICLE{Rowell1971-zj,
  title    = "Variable Responsiveness of a Visual Interneurone in the
              {Free-Moving} Locust, and its Relation to Behaviour and Arousal",
  author   = "Rowell, C",
  abstract = "The association between motor activity and dishabituation
              suggests that the latter derives either from motor system
              collaterals or from mechanoreceptive reafference, and the
              probable anatomical and physiological bases for modulation of
              DCMD responsiveness are discussed. 1. Recorded from a dissected
              immobilized animal, or from an unrestrained animal which is
              quiescent, the descending contralateral movement detector (DCMD)
              neurone shows an exponential decremental response to a repetitive
              stimulus (habituation), reaching a plateau level characteristic
              of the stimulus conditions. The process is site-specific on the
              retina, and movement to a new area of retina gives a complete
              recovery. In the absence of stimulation responsiveness returns
              over minutes or hours. 2. Immediate recovery without a rest
              (dishabituation) can be obtained by a variety of strong sensory
              stimuli of several different modalities (`extra-stimuli') or by
              non specific electrical stimulation of parts of the CNS. The
              dishabituating efficacy of all these wanes with repetition. When
              the habituating stimulus is moved to a new retinal site the
              previous site is not dishabituated. 3. Dishabituation is not
              site-specific but affects the whole retina simultaneously. It
              appears to reverse the original decremental process (`re-set')
              rather than to produce an independent enhancement elsewhere in
              the pathway, as it does not increase the response from a
              submaximally stimulated, but unhabituated, retinal site. 4. In
              unrestrained animals dishabituating extra-stimuli also cause
              behavioural arousal or other motor activity. When motor activity
              starts, the DCMD is dishabituated and shows no regular
              decremental trend thereafter until movement ceases. DCMD
              background activity is also increased. These effects are not due
              to the visual stimulus of the moving appendages. 5. The
              association between motor activity and dishabituation suggests
              that the latter derives either from motor system collaterals or
              from mechanoreceptive reafference. Stimulation of the antennal
              nerve of a totally de-efferented brain cause some dishabituation;
              this eliminates the lower motor system (below command-fibre
              level) as the source of dishabituation and suggests it is purely
              sensory. 6. The activity of a thoracic cord unit (of possibly a
              wide-field mechanoreceptor interneurone) precedes by 5-20 sec,
              and closely correlates with, changes in responsiveness of the
              DCMD. It is either an important input to, or an output from, the
              dishabituating system. 7. Progressive reduction of sensory input
              to the brain affects DCMD responsiveness as follows: (i)
              spontaneous dishabituation is less frequent, (ii) dishabituation
              is less easily induced and smaller, (iii) rate of habituation is
              increased, (iv) plateau response level after habituation is
              lower. 8. Electrical stimulation of the circumoesophageal
              connective can depress DCMD responsiveness for many minutes. 9.
              The probable anatomical and physiological bases for modulation of
              DCMD responsiveness are discussed.",
  journal  = "J. Exp. Biol.",
  year     =  1971,
  keywords = "4 behavior;4 brainstate;read next;unread;ERC Consolidator 2023",
  language = "en"
}

@ARTICLE{Conwell2021-pw,
  title    = "Neural regression, representational similarity, model zoology \&
              neural taskonomy at scale in rodent visual cortex",
  author   = "Conwell, Colin and Mayo, David and Barbu, Andrei and Buice,
              Michael and Alvarez, George and Katz, Boris",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  34,
  pages    = "5590--5607",
  year     =  2021,
  keywords = "read;4 mouse;ERC Consolidator 2023"
}

@INPROCEEDINGS{Baker2022-tj,
  title     = "Video {PreTraining} ({VPT)}: Learning to Act by Watching
               Unlabeled Online Videos",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Baker, Bowen and Akkaya, Ilge and Zhokov, Peter and Huizinga,
               Joost and Tang, Jie and Ecoffet, Adrien and Houghton, Brandon
               and Sampedro, Raul and Clune, Jeff",
  abstract  = "Pretraining on noisy, internet-scale datasets has been heavily
               studied as a technique for training models with broad, general
               capabilities for text, images, and other modalities. However,
               for many sequential decision domains such as robotics, video
               games, and computer use, publicly available data does not
               contain the labels required to train behavioral priors in the
               same way. We extend the internet-scale pretraining paradigm to
               sequential decision domains through semi-supervised imitation
               learning wherein agents learn to act by watching online
               unlabeled videos. Specifically, we show that with a small amount
               of labeled data we can train an inverse dynamics model accurate
               enough to label a huge unlabeled source of online data -- here,
               online videos of people playing Minecraft -- from which we can
               then train a general behavioral prior. Despite using the native
               human interface (mouse and keyboard at 20Hz), we show that this
               behavioral prior has nontrivial zero-shot capabilities and that
               it can be fine-tuned, with both imitation learning and
               reinforcement learning, to hard-exploration tasks that are
               impossible to learn from scratch via reinforcement learning. For
               many tasks our models exhibit human-level performance, and we
               are the first to report computer agents that can craft diamond
               tools, which can take proficient humans upwards of 20 minutes
               (24,000 environment actions) of gameplay to accomplish.",
  month     =  oct,
  year      =  2022,
  keywords  = "4 behavior;read next;unread;ERC Consolidator 2023"
}

@INPROCEEDINGS{Lurz2022-up,
  title     = "Bayesian Oracle for bounding information gain in neural encoding
               models",
  booktitle = "Neurips 2022 Workshop {InfoCog}",
  author    = "Lurz, Konstantin and Bashiri, Mohammad and Sinz, Fabian",
  abstract  = "In recent years, deep learning models have set new standards in
               predicting neural population responses. Most of these models
               currently focus on predicting the mean response of each neuron
               for a given input. However, neural variability around this mean
               is not just noise and plays a central role in several theories
               on neural computation. To capture this variability, we need
               models that predict full response distributions for a given
               stimulus. However, to measure the quality of such models,
               commonly used correlation-based metrics are not sufficient as
               they mainly care about the mean of the response distribution. An
               interpretable alternative evaluation metric for likelihood-based
               models is \textbackslashtextit\{Information Gain\} (IG) which
               evaluates the likelihood of a model relative to a lower and
               upper bound. However, while a lower bound is usually easy to
               obtain, constructing an upper bound turns out to be challenging
               for neural recordings with relatively low numbers of repeated
               trials, high (shared) variability, and sparse responses. In this
               work, we generalize the jack-knife oracle estimator for the
               mean---commonly used for correlation metrics---to a flexible
               Bayesian oracle estimator for IG based on posterior predictive
               distributions. We describe and address the challenges that arise
               when estimating the lower and upper bounds from small datasets.
               We then show that our upper bound estimate is data-efficient and
               robust even in the case of sparse responses and low
               signal-to-noise ratio. We further provide the derivation of the
               upper bound estimator for a variety of common distributions
               including the state-of-the-art zero-inflated mixture models, and
               relate IG to common mean-based metrics. Finally, we use our
               approach to evaluate such a mixture model resulting in $90\%$ IG
               performance.",
  month     =  nov,
  year      =  2022,
  keywords  = "read;own;ERC Consolidator 2023"
}
